{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "sys.path.insert(0, '../Continuous-Weight-Balancing')\n",
    "\n",
    "from weight_balancing import continuous_weight\n",
    "from util import plot_cont_var, roc_sklearn_model, plot_loss\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pathlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from math import pi\n",
    "from pprint import pprint\n",
    "## Sklearn models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "## Bokeh plotting\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.layouts import gridplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Constants ####\n",
    "\n",
    "SEED = 42\n",
    "N_ESTIMATORS = 200 # Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Heart Disease dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
       "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
       "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
       "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
       "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  \n",
       "5   0     1       1  \n",
       "6   0     2       1  \n",
       "7   0     3       1  \n",
       "8   0     3       1  \n",
       "9   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/hd/data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what each of these columns means:\n",
    "\n",
    "1. **age** -> Age of the person.\n",
    "2. **sex** -> Sex of the person.  (1 = male; 0 = female)\n",
    "3. **cp** -> Chest Pain Type. It can take values of 0, 1, 2, 3.\n",
    "4. **trestbps** -> Resting Blood Presssure (Measured in mm Hg on admission to the hospital). It can take continuous values from 94 to 200.  \n",
    "5. **chol** -> Serum Cholestrol in mg/dl. It also takes continuous values.\n",
    "6. **fbs** -> Fasting Blood Sugar. It can take value of either 1 or 0.\n",
    "7. **restecg** -> Resting Electrocardiographic Results. It can take value of 0, 1 or 2.\n",
    "8. **thalach** -> Maximum Heart Rate achieved. It can take continuous value from 71 to 202.\n",
    "9. **exang** -> Exercise Induced Angina. It can take value either of 0 or 1.\n",
    "10. **oldpeak** -> ST depression induced by exercise relative to rest. It takes continuous decimal values.\n",
    "11. **slope** -> the slope of the peak exercise ST segment. It can take value of either 0, 1 or 2.\n",
    "12. **ca** -> Number of major vessels colored by flourosopy. It can take value of either 0, 1, 2, 3 or 4. \n",
    "13. **thal** -> 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. **target** -> Indicates the presence or absence of heart disease. (= the predicted attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('Target', 2), ('color', 6), ('counts', 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.renderers.GlyphRenderer\">GlyphRenderer</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'1029', <span id=\"1032\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">data_source&nbsp;=&nbsp;ColumnDataSource(id='1002', ...),</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">glyph&nbsp;=&nbsp;VBar(id='1027', ...),</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hover_glyph&nbsp;=&nbsp;None,</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">level&nbsp;=&nbsp;'glyph',</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted&nbsp;=&nbsp;False,</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">muted_glyph&nbsp;=&nbsp;None,</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">nonselection_glyph&nbsp;=&nbsp;VBar(id='1028', ...),</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">selection_glyph&nbsp;=&nbsp;None,</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">view&nbsp;=&nbsp;CDSView(id='1030', ...),</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range_name&nbsp;=&nbsp;'default',</div></div><div class=\"1031\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range_name&nbsp;=&nbsp;'default')</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"1032\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"1031\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "GlyphRenderer(id='1029', ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique, counts = np.unique(df['target'].values)\n",
    "unique = [\"0\", '1']\n",
    "\n",
    "top = [df['target'].value_counts()[0], df['target'].value_counts()[1]]\n",
    "source = ColumnDataSource(data = dict(Target = unique, counts = top, color = Spectral6))\n",
    "\n",
    "p = figure(\n",
    "    x_range = unique,\n",
    "    plot_height = 500,\n",
    "    plot_width = 500,\n",
    "    x_axis_label = 'Target',\n",
    "    y_axis_label = 'Count(Target)',\n",
    "    title = 'Count of People Having Heart Disease and Not Having Heart Disease',\n",
    "    tools = \"hover\", tooltips=\"@Target: @counts\"\n",
    ")\n",
    "\n",
    "p.vbar(\n",
    "    x = 'Target',\n",
    "    top = 'counts',\n",
    "    bottom = 0,\n",
    "    width = 0.9,\n",
    "    source = source,\n",
    "    color = 'color'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of people having Heart Disease 54.0\n",
      "Percentage of people not having Heart Disease 46.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of people having Heart Disease\", round(df['target'].value_counts()[1] / (df['target'].value_counts()[0] + df['target'].value_counts()[1]), 2) * 100)\n",
    "print(\"Percentage of people not having Heart Disease\", round(df['target'].value_counts()[0] / (df['target'].value_counts()[0] + df['target'].value_counts()[1]), 2) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {\n",
    "            'No Heart Disease' : df['target'].value_counts()[0], \n",
    "          'Have Heart Disease' : df['target'].value_counts()[1]\n",
    "         }\n",
    "\n",
    "data = pd.Series(target).reset_index(name = 'value').rename(columns = {'index':'target'})\n",
    "data['angle'] = data['value']/data['value'].sum() * 2 * pi\n",
    "data['color'] = ['skyblue', 'salmon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"0d648b86-ad20-404f-973c-26040528f3d4\" data-root-id=\"1091\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"ff239218-f3e4-4371-99e1-bfd391be06a9\":{\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1090\",\"type\":\"ToolbarBox\"},{\"id\":\"1088\",\"type\":\"GridBox\"}]},\"id\":\"1091\",\"type\":\"Column\"},{\"attributes\":{},\"id\":\"1074\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1054\",\"type\":\"HoverTool\"}]},\"id\":\"1055\",\"type\":\"Toolbar\"},{\"attributes\":{\"source\":{\"id\":\"1002\",\"type\":\"ColumnDataSource\"}},\"id\":\"1030\",\"type\":\"CDSView\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1058\",\"type\":\"CumSum\"},\"units\":\"rad\"},\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"value\":\"white\"},\"radius\":{\"units\":\"data\",\"value\":0.4},\"start_angle\":{\"expr\":{\"id\":\"1057\",\"type\":\"CumSum\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":1}},\"id\":\"1061\",\"type\":\"Wedge\"},{\"attributes\":{\"field\":\"angle\"},\"id\":\"1058\",\"type\":\"CumSum\"},{\"attributes\":{\"text\":\"Count of People Having Heart Disease and Not Having Heart Disease\"},\"id\":\"1004\",\"type\":\"Title\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1069\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1045\",\"type\":\"BasicTicker\"}},\"id\":\"1044\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"data\":{\"angle\":{\"__ndarray__\":\"L3oQGqjkBkAB4HeOTl8LQA==\",\"dtype\":\"float64\",\"shape\":[2]},\"color\":[\"skyblue\",\"salmon\"],\"index\":[0,1],\"target\":[\"No Heart Disease\",\"Have Heart Disease\"],\"value\":[138,165]},\"selected\":{\"id\":\"1085\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1086\",\"type\":\"UnionRenderers\"}},\"id\":\"1059\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@target: @value\"},\"id\":\"1054\",\"type\":\"HoverTool\"},{\"attributes\":{\"axis_label\":\"Target\",\"formatter\":{\"id\":\"1076\",\"type\":\"CategoricalTickFormatter\"},\"ticker\":{\"id\":\"1015\",\"type\":\"CategoricalTicker\"}},\"id\":\"1014\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"callback\":null,\"data\":{\"Target\":[\"0\",\"1\"],\"color\":[\"#3288bd\",\"#99d594\",\"#e6f598\",\"#fee08b\",\"#fc8d59\",\"#d53e4f\"],\"counts\":[138,165]},\"selected\":{\"id\":\"1077\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1078\",\"type\":\"UnionRenderers\"}},\"id\":\"1002\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"Count(Target)\",\"formatter\":{\"id\":\"1074\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"counts\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"Target\"}},\"id\":\"1028\",\"type\":\"VBar\"},{\"attributes\":{\"field\":\"angle\",\"include_zero\":true},\"id\":\"1057\",\"type\":\"CumSum\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1076\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1023\",\"type\":\"HoverTool\"}]},\"id\":\"1024\",\"type\":\"Toolbar\"},{\"attributes\":{\"children\":[[{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},0,0],[{\"id\":\"1033\",\"subtype\":\"Figure\",\"type\":\"Plot\"},1,0]]},\"id\":\"1088\",\"type\":\"GridBox\"},{\"attributes\":{\"callback\":null},\"id\":\"1038\",\"type\":\"DataRange1d\"},{\"attributes\":{\"end_angle\":{\"expr\":{\"id\":\"1058\",\"type\":\"CumSum\"},\"units\":\"rad\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"radius\":{\"units\":\"data\",\"value\":0.4},\"start_angle\":{\"expr\":{\"id\":\"1057\",\"type\":\"CumSum\"},\"units\":\"rad\"},\"x\":{\"value\":0},\"y\":{\"value\":1}},\"id\":\"1062\",\"type\":\"Wedge\"},{\"attributes\":{},\"id\":\"1067\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1059\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1061\",\"type\":\"Wedge\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1062\",\"type\":\"Wedge\"},\"selection_glyph\":null,\"view\":{\"id\":\"1064\",\"type\":\"CDSView\"}},\"id\":\"1063\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1069\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@Target: @counts\"},\"id\":\"1023\",\"type\":\"HoverTool\"},{\"attributes\":{\"below\":[{\"id\":\"1014\",\"type\":\"CategoricalAxis\"}],\"center\":[{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1022\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1018\",\"type\":\"LinearAxis\"}],\"plot_height\":500,\"plot_width\":500,\"renderers\":[{\"id\":\"1029\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1004\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1024\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1006\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1010\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1008\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1012\",\"type\":\"LinearScale\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"text\":\"Proportion of People Having Heart Disease and not Having Heart Disease\"},\"id\":\"1034\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"LinearScale\"},{\"attributes\":{\"label\":{\"field\":\"target\"},\"renderers\":[{\"id\":\"1063\",\"type\":\"GlyphRenderer\"}]},\"id\":\"1071\",\"type\":\"LegendItem\"},{\"attributes\":{\"callback\":null},\"id\":\"1008\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null,\"start\":-0.5},\"id\":\"1036\",\"type\":\"Range1d\"},{\"attributes\":{\"items\":[{\"id\":\"1071\",\"type\":\"LegendItem\"}],\"label_text_font_size\":{\"value\":\"5pt\"}},\"id\":\"1070\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"line_color\":{\"field\":\"color\"},\"top\":{\"field\":\"counts\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"Target\"}},\"id\":\"1027\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"ticker\":{\"id\":\"1045\",\"type\":\"BasicTicker\"}},\"id\":\"1048\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"1044\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1048\",\"type\":\"Grid\"},{\"id\":\"1053\",\"type\":\"Grid\"},{\"id\":\"1070\",\"type\":\"Legend\"}],\"left\":[{\"id\":\"1049\",\"type\":\"LinearAxis\"}],\"plot_height\":500,\"plot_width\":500,\"renderers\":[{\"id\":\"1063\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1034\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1055\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1036\",\"type\":\"Range1d\"},\"x_scale\":{\"id\":\"1040\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1038\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1042\",\"type\":\"LinearScale\"}},\"id\":\"1033\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"tools\":[{\"id\":\"1023\",\"type\":\"HoverTool\"},{\"id\":\"1054\",\"type\":\"HoverTool\"}]},\"id\":\"1089\",\"type\":\"ProxyToolbar\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1050\",\"type\":\"BasicTicker\"}},\"id\":\"1053\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1059\",\"type\":\"ColumnDataSource\"}},\"id\":\"1064\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1027\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1028\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"1030\",\"type\":\"CDSView\"}},\"id\":\"1029\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1078\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1085\",\"type\":\"Selection\"},{\"attributes\":{\"ticker\":{\"id\":\"1015\",\"type\":\"CategoricalTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1015\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1077\",\"type\":\"Selection\"},{\"attributes\":{\"toolbar\":{\"id\":\"1089\",\"type\":\"ProxyToolbar\"},\"toolbar_location\":\"above\"},\"id\":\"1090\",\"type\":\"ToolbarBox\"},{\"attributes\":{\"callback\":null,\"factors\":[\"0\",\"1\"]},\"id\":\"1006\",\"type\":\"FactorRange\"},{\"attributes\":{},\"id\":\"1086\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"formatter\":{\"id\":\"1067\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1050\",\"type\":\"BasicTicker\"}},\"id\":\"1049\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1091\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"ff239218-f3e4-4371-99e1-bfd391be06a9\",\"roots\":{\"1091\":\"0d648b86-ad20-404f-973c-26040528f3d4\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1091"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = figure(\n",
    "            plot_height = 500, \n",
    "            plot_width = 500, \n",
    "            title = \"Proportion of People Having Heart Disease and not Having Heart Disease\", \n",
    "            toolbar_location = None,\n",
    "            tools = \"hover\", \n",
    "            tooltips = \"@target: @value\", \n",
    "            x_range = (-0.5, 1.0)\n",
    "            )\n",
    "\n",
    "p1.wedge(\n",
    "        x = 0, y = 1, radius = 0.4,\n",
    "        start_angle = cumsum('angle', include_zero=True), \n",
    "        end_angle = cumsum('angle'),\n",
    "        line_color = \"white\", \n",
    "        fill_color = 'color', \n",
    "        legend_field = 'target', \n",
    "        source = data\n",
    "        )\n",
    "\n",
    "p1.legend.location = \"top_right\"\n",
    "\n",
    "\n",
    "p1.legend.label_text_font_size = '5pt'\n",
    "\n",
    "show(gridplot([[p], [p1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Variables are:  ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'target']\n",
      "Continuous Variables are:  ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n"
     ]
    }
   ],
   "source": [
    "## Categorical vs Cont\n",
    "\n",
    "categorical_var = []\n",
    "continuous_var = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if len(df[column].unique()) <= 10:\n",
    "        categorical_var.append(column)\n",
    "    else:\n",
    "        continuous_var.append(column)\n",
    "        \n",
    "print(\"Categorical Variables are: \", categorical_var)\n",
    "print(\"Continuous Variables are: \", continuous_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use-case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['age'])\n",
    "plt.title('Distribution by age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"0f2b2428-e75c-4ec8-8b74-42f3e079b359\" data-root-id=\"1190\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"e4886b25-0657-4019-ba95-9045f5b7d9f8\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1201\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1205\",\"type\":\"Grid\"},{\"id\":\"1210\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"1206\",\"type\":\"LinearAxis\"}],\"plot_height\":500,\"plot_width\":500,\"renderers\":[{\"id\":\"1227\",\"type\":\"GlyphRenderer\"},{\"id\":\"1232\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1191\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1217\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1193\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1197\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1195\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1199\",\"type\":\"LinearScale\"}},\"id\":\"1190\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1211\",\"type\":\"PanTool\"},{\"id\":\"1212\",\"type\":\"WheelZoomTool\"},{\"id\":\"1213\",\"type\":\"BoxZoomTool\"},{\"id\":\"1214\",\"type\":\"SaveTool\"},{\"id\":\"1215\",\"type\":\"ResetTool\"},{\"id\":\"1216\",\"type\":\"HelpTool\"}]},\"id\":\"1217\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1254\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"1224\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1225\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1226\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1228\",\"type\":\"CDSView\"}},\"id\":\"1227\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1216\",\"type\":\"HelpTool\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1207\",\"type\":\"BasicTicker\"}},\"id\":\"1210\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1212\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1231\",\"type\":\"Quad\"},{\"attributes\":{\"source\":{\"id\":\"1229\",\"type\":\"ColumnDataSource\"}},\"id\":\"1233\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1207\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"1195\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1202\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1256\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1226\",\"type\":\"Quad\"},{\"attributes\":{\"text\":\"Age vs Target\"},\"id\":\"1191\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1199\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1255\",\"type\":\"Selection\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"blue\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.6},\"line_color\":{\"value\":\"white\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1225\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1214\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1215\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1252\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"source\":{\"id\":\"1224\",\"type\":\"ColumnDataSource\"}},\"id\":\"1228\",\"type\":\"CDSView\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1257\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1197\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"AAAAAACAQUBmZmZmZgZCQM3MzMzMjEJAMzMzMzMTQ0CamZmZmZlDQAAAAAAAIERAZmZmZmamREDNzMzMzCxFQDMzMzMzs0VAmpmZmZk5RkAAAAAAAMBGQGZmZmZmRkdAzczMzMzMR0AzMzMzM1NIQJqZmZmZ2UhAAAAAAABgSUBmZmZmZuZJQM3MzMzMbEpANDMzMzPzSkCamZmZmXlLQAAAAAAAAExAZmZmZmaGTEDNzMzMzAxNQDQzMzMzk01AmpmZmZkZTkAAAAAAAKBOQGZmZmZmJk9AzczMzMysT0CamZmZmRlQQM3MzMzMXFBAAAAAAACgUEA0MzMzM+NQQGZmZmZmJlFAmpmZmZlpUUDNzMzMzKxRQAAAAAAA8FFANDMzMzMzUkBmZmZmZnZSQJqZmZmZuVJAzczMzMz8UkA=\",\"dtype\":\"float64\",\"shape\":[40]},\"right\":{\"__ndarray__\":\"ZmZmZmYGQkDNzMzMzIxCQDMzMzMzE0NAmpmZmZmZQ0AAAAAAACBEQGZmZmZmpkRAzczMzMwsRUAzMzMzM7NFQJqZmZmZOUZAAAAAAADARkBmZmZmZkZHQM3MzMzMzEdAMzMzMzNTSECamZmZmdlIQAAAAAAAYElAZmZmZmbmSUDNzMzMzGxKQDQzMzMz80pAmpmZmZl5S0AAAAAAAABMQGZmZmZmhkxAzczMzMwMTUA0MzMzM5NNQJqZmZmZGU5AAAAAAACgTkBmZmZmZiZPQM3MzMzMrE9AmpmZmZkZUEDNzMzMzFxQQAAAAAAAoFBANDMzMzPjUEBmZmZmZiZRQJqZmZmZaVFAzczMzMysUUAAAAAAAPBRQDQzMzMzM1JAZmZmZmZ2UkCamZmZmblSQM3MzMzM/FJAAAAAAABAU0A=\",\"dtype\":\"float64\",\"shape\":[40]},\"top\":{\"__ndarray__\":\"zj7VoYxEjD8AAAAAAAAAAM4+1aGMRHw/mD7VoYxEfD/OPtWhjESMP84+1aGMRHw/mD7VoYxEfD8a7195aTOVP/LuX3lpM5U/zj7VoYxEjD8a7195aTOVP5g+1aGMRIw/Gu9feWkzlT+YPtWhjESMPxrvX3lpM5U/Gu9feWkzlT+YPtWhjEScP5g+1aGMRIw/Gu9feWkzpT9BRyXl16qhP84+1aGMRLw/8u5feWkztT9s5g82Hs2vP84+1aGMRKw/9JaaDfu7qD/0lpoN+7uoP/LuX3lpM6U/mD7VoYxEnD/OPtWhjEScPxrvX3lpM5U/ye5feWkzpT86P9WhjESMP2I+1aGMRHw/Gu9feWkzlT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAzj7VoYxEfD8=\",\"dtype\":\"float64\",\"shape\":[40]}},\"selected\":{\"id\":\"1253\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1254\",\"type\":\"UnionRenderers\"}},\"id\":\"1224\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"ticker\":{\"id\":\"1202\",\"type\":\"BasicTicker\"}},\"id\":\"1205\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"age\",\"formatter\":{\"id\":\"1252\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1202\",\"type\":\"BasicTicker\"}},\"id\":\"1201\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1211\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1253\",\"type\":\"Selection\"},{\"attributes\":{\"callback\":null,\"data\":{\"left\":{\"__ndarray__\":\"AAAAAAAAPUDNzMzMzCw+QJqZmZmZWT9AMzMzMzNDQECamZmZmdlAQAAAAAAAcEFAZmZmZmYGQkDNzMzMzJxCQDMzMzMzM0NAmpmZmZnJQ0AAAAAAAGBEQGZmZmZm9kRAzczMzMyMRUAzMzMzMyNGQJqZmZmZuUZAAAAAAABQR0BmZmZmZuZHQM3MzMzMfEhANDMzMzMTSUCamZmZmalJQAAAAAAAQEpAZmZmZmbWSkDNzMzMzGxLQDQzMzMzA0xAmpmZmZmZTEAAAAAAADBNQGZmZmZmxk1AzczMzMxcTkAzMzMzM/NOQJqZmZmZiU9AAAAAAAAQUEA0MzMzM1tQQGZmZmZmplBAmpmZmZnxUEDNzMzMzDxRQAAAAAAAiFFANDMzMzPTUUBmZmZmZh5SQJqZmZmZaVJAzczMzMy0UkA=\",\"dtype\":\"float64\",\"shape\":[40]},\"right\":{\"__ndarray__\":\"zczMzMwsPkCamZmZmVk/QDMzMzMzQ0BAmpmZmZnZQEAAAAAAAHBBQGZmZmZmBkJAzczMzMycQkAzMzMzMzNDQJqZmZmZyUNAAAAAAABgREBmZmZmZvZEQM3MzMzMjEVAMzMzMzMjRkCamZmZmblGQAAAAAAAUEdAZmZmZmbmR0DNzMzMzHxIQDQzMzMzE0lAmpmZmZmpSUAAAAAAAEBKQGZmZmZm1kpAzczMzMxsS0A0MzMzMwNMQJqZmZmZmUxAAAAAAAAwTUBmZmZmZsZNQM3MzMzMXE5AMzMzMzPzTkCamZmZmYlPQAAAAAAAEFBANDMzMzNbUEBmZmZmZqZQQJqZmZmZ8VBAzczMzMw8UUAAAAAAAIhRQDQzMzMz01FAZmZmZmYeUkCamZmZmWlSQM3MzMzMtFJAAAAAAAAAU0A=\",\"dtype\":\"float64\",\"shape\":[40]},\"top\":{\"__ndarray__\":\"IkY5C4QgdT8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0RjkLhCCFPzRGOQuEIIU/EEY5C4QghT80RjkLhCCFPxnp1RDGsI8/NEY5C4QgdT/7bqCMlMSnPxnp1RDGsK8/NEY5C4QgpT8Z6dUQxrCfPzRGOQuEIJU/T+nVEMawjz8QRjkLhCCVP04d0olzfKI/+26gjJTEpz/7bqCMlMSnP0/p1RDGsJ8/lZcHDqVoqj8QRjkLhCClP24d0olzfKI/bh3SiXN8oj/ClwcOpWiaPxnp1RDGsI8/NEY5C4QgdT9OHdKJc3yiP0/p1RDGsJ8/7UU5C4QglT98RjkLhCCVP+Po1RDGsI8/NEY5C4QghT9P6dUQxrCPP+Po1RDGsI8/AAAAAAAAAAAAAAAAAAAAADRGOQuEIHU/NEY5C4QgdT8=\",\"dtype\":\"float64\",\"shape\":[40]}},\"selected\":{\"id\":\"1255\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1256\",\"type\":\"UnionRenderers\"}},\"id\":\"1229\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"overlay\":{\"id\":\"1257\",\"type\":\"BoxAnnotation\"}},\"id\":\"1213\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1250\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1229\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1230\",\"type\":\"Quad\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1231\",\"type\":\"Quad\"},\"selection_glyph\":null,\"view\":{\"id\":\"1233\",\"type\":\"CDSView\"}},\"id\":\"1232\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"formatter\":{\"id\":\"1250\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1207\",\"type\":\"BasicTicker\"}},\"id\":\"1206\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.6},\"fill_color\":{\"value\":\"red\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.6},\"line_color\":{\"value\":\"white\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"1230\",\"type\":\"Quad\"},{\"attributes\":{\"callback\":null},\"id\":\"1193\",\"type\":\"DataRange1d\"}],\"root_ids\":[\"1190\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"e4886b25-0657-4019-ba95-9045f5b7d9f8\",\"roots\":{\"1190\":\"0f2b2428-e75c-4ec8-8b74-42f3e079b359\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1190"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p16 = plot_cont_var('age', df)\n",
    "show(p16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the plot below that the dataset is biased heavily in favor of people aged 50 and above. However, looking at the label distributions, we find peaks in the histogram (for +ve labels) below age 50. This is a bias we would ideally like to eliminate through weight balancing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset + weight traits\n",
    "\n",
    "We assume all data is mean-normalized beforehand. The weights for age as a trait have been saved beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/hd')\n",
    "X_train = np.load(data_dir / 'X_train.npy')\n",
    "y_train = np.load(data_dir / 'y_train.npy')\n",
    "X_val = np.load(data_dir / 'X_val.npy')\n",
    "y_val = np.load(data_dir / 'y_val.npy')\n",
    "X_test = np.load(data_dir / 'X_test.npy')\n",
    "y_test = np.load(data_dir / 'y_test.npy')\n",
    "\n",
    "\n",
    "traits_train = np.load(data_dir / 'traits_train.npy')\n",
    "traits_val = np.load(data_dir / 'traits_val.npy')\n",
    "traits_test = np.load(data_dir / 'traits_test.npy')\n",
    "\n",
    "\n",
    "# Merge both val & test sets for more samples\n",
    "traits_oos = np.concatenate([traits_val, traits_test], 0)\n",
    "X_oos = np.concatenate([X_val, X_test], 0)\n",
    "y_oos = np.concatenate([y_val, y_test], 0)\n",
    "\n",
    "# Below 60 years of age\n",
    "CUTOFF = 60\n",
    "X_below = X_oos[traits_oos < CUTOFF]\n",
    "y_below = y_oos[traits_oos < CUTOFF]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 35, 34, 77, 70, 71)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traits_train.min(), traits_val.min(), traits_test.min(), traits_train.max(), traits_val.max(), traits_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating weights on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a scipy.stats.rv_continuous obj\n",
    "min_trait = traits_train.min()\n",
    "range_trait = traits_train.max() - traits_train.min()\n",
    "target = stats.uniform(loc = min_trait, scale = range_trait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wts_tr = continuous_weight(traits_train, target, addl_trait = None, clipping = None, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def comparison_graph(trait, target, weights):\n",
    "    #Sort the trait and weights\n",
    "    tmp = sorted(zip(trait,weights))\n",
    "    trait = [item[0] for item in tmp]\n",
    "    weights = [item[1] for item in tmp]\n",
    "    \n",
    "    source_kde = stats.gaussian_kde(trait)\n",
    "    estimate = source_kde.evaluate(trait)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"Reweighting the Heart Disease Dataset By Age\")\n",
    "    plt.xlabel(\"Patient Age\")\n",
    "    plt.ylabel(\"Probability Density\")\n",
    "    #Plot original\n",
    "    plt.plot(trait, estimate, \"r\", label = \"Original Distribution\")\n",
    "    plt.fill_between(trait, estimate, np.zeros(len(trait)), color = \"r\", alpha=0.3)\n",
    "    \n",
    "    #Plot weighted source\n",
    "    weighted_kde = stats.gaussian_kde(trait, weights = weights)\n",
    "    weighted_estimate = weighted_kde.evaluate(trait)\n",
    "    plt.plot(trait, weighted_estimate, \"b\", label=\"Reweighted Distribution\")\n",
    "    plt.fill_between(trait, weighted_estimate, np.zeros(len(trait)), color = \"b\", alpha=0.3)\n",
    "\n",
    "    #Plot target\n",
    "    x = np.linspace(target.ppf(0.01),\n",
    "                target.ppf(0.99), 100)\n",
    "    plt.plot(x, target.pdf(x), \"g--\", label = \"Target Distribution\", linewidth = 4)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlim([30, 77])\n",
    "    plt.ylim([0, 0.05])\n",
    "    plt.show()\n",
    "    \n",
    "comparison_graph(traits_train, target, wts_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice weight trait (age in this example) isn't made exactly uniform, but we even out the peaks in the 40-60 age group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1: Does CWB improve performance over uniform sampling? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without sample balancing on the entire out-of-sample set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value on unbalanced data:  0.9401939655172413\n"
     ]
    }
   ],
   "source": [
    "clf_unbalanced = RandomForestClassifier(n_estimators=100, random_state=SEED).fit(X_train, y_train, sample_weight=None)\n",
    "roc_unbal = roc_sklearn_model(clf_unbalanced, X_oos, y_oos)\n",
    "print(\"ROC value on unbalanced data: \", roc_unbal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now training using continuous sample-weights as a function of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value on balanced data:  0.9401939655172414\n"
     ]
    }
   ],
   "source": [
    "clf_balanced = RandomForestClassifier(n_estimators=100, random_state=SEED).fit(X_train, y_train, sample_weight=wts_tr)\n",
    "roc_bal = roc_sklearn_model(clf_balanced, X_oos, y_oos)\n",
    "print(\"ROC value on balanced data: \", roc_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on ages below 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced ROC_value:  0.9554924242424242\n",
      "Balanced ROC_value:  0.9602272727272727\n"
     ]
    }
   ],
   "source": [
    "## X_below & y_below defined at start of notebook\n",
    "\n",
    "rf_probs = clf_unbalanced.predict_proba(X_below)[:, 1]\n",
    "roc_value = roc_auc_score(y_below, rf_probs)\n",
    "print(\"Unbalanced ROC_value: \", roc_value)\n",
    "\n",
    "rf_probs_bal = clf_balanced.predict_proba(X_below)[:, 1]\n",
    "roc_value_bal = roc_auc_score(y_below, rf_probs_bal)\n",
    "print(\"Balanced ROC_value: \", roc_value_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Both models perform aboutthe same on the OOS set, but the model trained on balanced data outperforms on a dataset limiited to subjects < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without sample balancing on the entire out-of-sample set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value for unbalanced data:  0.9245689655172413\n"
     ]
    }
   ],
   "source": [
    "clf_unbalanced = LogisticRegression(random_state=SEED).fit(X_train, y_train, sample_weight=None)\n",
    "roc_value_unbal = roc_sklearn_model(clf_unbalanced, X_oos, y_oos)\n",
    "\n",
    "print(\"ROC value for unbalanced data: \", roc_value_unbal) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now training using continuous sample-weights as a function of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value for unbalanced data:  0.9267241379310345\n"
     ]
    }
   ],
   "source": [
    "clf_balanced = LogisticRegression(random_state=SEED).fit(X_train, y_train, sample_weight=wts_tr)\n",
    "roc_value_bal = roc_sklearn_model(clf_balanced, X_oos, y_oos)\n",
    "\n",
    "print(\"ROC value for unbalanced data: \", roc_value_bal) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on ages below 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced ROC_value:  0.9261363636363638\n",
      "Balanced ROC_value:  0.9242424242424243\n"
     ]
    }
   ],
   "source": [
    "## X_below & y_below defined at start of notebook\n",
    "\n",
    "rf_probs = clf_unbalanced.predict_proba(X_below)[:, 1]\n",
    "roc_value = roc_auc_score(y_below, rf_probs)\n",
    "print(\"Unbalanced ROC_value: \", roc_value)\n",
    "\n",
    "rf_probs_bal = clf_balanced.predict_proba(X_below)[:, 1]\n",
    "roc_value_bal = roc_auc_score(y_below, rf_probs_bal)\n",
    "print(\"Balanced ROC_value: \", roc_value_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balanced model does slightly worse, but the difference is *within* 0.2 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def make_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=13, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "#     model.add(Dropout(.5))\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=25, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=True\n",
    ")\n",
    "lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=0, \n",
    "                       mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "callbacks = [es, lr]\n",
    "\n",
    "args_dict = {'x': X_train,\n",
    "             'y': y_train,\n",
    "             'epochs': 100,\n",
    "             'validation_data': (X_val, y_val),\n",
    "             'verbose': 1,\n",
    "             'batch_size': 16,\n",
    "             'callbacks': callbacks\n",
    "            }\n",
    "\n",
    "class Ensemble: \n",
    "    def __init__(self, size=10):\n",
    "        self.models = [make_nn() for _ in range(size)]\n",
    "        \n",
    "    def print_summary(self):\n",
    "        self.models[0].summary()\n",
    "    def fit(self, args_dict, sample_weight=None):\n",
    "        for model in tqdm(self.models):\n",
    "            model.fit(**args_dict, sample_weight=sample_weight)\n",
    "    def validate_roc(self, X, y):\n",
    "        return roc_auc_score(y, np.mean(np.concatenate([model.predict(X) for model in self.models], 1), 1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Due to the variance in Neural Net performance as a result of the random seed, we train an _ensemble_ of 10 models for each data-balancing scheme and average out the predictions on the out-of-sample test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First training with unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,953\n",
      "Trainable params: 1,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5207 - val_loss: 0.6086 - val_accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.6467 - accuracy: 0.6405 - val_loss: 0.5683 - val_accuracy: 0.8667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.5817 - accuracy: 0.7479 - val_loss: 0.5262 - val_accuracy: 0.8667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.5441 - accuracy: 0.7562 - val_loss: 0.4822 - val_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.5336 - accuracy: 0.7934 - val_loss: 0.4445 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.5035 - accuracy: 0.8017 - val_loss: 0.4153 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.4669 - accuracy: 0.8017 - val_loss: 0.3957 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.4596 - accuracy: 0.7645 - val_loss: 0.3778 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.4458 - accuracy: 0.7975 - val_loss: 0.3632 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.4026 - accuracy: 0.8388 - val_loss: 0.3546 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.4099 - accuracy: 0.8347 - val_loss: 0.3482 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.3673 - accuracy: 0.8471 - val_loss: 0.3481 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.3738 - accuracy: 0.8347 - val_loss: 0.3462 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.3817 - accuracy: 0.8264 - val_loss: 0.3473 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3571 - accuracy: 0.8512 - val_loss: 0.3499 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.3746 - accuracy: 0.8388 - val_loss: 0.3499 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3507 - accuracy: 0.8512 - val_loss: 0.3488 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3911 - accuracy: 0.8347 - val_loss: 0.3427 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.3627 - accuracy: 0.8306 - val_loss: 0.3400 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.3571 - accuracy: 0.8388 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.3456 - accuracy: 0.8554 - val_loss: 0.3397 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.3609 - accuracy: 0.8512 - val_loss: 0.3438 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3670 - accuracy: 0.8471 - val_loss: 0.3449 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.3458 - accuracy: 0.8554 - val_loss: 0.3388 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.3301 - accuracy: 0.8636 - val_loss: 0.3390 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3361 - accuracy: 0.8636 - val_loss: 0.3396 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.3606 - accuracy: 0.8512 - val_loss: 0.3378 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 158us/step - loss: 0.3121 - accuracy: 0.8636 - val_loss: 0.3332 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3344 - accuracy: 0.8678 - val_loss: 0.3313 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.3341 - accuracy: 0.8264 - val_loss: 0.3335 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 158us/step - loss: 0.3268 - accuracy: 0.8678 - val_loss: 0.3359 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3478 - accuracy: 0.8512 - val_loss: 0.3351 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3259 - accuracy: 0.8719 - val_loss: 0.3354 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.3287 - accuracy: 0.8636 - val_loss: 0.3335 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.3207 - accuracy: 0.8347 - val_loss: 0.3291 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.3004 - accuracy: 0.8967 - val_loss: 0.3307 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2825 - accuracy: 0.8967 - val_loss: 0.3323 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.2921 - accuracy: 0.8802 - val_loss: 0.3323 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.3323 - accuracy: 0.8719 - val_loss: 0.3313 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2912 - accuracy: 0.8760 - val_loss: 0.3287 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3361 - accuracy: 0.8678 - val_loss: 0.3274 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2867 - accuracy: 0.8843 - val_loss: 0.3273 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3335 - accuracy: 0.8471 - val_loss: 0.3228 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2656 - accuracy: 0.8802 - val_loss: 0.3218 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3197 - accuracy: 0.8636 - val_loss: 0.3215 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2989 - accuracy: 0.8760 - val_loss: 0.3217 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3186 - accuracy: 0.8595 - val_loss: 0.3217 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3283 - accuracy: 0.8636 - val_loss: 0.3225 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3110 - accuracy: 0.8719 - val_loss: 0.3227 - val_accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3106 - accuracy: 0.8802 - val_loss: 0.3224 - val_accuracy: 0.9000\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3012 - accuracy: 0.8554 - val_loss: 0.3218 - val_accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2803 - accuracy: 0.8636 - val_loss: 0.3221 - val_accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3159 - accuracy: 0.8430 - val_loss: 0.3225 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3180 - accuracy: 0.8554 - val_loss: 0.3223 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3345 - accuracy: 0.8595 - val_loss: 0.3226 - val_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2883 - accuracy: 0.9008 - val_loss: 0.3224 - val_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2870 - accuracy: 0.8719 - val_loss: 0.3229 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3308 - accuracy: 0.8760 - val_loss: 0.3231 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2945 - accuracy: 0.8760 - val_loss: 0.3236 - val_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3092 - accuracy: 0.8678 - val_loss: 0.3247 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2994 - accuracy: 0.8760 - val_loss: 0.3245 - val_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3379 - accuracy: 0.8347 - val_loss: 0.3241 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.3083 - accuracy: 0.8595 - val_loss: 0.3240 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3268 - accuracy: 0.8554 - val_loss: 0.3239 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3049 - accuracy: 0.8719 - val_loss: 0.3234 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2825 - accuracy: 0.8967 - val_loss: 0.3236 - val_accuracy: 0.9000\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2900 - accuracy: 0.8760 - val_loss: 0.3235 - val_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.3129 - accuracy: 0.8512 - val_loss: 0.3238 - val_accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3026 - accuracy: 0.8884 - val_loss: 0.3237 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3206 - accuracy: 0.8471 - val_loss: 0.3238 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:58,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7785 - accuracy: 0.5661 - val_loss: 0.7257 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.6822 - accuracy: 0.5909 - val_loss: 0.6542 - val_accuracy: 0.5667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.6179 - accuracy: 0.6529 - val_loss: 0.5962 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.5720 - accuracy: 0.7231 - val_loss: 0.5527 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.5598 - accuracy: 0.7521 - val_loss: 0.5162 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.5101 - accuracy: 0.7851 - val_loss: 0.4763 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.4859 - accuracy: 0.7810 - val_loss: 0.4410 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.4645 - accuracy: 0.7975 - val_loss: 0.4195 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.4337 - accuracy: 0.8347 - val_loss: 0.3965 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.4352 - accuracy: 0.8017 - val_loss: 0.3795 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.4092 - accuracy: 0.8264 - val_loss: 0.3651 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3903 - accuracy: 0.8636 - val_loss: 0.3508 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.4073 - accuracy: 0.8223 - val_loss: 0.3408 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.4074 - accuracy: 0.8306 - val_loss: 0.3331 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.3719 - accuracy: 0.8430 - val_loss: 0.3343 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3648 - accuracy: 0.8264 - val_loss: 0.3270 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3824 - accuracy: 0.8347 - val_loss: 0.3217 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3592 - accuracy: 0.8512 - val_loss: 0.3174 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.3837 - accuracy: 0.8388 - val_loss: 0.3194 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3474 - accuracy: 0.8388 - val_loss: 0.3171 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3430 - accuracy: 0.8554 - val_loss: 0.3162 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3599 - accuracy: 0.8471 - val_loss: 0.3150 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3125 - accuracy: 0.8595 - val_loss: 0.3155 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3482 - accuracy: 0.8430 - val_loss: 0.3201 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3637 - accuracy: 0.8512 - val_loss: 0.3127 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3456 - accuracy: 0.8471 - val_loss: 0.3045 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3573 - accuracy: 0.8388 - val_loss: 0.3095 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3537 - accuracy: 0.8347 - val_loss: 0.3145 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3528 - accuracy: 0.8430 - val_loss: 0.3127 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3528 - accuracy: 0.8512 - val_loss: 0.3137 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3125 - accuracy: 0.8636 - val_loss: 0.3072 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.3209 - accuracy: 0.8678 - val_loss: 0.3043 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3320 - accuracy: 0.8719 - val_loss: 0.3030 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3199 - accuracy: 0.8636 - val_loss: 0.3041 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3142 - accuracy: 0.8802 - val_loss: 0.3031 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3233 - accuracy: 0.8636 - val_loss: 0.3026 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3217 - accuracy: 0.8512 - val_loss: 0.3028 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3103 - accuracy: 0.8678 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.3229 - accuracy: 0.8512 - val_loss: 0.2926 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3178 - accuracy: 0.8430 - val_loss: 0.2907 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3012 - accuracy: 0.8678 - val_loss: 0.2898 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3246 - accuracy: 0.8636 - val_loss: 0.2879 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3061 - accuracy: 0.8678 - val_loss: 0.2870 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3130 - accuracy: 0.8554 - val_loss: 0.2869 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3334 - accuracy: 0.8512 - val_loss: 0.2872 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2912 - accuracy: 0.8843 - val_loss: 0.2866 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2853 - accuracy: 0.8884 - val_loss: 0.2896 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2959 - accuracy: 0.8719 - val_loss: 0.2911 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2939 - accuracy: 0.8636 - val_loss: 0.2920 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3159 - accuracy: 0.8760 - val_loss: 0.2899 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2947 - accuracy: 0.8884 - val_loss: 0.2874 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3145 - accuracy: 0.8802 - val_loss: 0.2873 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2822 - accuracy: 0.8926 - val_loss: 0.2885 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2914 - accuracy: 0.8595 - val_loss: 0.2896 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3115 - accuracy: 0.8719 - val_loss: 0.2906 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3206 - accuracy: 0.8719 - val_loss: 0.2898 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3272 - accuracy: 0.8595 - val_loss: 0.2896 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.2831 - accuracy: 0.8843 - val_loss: 0.2897 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3138 - accuracy: 0.8719 - val_loss: 0.2892 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.3155 - accuracy: 0.8760 - val_loss: 0.2888 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2764 - accuracy: 0.8884 - val_loss: 0.2885 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2935 - accuracy: 0.8843 - val_loss: 0.2883 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3081 - accuracy: 0.8678 - val_loss: 0.2882 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3044 - accuracy: 0.8760 - val_loss: 0.2877 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2977 - accuracy: 0.8719 - val_loss: 0.2873 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3251 - accuracy: 0.8636 - val_loss: 0.2872 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2879 - accuracy: 0.8760 - val_loss: 0.2871 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2886 - accuracy: 0.8595 - val_loss: 0.2871 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.3267 - accuracy: 0.8843 - val_loss: 0.2873 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2757 - accuracy: 0.8636 - val_loss: 0.2875 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2981 - accuracy: 0.8595 - val_loss: 0.2875 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:12<00:50,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7422 - accuracy: 0.4959 - val_loss: 0.6535 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.6535 - accuracy: 0.6116 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.5890 - accuracy: 0.6653 - val_loss: 0.5373 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.5459 - accuracy: 0.7851 - val_loss: 0.4946 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.5170 - accuracy: 0.7851 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.4742 - accuracy: 0.8058 - val_loss: 0.4278 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4829 - accuracy: 0.7810 - val_loss: 0.3971 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.4578 - accuracy: 0.7851 - val_loss: 0.3782 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.4426 - accuracy: 0.8099 - val_loss: 0.3626 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.4395 - accuracy: 0.7727 - val_loss: 0.3508 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.4413 - accuracy: 0.8099 - val_loss: 0.3417 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4008 - accuracy: 0.8430 - val_loss: 0.3409 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.4216 - accuracy: 0.8099 - val_loss: 0.3345 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.4177 - accuracy: 0.8182 - val_loss: 0.3281 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4264 - accuracy: 0.8306 - val_loss: 0.3264 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3871 - accuracy: 0.8223 - val_loss: 0.3206 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3781 - accuracy: 0.8595 - val_loss: 0.3161 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3709 - accuracy: 0.8678 - val_loss: 0.3147 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3791 - accuracy: 0.8430 - val_loss: 0.3140 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3716 - accuracy: 0.8512 - val_loss: 0.3163 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.3571 - accuracy: 0.8306 - val_loss: 0.3096 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.3541 - accuracy: 0.8678 - val_loss: 0.3079 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3255 - accuracy: 0.8760 - val_loss: 0.3046 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.3365 - accuracy: 0.8719 - val_loss: 0.3007 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3381 - accuracy: 0.8347 - val_loss: 0.2990 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.3417 - accuracy: 0.8430 - val_loss: 0.2968 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.3353 - accuracy: 0.8554 - val_loss: 0.2956 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3472 - accuracy: 0.8636 - val_loss: 0.2921 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3304 - accuracy: 0.8595 - val_loss: 0.2936 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3344 - accuracy: 0.8554 - val_loss: 0.2946 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.3621 - accuracy: 0.8512 - val_loss: 0.2908 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3394 - accuracy: 0.8636 - val_loss: 0.2920 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3186 - accuracy: 0.8636 - val_loss: 0.2954 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3076 - accuracy: 0.8595 - val_loss: 0.2994 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.3226 - accuracy: 0.8554 - val_loss: 0.2969 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3085 - accuracy: 0.8843 - val_loss: 0.2956 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.3211 - accuracy: 0.8636 - val_loss: 0.2949 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.3238 - accuracy: 0.8719 - val_loss: 0.2940 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3139 - accuracy: 0.8719 - val_loss: 0.2930 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.3320 - accuracy: 0.8760 - val_loss: 0.2912 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.3073 - accuracy: 0.8843 - val_loss: 0.2938 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.3208 - accuracy: 0.8636 - val_loss: 0.2931 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.3016 - accuracy: 0.8760 - val_loss: 0.2934 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3115 - accuracy: 0.8430 - val_loss: 0.2931 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3200 - accuracy: 0.8471 - val_loss: 0.2923 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2923 - accuracy: 0.8760 - val_loss: 0.2912 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3121 - accuracy: 0.8719 - val_loss: 0.2914 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.3124 - accuracy: 0.8843 - val_loss: 0.2909 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.3149 - accuracy: 0.8636 - val_loss: 0.2911 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3275 - accuracy: 0.8595 - val_loss: 0.2905 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.3280 - accuracy: 0.8554 - val_loss: 0.2901 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2857 - accuracy: 0.8760 - val_loss: 0.2894 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.3252 - accuracy: 0.8595 - val_loss: 0.2888 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2759 - accuracy: 0.8802 - val_loss: 0.2887 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2781 - accuracy: 0.8884 - val_loss: 0.2888 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.3111 - accuracy: 0.8719 - val_loss: 0.2891 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3004 - accuracy: 0.8926 - val_loss: 0.2890 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2930 - accuracy: 0.8967 - val_loss: 0.2887 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2802 - accuracy: 0.8760 - val_loss: 0.2883 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2680 - accuracy: 0.8967 - val_loss: 0.2878 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3057 - accuracy: 0.8802 - val_loss: 0.2874 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2749 - accuracy: 0.8967 - val_loss: 0.2864 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.2906 - accuracy: 0.8595 - val_loss: 0.2860 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.2956 - accuracy: 0.8802 - val_loss: 0.2854 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2952 - accuracy: 0.8678 - val_loss: 0.2858 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.2857 - accuracy: 0.8719 - val_loss: 0.2852 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2878 - accuracy: 0.8843 - val_loss: 0.2848 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.3110 - accuracy: 0.8595 - val_loss: 0.2850 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.3007 - accuracy: 0.8884 - val_loss: 0.2846 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.3404 - accuracy: 0.8636 - val_loss: 0.2838 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.3348 - accuracy: 0.8719 - val_loss: 0.2832 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.2860 - accuracy: 0.8636 - val_loss: 0.2826 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.3269 - accuracy: 0.8595 - val_loss: 0.2828 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.3147 - accuracy: 0.8678 - val_loss: 0.2829 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2905 - accuracy: 0.8926 - val_loss: 0.2827 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2988 - accuracy: 0.8760 - val_loss: 0.2829 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2678 - accuracy: 0.9132 - val_loss: 0.2828 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.3010 - accuracy: 0.8678 - val_loss: 0.2827 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3174 - accuracy: 0.8719 - val_loss: 0.2827 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.3164 - accuracy: 0.8678 - val_loss: 0.2825 - val_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.3074 - accuracy: 0.8595 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3052 - accuracy: 0.8719 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.2916 - accuracy: 0.8926 - val_loss: 0.2821 - val_accuracy: 0.8667\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.3026 - accuracy: 0.8843 - val_loss: 0.2818 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.3106 - accuracy: 0.8884 - val_loss: 0.2817 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.3237 - accuracy: 0.8678 - val_loss: 0.2816 - val_accuracy: 0.8667\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.2930 - accuracy: 0.8760 - val_loss: 0.2815 - val_accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.2915 - accuracy: 0.8678 - val_loss: 0.2814 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.3020 - accuracy: 0.8678 - val_loss: 0.2814 - val_accuracy: 0.8667\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2896 - accuracy: 0.8884 - val_loss: 0.2812 - val_accuracy: 0.8667\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.2964 - accuracy: 0.8471 - val_loss: 0.2811 - val_accuracy: 0.8667\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3140 - accuracy: 0.8719 - val_loss: 0.2808 - val_accuracy: 0.8667\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2953 - accuracy: 0.8926 - val_loss: 0.2805 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.3001 - accuracy: 0.8595 - val_loss: 0.2802 - val_accuracy: 0.8667\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2652 - accuracy: 0.8802 - val_loss: 0.2798 - val_accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3056 - accuracy: 0.8636 - val_loss: 0.2794 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2721 - accuracy: 0.8843 - val_loss: 0.2794 - val_accuracy: 0.8667\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3159 - accuracy: 0.8802 - val_loss: 0.2796 - val_accuracy: 0.8667\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2863 - accuracy: 0.8760 - val_loss: 0.2796 - val_accuracy: 0.8667\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.3107 - accuracy: 0.8802 - val_loss: 0.2796 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:19<00:47,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5785 - val_loss: 0.6225 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.6296 - accuracy: 0.6653 - val_loss: 0.5855 - val_accuracy: 0.6333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.5461 - accuracy: 0.7355 - val_loss: 0.5592 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.5276 - accuracy: 0.7769 - val_loss: 0.5357 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.4954 - accuracy: 0.8182 - val_loss: 0.5088 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.4965 - accuracy: 0.7438 - val_loss: 0.4901 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.4761 - accuracy: 0.7893 - val_loss: 0.4700 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.4467 - accuracy: 0.7851 - val_loss: 0.4551 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.4303 - accuracy: 0.8182 - val_loss: 0.4423 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.4224 - accuracy: 0.8347 - val_loss: 0.4343 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.4048 - accuracy: 0.7975 - val_loss: 0.4303 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3851 - accuracy: 0.8306 - val_loss: 0.4252 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.3898 - accuracy: 0.8347 - val_loss: 0.4192 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.4036 - accuracy: 0.8388 - val_loss: 0.4146 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3659 - accuracy: 0.8554 - val_loss: 0.4078 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3739 - accuracy: 0.8471 - val_loss: 0.4030 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.3705 - accuracy: 0.8471 - val_loss: 0.4028 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3406 - accuracy: 0.8554 - val_loss: 0.4015 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.3608 - accuracy: 0.8512 - val_loss: 0.4029 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3631 - accuracy: 0.8471 - val_loss: 0.4039 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3379 - accuracy: 0.8678 - val_loss: 0.3991 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.3466 - accuracy: 0.8512 - val_loss: 0.3958 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3458 - accuracy: 0.8595 - val_loss: 0.3881 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.3426 - accuracy: 0.8512 - val_loss: 0.3834 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.3354 - accuracy: 0.8388 - val_loss: 0.3834 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.3302 - accuracy: 0.8884 - val_loss: 0.3792 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.3326 - accuracy: 0.8595 - val_loss: 0.3730 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3157 - accuracy: 0.8760 - val_loss: 0.3598 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.3245 - accuracy: 0.8430 - val_loss: 0.3549 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.3225 - accuracy: 0.8967 - val_loss: 0.3630 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.3325 - accuracy: 0.8595 - val_loss: 0.3649 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3430 - accuracy: 0.8430 - val_loss: 0.3636 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.3251 - accuracy: 0.8678 - val_loss: 0.3622 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3187 - accuracy: 0.8636 - val_loss: 0.3594 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3331 - accuracy: 0.8595 - val_loss: 0.3591 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3373 - accuracy: 0.8636 - val_loss: 0.3577 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3234 - accuracy: 0.8595 - val_loss: 0.3553 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.2930 - accuracy: 0.8843 - val_loss: 0.3545 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.2945 - accuracy: 0.8595 - val_loss: 0.3553 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.2925 - accuracy: 0.8636 - val_loss: 0.3559 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3132 - accuracy: 0.8802 - val_loss: 0.3533 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.3117 - accuracy: 0.8678 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3260 - accuracy: 0.8595 - val_loss: 0.3519 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.3125 - accuracy: 0.8595 - val_loss: 0.3554 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.2691 - accuracy: 0.9050 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.3029 - accuracy: 0.8719 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.3059 - accuracy: 0.8926 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2909 - accuracy: 0.8719 - val_loss: 0.3498 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.3044 - accuracy: 0.8760 - val_loss: 0.3493 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2745 - accuracy: 0.8843 - val_loss: 0.3501 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2875 - accuracy: 0.8760 - val_loss: 0.3525 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2705 - accuracy: 0.8884 - val_loss: 0.3532 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2580 - accuracy: 0.8926 - val_loss: 0.3523 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2847 - accuracy: 0.8884 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2818 - accuracy: 0.8719 - val_loss: 0.3525 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2928 - accuracy: 0.8802 - val_loss: 0.3531 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.3140 - accuracy: 0.8554 - val_loss: 0.3531 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.2715 - accuracy: 0.8926 - val_loss: 0.3528 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 158us/step - loss: 0.3150 - accuracy: 0.8636 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2807 - accuracy: 0.8678 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2895 - accuracy: 0.8843 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3055 - accuracy: 0.8719 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2641 - accuracy: 0.9050 - val_loss: 0.3489 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2804 - accuracy: 0.8884 - val_loss: 0.3487 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2954 - accuracy: 0.8843 - val_loss: 0.3485 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.2697 - accuracy: 0.8926 - val_loss: 0.3482 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.2612 - accuracy: 0.8884 - val_loss: 0.3477 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2779 - accuracy: 0.8802 - val_loss: 0.3473 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2727 - accuracy: 0.8926 - val_loss: 0.3472 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2862 - accuracy: 0.8760 - val_loss: 0.3477 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3108 - accuracy: 0.8595 - val_loss: 0.3467 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2924 - accuracy: 0.8967 - val_loss: 0.3464 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2937 - accuracy: 0.8802 - val_loss: 0.3463 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2921 - accuracy: 0.8678 - val_loss: 0.3457 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.2873 - accuracy: 0.8760 - val_loss: 0.3462 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2805 - accuracy: 0.8843 - val_loss: 0.3461 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2773 - accuracy: 0.8843 - val_loss: 0.3459 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2736 - accuracy: 0.8843 - val_loss: 0.3454 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2670 - accuracy: 0.8967 - val_loss: 0.3455 - val_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.2755 - accuracy: 0.8760 - val_loss: 0.3452 - val_accuracy: 0.8667\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2720 - accuracy: 0.9091 - val_loss: 0.3449 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.2856 - accuracy: 0.8760 - val_loss: 0.3443 - val_accuracy: 0.8667\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.2912 - accuracy: 0.9008 - val_loss: 0.3437 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.2701 - accuracy: 0.8843 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2749 - accuracy: 0.9132 - val_loss: 0.3433 - val_accuracy: 0.8667\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2508 - accuracy: 0.9174 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2860 - accuracy: 0.8884 - val_loss: 0.3430 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2603 - accuracy: 0.8967 - val_loss: 0.3433 - val_accuracy: 0.8667\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2848 - accuracy: 0.8843 - val_loss: 0.3431 - val_accuracy: 0.8667\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2584 - accuracy: 0.9132 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2640 - accuracy: 0.9050 - val_loss: 0.3422 - val_accuracy: 0.8667\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2883 - accuracy: 0.8760 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2900 - accuracy: 0.8760 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2978 - accuracy: 0.8760 - val_loss: 0.3424 - val_accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.2716 - accuracy: 0.8967 - val_loss: 0.3421 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2800 - accuracy: 0.8967 - val_loss: 0.3425 - val_accuracy: 0.8667\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2745 - accuracy: 0.8884 - val_loss: 0.3426 - val_accuracy: 0.8667\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2891 - accuracy: 0.8802 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2400 - accuracy: 0.8967 - val_loss: 0.3419 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:27<00:41,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7075 - accuracy: 0.5620 - val_loss: 0.6729 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.6292 - accuracy: 0.6240 - val_loss: 0.5912 - val_accuracy: 0.6333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.5792 - accuracy: 0.7066 - val_loss: 0.5447 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.5207 - accuracy: 0.7562 - val_loss: 0.4999 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.5205 - accuracy: 0.7727 - val_loss: 0.4696 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.4838 - accuracy: 0.7934 - val_loss: 0.4411 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.4522 - accuracy: 0.8182 - val_loss: 0.4149 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.4218 - accuracy: 0.8182 - val_loss: 0.3987 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.4095 - accuracy: 0.8099 - val_loss: 0.3870 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.4019 - accuracy: 0.8388 - val_loss: 0.3767 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.4003 - accuracy: 0.8347 - val_loss: 0.3679 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.4077 - accuracy: 0.8182 - val_loss: 0.3640 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.4100 - accuracy: 0.8058 - val_loss: 0.3594 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.4183 - accuracy: 0.8264 - val_loss: 0.3611 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.3742 - accuracy: 0.8264 - val_loss: 0.3574 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.3828 - accuracy: 0.8430 - val_loss: 0.3565 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3804 - accuracy: 0.8554 - val_loss: 0.3563 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.3813 - accuracy: 0.8471 - val_loss: 0.3531 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3609 - accuracy: 0.8554 - val_loss: 0.3485 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3651 - accuracy: 0.8264 - val_loss: 0.3452 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.3952 - accuracy: 0.8471 - val_loss: 0.3424 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3642 - accuracy: 0.8512 - val_loss: 0.3391 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3551 - accuracy: 0.8512 - val_loss: 0.3387 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3513 - accuracy: 0.8471 - val_loss: 0.3360 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.3280 - accuracy: 0.8471 - val_loss: 0.3340 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.3351 - accuracy: 0.8554 - val_loss: 0.3333 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3503 - accuracy: 0.8264 - val_loss: 0.3321 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.3319 - accuracy: 0.8843 - val_loss: 0.3330 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.3361 - accuracy: 0.8471 - val_loss: 0.3369 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3522 - accuracy: 0.8554 - val_loss: 0.3374 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3725 - accuracy: 0.8430 - val_loss: 0.3324 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.3529 - accuracy: 0.8512 - val_loss: 0.3291 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3565 - accuracy: 0.8430 - val_loss: 0.3271 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.3442 - accuracy: 0.8760 - val_loss: 0.3263 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.3107 - accuracy: 0.8595 - val_loss: 0.3270 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3393 - accuracy: 0.8554 - val_loss: 0.3242 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.3420 - accuracy: 0.8595 - val_loss: 0.3225 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3466 - accuracy: 0.8388 - val_loss: 0.3247 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3135 - accuracy: 0.8636 - val_loss: 0.3220 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3000 - accuracy: 0.8760 - val_loss: 0.3221 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 112us/step - loss: 0.3097 - accuracy: 0.8802 - val_loss: 0.3212 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3234 - accuracy: 0.8471 - val_loss: 0.3208 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2879 - accuracy: 0.8760 - val_loss: 0.3218 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3290 - accuracy: 0.8636 - val_loss: 0.3187 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3066 - accuracy: 0.8802 - val_loss: 0.3172 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3099 - accuracy: 0.8719 - val_loss: 0.3140 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3202 - accuracy: 0.8636 - val_loss: 0.3136 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.3079 - accuracy: 0.8595 - val_loss: 0.3172 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.2854 - accuracy: 0.8926 - val_loss: 0.3136 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3032 - accuracy: 0.8843 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2714 - accuracy: 0.8884 - val_loss: 0.3071 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.3366 - accuracy: 0.8636 - val_loss: 0.3044 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.2915 - accuracy: 0.8843 - val_loss: 0.3016 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.2866 - accuracy: 0.8926 - val_loss: 0.2969 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.2921 - accuracy: 0.8719 - val_loss: 0.2943 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.2839 - accuracy: 0.8802 - val_loss: 0.2959 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3158 - accuracy: 0.8884 - val_loss: 0.2971 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3097 - accuracy: 0.8760 - val_loss: 0.3000 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2890 - accuracy: 0.8595 - val_loss: 0.3044 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2892 - accuracy: 0.8926 - val_loss: 0.3054 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3389 - accuracy: 0.8843 - val_loss: 0.3046 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.3138 - accuracy: 0.8802 - val_loss: 0.3013 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.2827 - accuracy: 0.8884 - val_loss: 0.3006 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2799 - accuracy: 0.8802 - val_loss: 0.3024 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2858 - accuracy: 0.8595 - val_loss: 0.3027 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2981 - accuracy: 0.8719 - val_loss: 0.3017 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2592 - accuracy: 0.8967 - val_loss: 0.3015 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2627 - accuracy: 0.9008 - val_loss: 0.3013 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.2397 - accuracy: 0.9091 - val_loss: 0.2999 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.3001 - accuracy: 0.8802 - val_loss: 0.2982 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.3054 - accuracy: 0.8802 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.2920 - accuracy: 0.8636 - val_loss: 0.2983 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.2999 - accuracy: 0.8471 - val_loss: 0.2988 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2851 - accuracy: 0.8760 - val_loss: 0.2988 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.2799 - accuracy: 0.8760 - val_loss: 0.2990 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2920 - accuracy: 0.8802 - val_loss: 0.2992 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.3063 - accuracy: 0.8967 - val_loss: 0.2991 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.2734 - accuracy: 0.8884 - val_loss: 0.2990 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2841 - accuracy: 0.8843 - val_loss: 0.2989 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2725 - accuracy: 0.8884 - val_loss: 0.2989 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:35<00:36,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7513 - accuracy: 0.5579 - val_loss: 0.6533 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.6690 - accuracy: 0.6033 - val_loss: 0.5973 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.5893 - accuracy: 0.6942 - val_loss: 0.5553 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.5693 - accuracy: 0.7066 - val_loss: 0.5185 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.5366 - accuracy: 0.7727 - val_loss: 0.4903 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.5110 - accuracy: 0.7686 - val_loss: 0.4673 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.4894 - accuracy: 0.7769 - val_loss: 0.4501 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.4785 - accuracy: 0.7893 - val_loss: 0.4368 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.4586 - accuracy: 0.7893 - val_loss: 0.4226 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.4351 - accuracy: 0.8264 - val_loss: 0.4097 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.4211 - accuracy: 0.8264 - val_loss: 0.4019 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4023 - accuracy: 0.8017 - val_loss: 0.3947 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.4193 - accuracy: 0.8017 - val_loss: 0.3819 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3967 - accuracy: 0.8223 - val_loss: 0.3725 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 112us/step - loss: 0.3660 - accuracy: 0.8347 - val_loss: 0.3684 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3472 - accuracy: 0.8884 - val_loss: 0.3657 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3567 - accuracy: 0.8306 - val_loss: 0.3642 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3619 - accuracy: 0.8595 - val_loss: 0.3613 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.3483 - accuracy: 0.8678 - val_loss: 0.3592 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3555 - accuracy: 0.8512 - val_loss: 0.3585 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3581 - accuracy: 0.8430 - val_loss: 0.3519 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3409 - accuracy: 0.8512 - val_loss: 0.3514 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3730 - accuracy: 0.8430 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3735 - accuracy: 0.8512 - val_loss: 0.3484 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3244 - accuracy: 0.8719 - val_loss: 0.3459 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3486 - accuracy: 0.8554 - val_loss: 0.3481 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3603 - accuracy: 0.8347 - val_loss: 0.3458 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3490 - accuracy: 0.8678 - val_loss: 0.3549 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3586 - accuracy: 0.8512 - val_loss: 0.3532 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.93 - 0s 137us/step - loss: 0.3363 - accuracy: 0.8554 - val_loss: 0.3498 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3083 - accuracy: 0.8678 - val_loss: 0.3493 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.3490 - accuracy: 0.8306 - val_loss: 0.3484 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.3285 - accuracy: 0.8595 - val_loss: 0.3465 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.3254 - accuracy: 0.8636 - val_loss: 0.3445 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3543 - accuracy: 0.8471 - val_loss: 0.3450 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3215 - accuracy: 0.8678 - val_loss: 0.3469 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3069 - accuracy: 0.8884 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3332 - accuracy: 0.8678 - val_loss: 0.3430 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3210 - accuracy: 0.8636 - val_loss: 0.3430 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3451 - accuracy: 0.8512 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3190 - accuracy: 0.8719 - val_loss: 0.3424 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.3004 - accuracy: 0.8884 - val_loss: 0.3402 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3252 - accuracy: 0.8678 - val_loss: 0.3398 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3484 - accuracy: 0.8554 - val_loss: 0.3380 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3004 - accuracy: 0.8678 - val_loss: 0.3383 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.3038 - accuracy: 0.8802 - val_loss: 0.3372 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.3443 - accuracy: 0.8471 - val_loss: 0.3387 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3133 - accuracy: 0.8554 - val_loss: 0.3414 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3130 - accuracy: 0.8678 - val_loss: 0.3416 - val_accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3275 - accuracy: 0.8843 - val_loss: 0.3409 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3285 - accuracy: 0.8719 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3064 - accuracy: 0.8678 - val_loss: 0.3395 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3038 - accuracy: 0.8678 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2989 - accuracy: 0.8884 - val_loss: 0.3365 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3206 - accuracy: 0.8636 - val_loss: 0.3355 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3065 - accuracy: 0.8512 - val_loss: 0.3346 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3147 - accuracy: 0.8678 - val_loss: 0.3343 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3100 - accuracy: 0.8760 - val_loss: 0.3349 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3002 - accuracy: 0.8884 - val_loss: 0.3348 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3097 - accuracy: 0.8802 - val_loss: 0.3370 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.3149 - accuracy: 0.8595 - val_loss: 0.3375 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3066 - accuracy: 0.8719 - val_loss: 0.3373 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.2928 - accuracy: 0.8760 - val_loss: 0.3370 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3166 - accuracy: 0.8512 - val_loss: 0.3365 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2945 - accuracy: 0.8636 - val_loss: 0.3366 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2918 - accuracy: 0.8719 - val_loss: 0.3362 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3200 - accuracy: 0.8512 - val_loss: 0.3357 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2937 - accuracy: 0.8802 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3042 - accuracy: 0.8760 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2850 - accuracy: 0.8802 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2961 - accuracy: 0.8760 - val_loss: 0.3355 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2934 - accuracy: 0.8760 - val_loss: 0.3353 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3137 - accuracy: 0.8512 - val_loss: 0.3353 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3119 - accuracy: 0.8554 - val_loss: 0.3352 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.3088 - accuracy: 0.8760 - val_loss: 0.3353 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.2729 - accuracy: 0.8967 - val_loss: 0.3355 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.3271 - accuracy: 0.8678 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3029 - accuracy: 0.8802 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3037 - accuracy: 0.8678 - val_loss: 0.3356 - val_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3158 - accuracy: 0.8678 - val_loss: 0.3357 - val_accuracy: 0.8667\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.3040 - accuracy: 0.8719 - val_loss: 0.3357 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:42<00:29,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7537 - accuracy: 0.5496 - val_loss: 0.6596 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.6517 - accuracy: 0.5826 - val_loss: 0.6121 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.5994 - accuracy: 0.6860 - val_loss: 0.5733 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.5745 - accuracy: 0.7107 - val_loss: 0.5395 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.5421 - accuracy: 0.7686 - val_loss: 0.5107 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.4981 - accuracy: 0.8017 - val_loss: 0.4834 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.4819 - accuracy: 0.7727 - val_loss: 0.4559 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.4335 - accuracy: 0.8182 - val_loss: 0.4299 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.4793 - accuracy: 0.7934 - val_loss: 0.4137 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.4321 - accuracy: 0.8099 - val_loss: 0.3983 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.4188 - accuracy: 0.8264 - val_loss: 0.3858 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 112us/step - loss: 0.3947 - accuracy: 0.8182 - val_loss: 0.3778 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.4281 - accuracy: 0.8058 - val_loss: 0.3766 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.4147 - accuracy: 0.8306 - val_loss: 0.3698 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.3699 - accuracy: 0.8678 - val_loss: 0.3629 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3735 - accuracy: 0.8430 - val_loss: 0.3583 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3720 - accuracy: 0.8595 - val_loss: 0.3562 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3917 - accuracy: 0.8554 - val_loss: 0.3565 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3694 - accuracy: 0.8347 - val_loss: 0.3545 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3708 - accuracy: 0.8512 - val_loss: 0.3498 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3558 - accuracy: 0.8636 - val_loss: 0.3439 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.3983 - accuracy: 0.8140 - val_loss: 0.3440 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.3591 - accuracy: 0.8347 - val_loss: 0.3395 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3704 - accuracy: 0.8430 - val_loss: 0.3373 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.3328 - accuracy: 0.8595 - val_loss: 0.3288 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3360 - accuracy: 0.8512 - val_loss: 0.3289 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.3591 - accuracy: 0.8554 - val_loss: 0.3335 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3377 - accuracy: 0.8760 - val_loss: 0.3311 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3547 - accuracy: 0.8430 - val_loss: 0.3273 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3271 - accuracy: 0.8512 - val_loss: 0.3280 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.3312 - accuracy: 0.8554 - val_loss: 0.3205 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3121 - accuracy: 0.8430 - val_loss: 0.3233 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3538 - accuracy: 0.8388 - val_loss: 0.3202 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3254 - accuracy: 0.8636 - val_loss: 0.3150 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3430 - accuracy: 0.8430 - val_loss: 0.3170 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.3045 - accuracy: 0.8802 - val_loss: 0.3156 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.3346 - accuracy: 0.8719 - val_loss: 0.3172 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3099 - accuracy: 0.8719 - val_loss: 0.3169 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3057 - accuracy: 0.8760 - val_loss: 0.3201 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3150 - accuracy: 0.8595 - val_loss: 0.3189 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3275 - accuracy: 0.8512 - val_loss: 0.3155 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3403 - accuracy: 0.8388 - val_loss: 0.3179 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.3209 - accuracy: 0.8388 - val_loss: 0.3187 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3290 - accuracy: 0.8719 - val_loss: 0.3200 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 98us/step - loss: 0.3030 - accuracy: 0.8884 - val_loss: 0.3211 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3137 - accuracy: 0.8554 - val_loss: 0.3219 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.3216 - accuracy: 0.8760 - val_loss: 0.3238 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3182 - accuracy: 0.8636 - val_loss: 0.3242 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3424 - accuracy: 0.8223 - val_loss: 0.3238 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2928 - accuracy: 0.8843 - val_loss: 0.3232 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2775 - accuracy: 0.8967 - val_loss: 0.3224 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 98us/step - loss: 0.2935 - accuracy: 0.8884 - val_loss: 0.3222 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3203 - accuracy: 0.8512 - val_loss: 0.3217 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3006 - accuracy: 0.8760 - val_loss: 0.3227 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3138 - accuracy: 0.8636 - val_loss: 0.3227 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3098 - accuracy: 0.8554 - val_loss: 0.3222 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.2971 - accuracy: 0.8678 - val_loss: 0.3222 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.2929 - accuracy: 0.8760 - val_loss: 0.3219 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3142 - accuracy: 0.8760 - val_loss: 0.3216 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:49<00:21,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.5620 - val_loss: 0.5990 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.6173 - accuracy: 0.6901 - val_loss: 0.5319 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.5662 - accuracy: 0.7479 - val_loss: 0.4840 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.5173 - accuracy: 0.7727 - val_loss: 0.4468 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.4913 - accuracy: 0.7603 - val_loss: 0.4153 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.4462 - accuracy: 0.8306 - val_loss: 0.3955 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4501 - accuracy: 0.8058 - val_loss: 0.3796 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.4356 - accuracy: 0.8058 - val_loss: 0.3666 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4207 - accuracy: 0.8182 - val_loss: 0.3573 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.4000 - accuracy: 0.8471 - val_loss: 0.3488 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.4185 - accuracy: 0.8347 - val_loss: 0.3436 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3936 - accuracy: 0.8182 - val_loss: 0.3374 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3546 - accuracy: 0.8347 - val_loss: 0.3343 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3983 - accuracy: 0.8099 - val_loss: 0.3318 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3782 - accuracy: 0.8306 - val_loss: 0.3245 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3711 - accuracy: 0.8347 - val_loss: 0.3194 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3687 - accuracy: 0.8554 - val_loss: 0.3182 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3466 - accuracy: 0.8512 - val_loss: 0.3129 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3781 - accuracy: 0.8306 - val_loss: 0.3119 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3620 - accuracy: 0.8223 - val_loss: 0.3093 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3850 - accuracy: 0.8347 - val_loss: 0.3084 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.3385 - accuracy: 0.8554 - val_loss: 0.3072 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3617 - accuracy: 0.8347 - val_loss: 0.3085 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3307 - accuracy: 0.8595 - val_loss: 0.3086 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2940 - accuracy: 0.8802 - val_loss: 0.3095 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3548 - accuracy: 0.8595 - val_loss: 0.3055 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3244 - accuracy: 0.8388 - val_loss: 0.3060 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3336 - accuracy: 0.8678 - val_loss: 0.3088 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3147 - accuracy: 0.8719 - val_loss: 0.3088 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3339 - accuracy: 0.8554 - val_loss: 0.3076 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3366 - accuracy: 0.8347 - val_loss: 0.3082 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3441 - accuracy: 0.8678 - val_loss: 0.3081 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3080 - accuracy: 0.8802 - val_loss: 0.3084 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2921 - accuracy: 0.8802 - val_loss: 0.3102 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3160 - accuracy: 0.8802 - val_loss: 0.3110 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3039 - accuracy: 0.8802 - val_loss: 0.3087 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3654 - accuracy: 0.8554 - val_loss: 0.3062 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3163 - accuracy: 0.8595 - val_loss: 0.3064 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3106 - accuracy: 0.8719 - val_loss: 0.3062 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3180 - accuracy: 0.8719 - val_loss: 0.3053 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3121 - accuracy: 0.8512 - val_loss: 0.3034 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3324 - accuracy: 0.8760 - val_loss: 0.3031 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3327 - accuracy: 0.8636 - val_loss: 0.3027 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2909 - accuracy: 0.8926 - val_loss: 0.3027 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.2963 - accuracy: 0.8678 - val_loss: 0.3026 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3208 - accuracy: 0.8430 - val_loss: 0.3027 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 112us/step - loss: 0.3004 - accuracy: 0.8719 - val_loss: 0.3010 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3235 - accuracy: 0.8760 - val_loss: 0.3008 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3354 - accuracy: 0.8471 - val_loss: 0.3009 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3157 - accuracy: 0.8843 - val_loss: 0.3012 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3416 - accuracy: 0.8636 - val_loss: 0.3013 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3416 - accuracy: 0.8430 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.2888 - accuracy: 0.8926 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3238 - accuracy: 0.8760 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3539 - accuracy: 0.8430 - val_loss: 0.3012 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3290 - accuracy: 0.8471 - val_loss: 0.3012 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3162 - accuracy: 0.8843 - val_loss: 0.3011 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.2937 - accuracy: 0.8802 - val_loss: 0.3007 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3104 - accuracy: 0.8636 - val_loss: 0.3005 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3240 - accuracy: 0.8595 - val_loss: 0.3004 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3126 - accuracy: 0.8719 - val_loss: 0.3004 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.2987 - accuracy: 0.8760 - val_loss: 0.3006 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3201 - accuracy: 0.8636 - val_loss: 0.3006 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2990 - accuracy: 0.8843 - val_loss: 0.3009 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3187 - accuracy: 0.8760 - val_loss: 0.3010 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3260 - accuracy: 0.8636 - val_loss: 0.3010 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.2953 - accuracy: 0.8595 - val_loss: 0.3012 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2901 - accuracy: 0.8843 - val_loss: 0.3013 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3212 - accuracy: 0.8636 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3052 - accuracy: 0.8760 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3112 - accuracy: 0.8760 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.3170 - accuracy: 0.8926 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.2850 - accuracy: 0.8802 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.2940 - accuracy: 0.8678 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3077 - accuracy: 0.8678 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.3137 - accuracy: 0.8843 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3264 - accuracy: 0.8595 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: 0.3087 - accuracy: 0.8595 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3331 - accuracy: 0.8595 - val_loss: 0.3014 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.3073 - accuracy: 0.8802 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3442 - accuracy: 0.8430 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3059 - accuracy: 0.8967 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3363 - accuracy: 0.8512 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3070 - accuracy: 0.8802 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3229 - accuracy: 0.8802 - val_loss: 0.3015 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3078 - accuracy: 0.8967 - val_loss: 0.3015 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:56<00:14,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7872 - accuracy: 0.4711 - val_loss: 0.5557 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.6656 - accuracy: 0.6074 - val_loss: 0.4972 - val_accuracy: 0.8667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.6031 - accuracy: 0.6612 - val_loss: 0.4579 - val_accuracy: 0.9333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.5933 - accuracy: 0.6694 - val_loss: 0.4275 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.5279 - accuracy: 0.7397 - val_loss: 0.3995 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.5046 - accuracy: 0.7851 - val_loss: 0.3753 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4571 - accuracy: 0.8264 - val_loss: 0.3572 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.4496 - accuracy: 0.7934 - val_loss: 0.3413 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.4451 - accuracy: 0.8058 - val_loss: 0.3290 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4325 - accuracy: 0.8017 - val_loss: 0.3206 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.4256 - accuracy: 0.8017 - val_loss: 0.3152 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.4029 - accuracy: 0.8347 - val_loss: 0.3110 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3954 - accuracy: 0.8140 - val_loss: 0.3080 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3788 - accuracy: 0.8595 - val_loss: 0.3071 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3887 - accuracy: 0.8140 - val_loss: 0.3054 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.3885 - accuracy: 0.8636 - val_loss: 0.3008 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.3824 - accuracy: 0.8471 - val_loss: 0.2974 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3596 - accuracy: 0.8595 - val_loss: 0.2973 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.4018 - accuracy: 0.8223 - val_loss: 0.2969 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3252 - accuracy: 0.8760 - val_loss: 0.2928 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3297 - accuracy: 0.8554 - val_loss: 0.2931 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3804 - accuracy: 0.8678 - val_loss: 0.2946 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3552 - accuracy: 0.8554 - val_loss: 0.2958 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3843 - accuracy: 0.8471 - val_loss: 0.2959 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3394 - accuracy: 0.8430 - val_loss: 0.2963 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3589 - accuracy: 0.8306 - val_loss: 0.2955 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3409 - accuracy: 0.8554 - val_loss: 0.2943 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3370 - accuracy: 0.8595 - val_loss: 0.2934 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3326 - accuracy: 0.8554 - val_loss: 0.2947 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3345 - accuracy: 0.8471 - val_loss: 0.2959 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3524 - accuracy: 0.8636 - val_loss: 0.2961 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3592 - accuracy: 0.8388 - val_loss: 0.2969 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3584 - accuracy: 0.8636 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3448 - accuracy: 0.8512 - val_loss: 0.2984 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3079 - accuracy: 0.8926 - val_loss: 0.2988 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3358 - accuracy: 0.8554 - val_loss: 0.2985 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3413 - accuracy: 0.8554 - val_loss: 0.2984 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3424 - accuracy: 0.8512 - val_loss: 0.2983 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3591 - accuracy: 0.8512 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3437 - accuracy: 0.8636 - val_loss: 0.2976 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3284 - accuracy: 0.8719 - val_loss: 0.2977 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.3272 - accuracy: 0.8719 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3230 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3320 - accuracy: 0.8678 - val_loss: 0.2982 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3409 - accuracy: 0.8388 - val_loss: 0.2981 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:03<00:06,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7106 - accuracy: 0.4917 - val_loss: 0.6074 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.6544 - accuracy: 0.6446 - val_loss: 0.5650 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.6218 - accuracy: 0.6901 - val_loss: 0.5205 - val_accuracy: 0.8667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.5427 - accuracy: 0.7645 - val_loss: 0.4870 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.5359 - accuracy: 0.7438 - val_loss: 0.4577 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.5140 - accuracy: 0.7603 - val_loss: 0.4341 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.4681 - accuracy: 0.8388 - val_loss: 0.4144 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.4570 - accuracy: 0.8182 - val_loss: 0.3947 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.4332 - accuracy: 0.8430 - val_loss: 0.3811 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.4515 - accuracy: 0.7893 - val_loss: 0.3719 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.4186 - accuracy: 0.8140 - val_loss: 0.3694 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.4253 - accuracy: 0.8223 - val_loss: 0.3649 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.4212 - accuracy: 0.8140 - val_loss: 0.3612 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.4048 - accuracy: 0.7975 - val_loss: 0.3606 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.4034 - accuracy: 0.8264 - val_loss: 0.3578 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 98us/step - loss: 0.3755 - accuracy: 0.8306 - val_loss: 0.3605 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.4162 - accuracy: 0.7893 - val_loss: 0.3582 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.3886 - accuracy: 0.8347 - val_loss: 0.3549 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 101us/step - loss: 0.3848 - accuracy: 0.8471 - val_loss: 0.3491 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3886 - accuracy: 0.8347 - val_loss: 0.3476 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.3826 - accuracy: 0.8430 - val_loss: 0.3483 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.3623 - accuracy: 0.8554 - val_loss: 0.3434 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3405 - accuracy: 0.8636 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3455 - accuracy: 0.8554 - val_loss: 0.3450 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3571 - accuracy: 0.8636 - val_loss: 0.3453 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.3683 - accuracy: 0.8430 - val_loss: 0.3425 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.3480 - accuracy: 0.8471 - val_loss: 0.3366 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3250 - accuracy: 0.8471 - val_loss: 0.3294 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.3519 - accuracy: 0.8471 - val_loss: 0.3258 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3590 - accuracy: 0.8471 - val_loss: 0.3225 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.3758 - accuracy: 0.8636 - val_loss: 0.3183 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3675 - accuracy: 0.8554 - val_loss: 0.3175 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3211 - accuracy: 0.8678 - val_loss: 0.3135 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3125 - accuracy: 0.8430 - val_loss: 0.3110 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3353 - accuracy: 0.8554 - val_loss: 0.3105 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3372 - accuracy: 0.8512 - val_loss: 0.3116 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3309 - accuracy: 0.8512 - val_loss: 0.3158 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3239 - accuracy: 0.8430 - val_loss: 0.3164 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3105 - accuracy: 0.8719 - val_loss: 0.3161 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3141 - accuracy: 0.8388 - val_loss: 0.3152 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3475 - accuracy: 0.8595 - val_loss: 0.3147 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3331 - accuracy: 0.8554 - val_loss: 0.3139 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3202 - accuracy: 0.8719 - val_loss: 0.3119 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3058 - accuracy: 0.8595 - val_loss: 0.3118 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3150 - accuracy: 0.8595 - val_loss: 0.3107 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.2980 - accuracy: 0.8678 - val_loss: 0.3094 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3227 - accuracy: 0.8636 - val_loss: 0.3090 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3181 - accuracy: 0.8760 - val_loss: 0.3100 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3340 - accuracy: 0.8595 - val_loss: 0.3107 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.3035 - accuracy: 0.8884 - val_loss: 0.3109 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.2937 - accuracy: 0.8884 - val_loss: 0.3104 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.3218 - accuracy: 0.8595 - val_loss: 0.3102 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3261 - accuracy: 0.8760 - val_loss: 0.3103 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2957 - accuracy: 0.8678 - val_loss: 0.3100 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3279 - accuracy: 0.8388 - val_loss: 0.3097 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3136 - accuracy: 0.8802 - val_loss: 0.3098 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2711 - accuracy: 0.8884 - val_loss: 0.3097 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3005 - accuracy: 0.8884 - val_loss: 0.3096 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2902 - accuracy: 0.8843 - val_loss: 0.3096 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2897 - accuracy: 0.8802 - val_loss: 0.3092 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.3312 - accuracy: 0.8554 - val_loss: 0.3090 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.3165 - accuracy: 0.8595 - val_loss: 0.3089 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3240 - accuracy: 0.8719 - val_loss: 0.3088 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3262 - accuracy: 0.8802 - val_loss: 0.3088 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3236 - accuracy: 0.8512 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3165 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3207 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.3088 - accuracy: 0.8595 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2945 - accuracy: 0.8595 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 100us/step - loss: 0.2979 - accuracy: 0.8719 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3021 - accuracy: 0.8636 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3540 - accuracy: 0.8512 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3114 - accuracy: 0.8678 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 102us/step - loss: 0.3120 - accuracy: 0.8636 - val_loss: 0.3087 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.3271 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3102 - accuracy: 0.8760 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3365 - accuracy: 0.8512 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3038 - accuracy: 0.8595 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.3084 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.3343 - accuracy: 0.8554 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.3178 - accuracy: 0.8636 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.3153 - accuracy: 0.8719 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3003 - accuracy: 0.8760 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.3121 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.3125 - accuracy: 0.8595 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3113 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3002 - accuracy: 0.8967 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3137 - accuracy: 0.8554 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.3057 - accuracy: 0.8802 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3064 - accuracy: 0.8760 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3313 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.3409 - accuracy: 0.8595 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.3182 - accuracy: 0.8595 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.3141 - accuracy: 0.8719 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.3069 - accuracy: 0.8719 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.3075 - accuracy: 0.8554 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.3032 - accuracy: 0.8512 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3105 - accuracy: 0.8554 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3042 - accuracy: 0.8719 - val_loss: 0.3086 - val_accuracy: 0.8667\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3069 - accuracy: 0.8678 - val_loss: 0.3086 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:10<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced ROC_value:  0.9364224137931034\n"
     ]
    }
   ],
   "source": [
    "nn_unbalanced = Ensemble(10)\n",
    "nn_unbalanced.print_summary()\n",
    "\n",
    "nn_unbalanced.fit(args_dict)\n",
    "roc_value = nn_unbalanced.validate_roc(X_oos, y_oos)\n",
    "print(\"Unbalanced ROC_value: \", roc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now with a continuously-balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,953\n",
      "Trainable params: 1,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7052 - accuracy: 0.5496 - val_loss: 0.5869 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.6516 - accuracy: 0.6694 - val_loss: 0.5327 - val_accuracy: 0.9000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.5749 - accuracy: 0.7397 - val_loss: 0.4870 - val_accuracy: 0.9000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.5593 - accuracy: 0.7149 - val_loss: 0.4465 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.5180 - accuracy: 0.7603 - val_loss: 0.4134 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.4615 - accuracy: 0.7479 - val_loss: 0.3892 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.4291 - accuracy: 0.7769 - val_loss: 0.3614 - val_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.4211 - accuracy: 0.7851 - val_loss: 0.3463 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3930 - accuracy: 0.7810 - val_loss: 0.3309 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.4008 - accuracy: 0.7893 - val_loss: 0.3236 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.3660 - accuracy: 0.7975 - val_loss: 0.3162 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.3688 - accuracy: 0.7893 - val_loss: 0.3127 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.3410 - accuracy: 0.8140 - val_loss: 0.3091 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.3054 - accuracy: 0.8099 - val_loss: 0.3034 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3177 - accuracy: 0.8306 - val_loss: 0.3020 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3263 - accuracy: 0.8017 - val_loss: 0.3004 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.3141 - accuracy: 0.8223 - val_loss: 0.3009 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3143 - accuracy: 0.8099 - val_loss: 0.3008 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2988 - accuracy: 0.8182 - val_loss: 0.3007 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3287 - accuracy: 0.8099 - val_loss: 0.3029 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2798 - accuracy: 0.8140 - val_loss: 0.3039 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3170 - accuracy: 0.8099 - val_loss: 0.3026 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.3071 - accuracy: 0.8223 - val_loss: 0.3022 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2761 - accuracy: 0.8430 - val_loss: 0.3024 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.2710 - accuracy: 0.8512 - val_loss: 0.3033 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.2644 - accuracy: 0.8471 - val_loss: 0.3029 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2678 - accuracy: 0.8471 - val_loss: 0.3032 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3080 - accuracy: 0.8182 - val_loss: 0.3040 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2959 - accuracy: 0.8099 - val_loss: 0.3040 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2881 - accuracy: 0.8306 - val_loss: 0.3039 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2891 - accuracy: 0.8347 - val_loss: 0.3048 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.2992 - accuracy: 0.8182 - val_loss: 0.3048 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.3056 - accuracy: 0.8264 - val_loss: 0.3048 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.2584 - accuracy: 0.8430 - val_loss: 0.3051 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.2823 - accuracy: 0.8471 - val_loss: 0.3049 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2643 - accuracy: 0.8430 - val_loss: 0.3043 - val_accuracy: 0.9000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2833 - accuracy: 0.8182 - val_loss: 0.3042 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.2727 - accuracy: 0.8554 - val_loss: 0.3041 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.3067 - accuracy: 0.8099 - val_loss: 0.3044 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2978 - accuracy: 0.8306 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2597 - accuracy: 0.8512 - val_loss: 0.3043 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:07<01:08,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6435 - accuracy: 0.5702 - val_loss: 0.6247 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.6308 - accuracy: 0.6405 - val_loss: 0.5730 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.5536 - accuracy: 0.6818 - val_loss: 0.5405 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.5359 - accuracy: 0.6942 - val_loss: 0.5120 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.4923 - accuracy: 0.7686 - val_loss: 0.4877 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.4366 - accuracy: 0.7810 - val_loss: 0.4662 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.4540 - accuracy: 0.7893 - val_loss: 0.4502 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.4376 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.3731 - accuracy: 0.8182 - val_loss: 0.4283 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3738 - accuracy: 0.8388 - val_loss: 0.4196 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.3714 - accuracy: 0.8140 - val_loss: 0.4159 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3405 - accuracy: 0.8388 - val_loss: 0.4105 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3403 - accuracy: 0.8099 - val_loss: 0.4083 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 158us/step - loss: 0.3146 - accuracy: 0.8099 - val_loss: 0.4086 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.3522 - accuracy: 0.8182 - val_loss: 0.4168 - val_accuracy: 0.7667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2962 - accuracy: 0.8306 - val_loss: 0.4161 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.3019 - accuracy: 0.8182 - val_loss: 0.4158 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2801 - accuracy: 0.8512 - val_loss: 0.4115 - val_accuracy: 0.7667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2746 - accuracy: 0.8512 - val_loss: 0.4139 - val_accuracy: 0.7667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2700 - accuracy: 0.8636 - val_loss: 0.4176 - val_accuracy: 0.7667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.2714 - accuracy: 0.8430 - val_loss: 0.4196 - val_accuracy: 0.7667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.2862 - accuracy: 0.8430 - val_loss: 0.4178 - val_accuracy: 0.7667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3071 - accuracy: 0.8388 - val_loss: 0.4153 - val_accuracy: 0.7667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.2516 - accuracy: 0.8595 - val_loss: 0.4169 - val_accuracy: 0.7667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2868 - accuracy: 0.8554 - val_loss: 0.4172 - val_accuracy: 0.7667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2668 - accuracy: 0.8430 - val_loss: 0.4159 - val_accuracy: 0.7667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2835 - accuracy: 0.8471 - val_loss: 0.4156 - val_accuracy: 0.7667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2588 - accuracy: 0.8595 - val_loss: 0.4160 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2644 - accuracy: 0.8512 - val_loss: 0.4160 - val_accuracy: 0.7667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2661 - accuracy: 0.8264 - val_loss: 0.4160 - val_accuracy: 0.7667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2755 - accuracy: 0.8512 - val_loss: 0.4159 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2921 - accuracy: 0.8264 - val_loss: 0.4159 - val_accuracy: 0.7667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2829 - accuracy: 0.8471 - val_loss: 0.4159 - val_accuracy: 0.7667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2782 - accuracy: 0.8388 - val_loss: 0.4155 - val_accuracy: 0.7667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2817 - accuracy: 0.8554 - val_loss: 0.4158 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2581 - accuracy: 0.8512 - val_loss: 0.4159 - val_accuracy: 0.7667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2846 - accuracy: 0.8430 - val_loss: 0.4159 - val_accuracy: 0.7667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.2606 - accuracy: 0.8471 - val_loss: 0.4158 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:15<01:01,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6585 - accuracy: 0.5702 - val_loss: 0.6087 - val_accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.5609 - accuracy: 0.6694 - val_loss: 0.5595 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.5153 - accuracy: 0.7521 - val_loss: 0.5203 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.4912 - accuracy: 0.7727 - val_loss: 0.4807 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.4866 - accuracy: 0.7521 - val_loss: 0.4486 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.4434 - accuracy: 0.7851 - val_loss: 0.4222 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.4110 - accuracy: 0.7851 - val_loss: 0.4020 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3640 - accuracy: 0.7851 - val_loss: 0.3885 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3547 - accuracy: 0.7893 - val_loss: 0.3758 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3813 - accuracy: 0.7810 - val_loss: 0.3636 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3372 - accuracy: 0.8306 - val_loss: 0.3584 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.3439 - accuracy: 0.8017 - val_loss: 0.3538 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.3346 - accuracy: 0.8264 - val_loss: 0.3560 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3081 - accuracy: 0.8017 - val_loss: 0.3524 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.2839 - accuracy: 0.8223 - val_loss: 0.3519 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.3074 - accuracy: 0.8264 - val_loss: 0.3488 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.2598 - accuracy: 0.8636 - val_loss: 0.3454 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.3205 - accuracy: 0.8223 - val_loss: 0.3482 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2608 - accuracy: 0.8678 - val_loss: 0.3609 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2683 - accuracy: 0.8430 - val_loss: 0.3617 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2959 - accuracy: 0.8347 - val_loss: 0.3625 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2837 - accuracy: 0.8264 - val_loss: 0.3599 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2762 - accuracy: 0.8347 - val_loss: 0.3597 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2773 - accuracy: 0.8223 - val_loss: 0.3590 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2763 - accuracy: 0.8306 - val_loss: 0.3606 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2723 - accuracy: 0.8388 - val_loss: 0.3607 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2748 - accuracy: 0.8471 - val_loss: 0.3612 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2702 - accuracy: 0.8554 - val_loss: 0.3630 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2822 - accuracy: 0.8430 - val_loss: 0.3636 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.2798 - accuracy: 0.8471 - val_loss: 0.3635 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.2872 - accuracy: 0.8512 - val_loss: 0.3636 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.2545 - accuracy: 0.8595 - val_loss: 0.3649 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2545 - accuracy: 0.8471 - val_loss: 0.3647 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2591 - accuracy: 0.8140 - val_loss: 0.3645 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2852 - accuracy: 0.8678 - val_loss: 0.3637 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.2999 - accuracy: 0.8306 - val_loss: 0.3635 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2744 - accuracy: 0.8388 - val_loss: 0.3631 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2412 - accuracy: 0.8595 - val_loss: 0.3632 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2641 - accuracy: 0.8471 - val_loss: 0.3630 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2506 - accuracy: 0.8512 - val_loss: 0.3630 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.2564 - accuracy: 0.8554 - val_loss: 0.3627 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2489 - accuracy: 0.8595 - val_loss: 0.3628 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:23<00:54,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.8100 - accuracy: 0.4876 - val_loss: 0.6620 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.6777 - accuracy: 0.6198 - val_loss: 0.6189 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.6257 - accuracy: 0.6240 - val_loss: 0.5910 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.5566 - accuracy: 0.6694 - val_loss: 0.5638 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.5348 - accuracy: 0.6570 - val_loss: 0.5392 - val_accuracy: 0.7000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.5015 - accuracy: 0.7562 - val_loss: 0.5177 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.4711 - accuracy: 0.8017 - val_loss: 0.4991 - val_accuracy: 0.7333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.4552 - accuracy: 0.7686 - val_loss: 0.4773 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.4447 - accuracy: 0.7810 - val_loss: 0.4583 - val_accuracy: 0.7333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.4334 - accuracy: 0.7810 - val_loss: 0.4433 - val_accuracy: 0.7333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 158us/step - loss: 0.3619 - accuracy: 0.8058 - val_loss: 0.4288 - val_accuracy: 0.7667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.3637 - accuracy: 0.7975 - val_loss: 0.4154 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.3591 - accuracy: 0.8264 - val_loss: 0.3982 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3220 - accuracy: 0.8430 - val_loss: 0.3842 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.3430 - accuracy: 0.7727 - val_loss: 0.3760 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.3434 - accuracy: 0.8140 - val_loss: 0.3712 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.3240 - accuracy: 0.8140 - val_loss: 0.3708 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3245 - accuracy: 0.8182 - val_loss: 0.3673 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.3273 - accuracy: 0.8388 - val_loss: 0.3607 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2913 - accuracy: 0.8554 - val_loss: 0.3569 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.3047 - accuracy: 0.8306 - val_loss: 0.3532 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2952 - accuracy: 0.8430 - val_loss: 0.3496 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2972 - accuracy: 0.8099 - val_loss: 0.3458 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.3079 - accuracy: 0.8223 - val_loss: 0.3438 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.3150 - accuracy: 0.8223 - val_loss: 0.3544 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.2814 - accuracy: 0.8471 - val_loss: 0.3518 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.2959 - accuracy: 0.8471 - val_loss: 0.3498 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.2872 - accuracy: 0.8388 - val_loss: 0.3439 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2815 - accuracy: 0.8388 - val_loss: 0.3416 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.2827 - accuracy: 0.8388 - val_loss: 0.3388 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.2578 - accuracy: 0.8430 - val_loss: 0.3364 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2687 - accuracy: 0.8306 - val_loss: 0.3345 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2714 - accuracy: 0.8595 - val_loss: 0.3337 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.2809 - accuracy: 0.8554 - val_loss: 0.3316 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2610 - accuracy: 0.8554 - val_loss: 0.3312 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2629 - accuracy: 0.8471 - val_loss: 0.3317 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2813 - accuracy: 0.8512 - val_loss: 0.3311 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2518 - accuracy: 0.8802 - val_loss: 0.3288 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2565 - accuracy: 0.8636 - val_loss: 0.3286 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.2666 - accuracy: 0.8554 - val_loss: 0.3260 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2618 - accuracy: 0.8430 - val_loss: 0.3299 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.2613 - accuracy: 0.8430 - val_loss: 0.3269 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2411 - accuracy: 0.8512 - val_loss: 0.3266 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2219 - accuracy: 0.8595 - val_loss: 0.3279 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2697 - accuracy: 0.8802 - val_loss: 0.3268 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.2365 - accuracy: 0.8843 - val_loss: 0.3260 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.2742 - accuracy: 0.8306 - val_loss: 0.3297 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.2415 - accuracy: 0.8636 - val_loss: 0.3303 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.2589 - accuracy: 0.8347 - val_loss: 0.3290 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.2373 - accuracy: 0.8636 - val_loss: 0.3294 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2321 - accuracy: 0.8678 - val_loss: 0.3292 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2869 - accuracy: 0.8471 - val_loss: 0.3287 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2638 - accuracy: 0.8471 - val_loss: 0.3281 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.2235 - accuracy: 0.8760 - val_loss: 0.3282 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2368 - accuracy: 0.8512 - val_loss: 0.3283 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2495 - accuracy: 0.8512 - val_loss: 0.3278 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2501 - accuracy: 0.8554 - val_loss: 0.3278 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2612 - accuracy: 0.8884 - val_loss: 0.3277 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2374 - accuracy: 0.8471 - val_loss: 0.3274 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2215 - accuracy: 0.8760 - val_loss: 0.3270 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2473 - accuracy: 0.8678 - val_loss: 0.3269 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2412 - accuracy: 0.8554 - val_loss: 0.3270 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.2322 - accuracy: 0.8678 - val_loss: 0.3264 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2419 - accuracy: 0.8678 - val_loss: 0.3259 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.2434 - accuracy: 0.8595 - val_loss: 0.3255 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 110us/step - loss: 0.2558 - accuracy: 0.8388 - val_loss: 0.3254 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2479 - accuracy: 0.8595 - val_loss: 0.3254 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.2310 - accuracy: 0.8678 - val_loss: 0.3254 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2382 - accuracy: 0.8595 - val_loss: 0.3250 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2524 - accuracy: 0.8554 - val_loss: 0.3249 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2338 - accuracy: 0.8802 - val_loss: 0.3248 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: 0.2144 - accuracy: 0.8678 - val_loss: 0.3247 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2483 - accuracy: 0.8678 - val_loss: 0.3246 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2526 - accuracy: 0.8512 - val_loss: 0.3245 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 112us/step - loss: 0.2594 - accuracy: 0.8512 - val_loss: 0.3243 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2205 - accuracy: 0.8760 - val_loss: 0.3241 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2450 - accuracy: 0.8554 - val_loss: 0.3240 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.2292 - accuracy: 0.8802 - val_loss: 0.3236 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2374 - accuracy: 0.8554 - val_loss: 0.3234 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2509 - accuracy: 0.8595 - val_loss: 0.3233 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2165 - accuracy: 0.8843 - val_loss: 0.3232 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.2377 - accuracy: 0.8512 - val_loss: 0.3230 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2451 - accuracy: 0.8512 - val_loss: 0.3232 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2389 - accuracy: 0.8595 - val_loss: 0.3235 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 109us/step - loss: 0.2209 - accuracy: 0.8843 - val_loss: 0.3235 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2291 - accuracy: 0.8678 - val_loss: 0.3238 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: 0.2648 - accuracy: 0.8264 - val_loss: 0.3237 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2319 - accuracy: 0.8512 - val_loss: 0.3235 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2438 - accuracy: 0.8678 - val_loss: 0.3234 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2379 - accuracy: 0.8678 - val_loss: 0.3234 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2456 - accuracy: 0.8388 - val_loss: 0.3235 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2418 - accuracy: 0.8719 - val_loss: 0.3233 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2533 - accuracy: 0.8430 - val_loss: 0.3232 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2330 - accuracy: 0.8719 - val_loss: 0.3231 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2484 - accuracy: 0.8636 - val_loss: 0.3232 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2576 - accuracy: 0.8595 - val_loss: 0.3231 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: 0.2577 - accuracy: 0.8347 - val_loss: 0.3231 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2315 - accuracy: 0.8719 - val_loss: 0.3231 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 104us/step - loss: 0.2209 - accuracy: 0.8636 - val_loss: 0.3231 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 105us/step - loss: 0.2549 - accuracy: 0.8595 - val_loss: 0.3231 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:32<00:49,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6915 - accuracy: 0.5289 - val_loss: 0.6326 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.5832 - accuracy: 0.6488 - val_loss: 0.5772 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.5654 - accuracy: 0.6983 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.4987 - accuracy: 0.7231 - val_loss: 0.5018 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.4569 - accuracy: 0.7521 - val_loss: 0.4780 - val_accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.4492 - accuracy: 0.7562 - val_loss: 0.4578 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.3987 - accuracy: 0.7893 - val_loss: 0.4409 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.4246 - accuracy: 0.7810 - val_loss: 0.4277 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3511 - accuracy: 0.7975 - val_loss: 0.4176 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3543 - accuracy: 0.8182 - val_loss: 0.4093 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.3955 - accuracy: 0.8058 - val_loss: 0.4017 - val_accuracy: 0.7667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.3595 - accuracy: 0.7851 - val_loss: 0.3962 - val_accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3242 - accuracy: 0.8347 - val_loss: 0.3909 - val_accuracy: 0.7667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3216 - accuracy: 0.8306 - val_loss: 0.3830 - val_accuracy: 0.7667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.3056 - accuracy: 0.8306 - val_loss: 0.3754 - val_accuracy: 0.7667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3084 - accuracy: 0.8347 - val_loss: 0.3733 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.3237 - accuracy: 0.7934 - val_loss: 0.3755 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.3199 - accuracy: 0.8306 - val_loss: 0.3810 - val_accuracy: 0.7667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2748 - accuracy: 0.8388 - val_loss: 0.3857 - val_accuracy: 0.7667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.2728 - accuracy: 0.8430 - val_loss: 0.3847 - val_accuracy: 0.7667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.3081 - accuracy: 0.8223 - val_loss: 0.3824 - val_accuracy: 0.7667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2982 - accuracy: 0.8306 - val_loss: 0.3801 - val_accuracy: 0.7667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.2903 - accuracy: 0.8264 - val_loss: 0.3764 - val_accuracy: 0.7667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2923 - accuracy: 0.8058 - val_loss: 0.3734 - val_accuracy: 0.7667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2900 - accuracy: 0.8430 - val_loss: 0.3707 - val_accuracy: 0.7667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2624 - accuracy: 0.8264 - val_loss: 0.3648 - val_accuracy: 0.7667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2861 - accuracy: 0.8306 - val_loss: 0.3679 - val_accuracy: 0.7667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.2622 - accuracy: 0.8430 - val_loss: 0.3683 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2750 - accuracy: 0.8554 - val_loss: 0.3687 - val_accuracy: 0.7667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2661 - accuracy: 0.8512 - val_loss: 0.3694 - val_accuracy: 0.7667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2835 - accuracy: 0.8595 - val_loss: 0.3720 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2537 - accuracy: 0.8347 - val_loss: 0.3726 - val_accuracy: 0.7667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2601 - accuracy: 0.8512 - val_loss: 0.3726 - val_accuracy: 0.7667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2577 - accuracy: 0.8388 - val_loss: 0.3733 - val_accuracy: 0.7667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2798 - accuracy: 0.8512 - val_loss: 0.3742 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2690 - accuracy: 0.8430 - val_loss: 0.3755 - val_accuracy: 0.7667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2588 - accuracy: 0.8388 - val_loss: 0.3756 - val_accuracy: 0.7667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2855 - accuracy: 0.8182 - val_loss: 0.3752 - val_accuracy: 0.7667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2908 - accuracy: 0.8264 - val_loss: 0.3752 - val_accuracy: 0.7667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2623 - accuracy: 0.8347 - val_loss: 0.3754 - val_accuracy: 0.7667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2506 - accuracy: 0.8554 - val_loss: 0.3760 - val_accuracy: 0.7667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2420 - accuracy: 0.8636 - val_loss: 0.3761 - val_accuracy: 0.7667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2663 - accuracy: 0.8760 - val_loss: 0.3760 - val_accuracy: 0.7667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2543 - accuracy: 0.8430 - val_loss: 0.3760 - val_accuracy: 0.7667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2736 - accuracy: 0.8430 - val_loss: 0.3760 - val_accuracy: 0.7667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2823 - accuracy: 0.8388 - val_loss: 0.3756 - val_accuracy: 0.7667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2591 - accuracy: 0.8471 - val_loss: 0.3757 - val_accuracy: 0.7667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2633 - accuracy: 0.8388 - val_loss: 0.3757 - val_accuracy: 0.7667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2807 - accuracy: 0.8471 - val_loss: 0.3760 - val_accuracy: 0.7667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2680 - accuracy: 0.8347 - val_loss: 0.3761 - val_accuracy: 0.7667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.2435 - accuracy: 0.8554 - val_loss: 0.3761 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:41<00:43,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6627 - accuracy: 0.5702 - val_loss: 0.6189 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.5609 - accuracy: 0.6818 - val_loss: 0.5643 - val_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.5889 - accuracy: 0.6983 - val_loss: 0.5282 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.5013 - accuracy: 0.6901 - val_loss: 0.4994 - val_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.4608 - accuracy: 0.7438 - val_loss: 0.4688 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.4747 - accuracy: 0.7769 - val_loss: 0.4486 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.4153 - accuracy: 0.7851 - val_loss: 0.4297 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3946 - accuracy: 0.8017 - val_loss: 0.4083 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3695 - accuracy: 0.7769 - val_loss: 0.3920 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.3657 - accuracy: 0.7893 - val_loss: 0.3850 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.3453 - accuracy: 0.7893 - val_loss: 0.3786 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.3780 - accuracy: 0.7934 - val_loss: 0.3700 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.3347 - accuracy: 0.8182 - val_loss: 0.3655 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2949 - accuracy: 0.8223 - val_loss: 0.3596 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.3145 - accuracy: 0.8388 - val_loss: 0.3591 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2806 - accuracy: 0.8264 - val_loss: 0.3573 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2787 - accuracy: 0.8306 - val_loss: 0.3557 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.2879 - accuracy: 0.8512 - val_loss: 0.3602 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.3068 - accuracy: 0.8140 - val_loss: 0.3596 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.3156 - accuracy: 0.8306 - val_loss: 0.3598 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.2728 - accuracy: 0.8430 - val_loss: 0.3606 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.2658 - accuracy: 0.8471 - val_loss: 0.3606 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2893 - accuracy: 0.8430 - val_loss: 0.3610 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.2722 - accuracy: 0.8347 - val_loss: 0.3622 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2792 - accuracy: 0.8140 - val_loss: 0.3618 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2827 - accuracy: 0.8430 - val_loss: 0.3630 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2952 - accuracy: 0.8388 - val_loss: 0.3612 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: 0.2779 - accuracy: 0.8554 - val_loss: 0.3621 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2743 - accuracy: 0.8388 - val_loss: 0.3631 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2599 - accuracy: 0.8388 - val_loss: 0.3628 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2853 - accuracy: 0.8636 - val_loss: 0.3629 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2460 - accuracy: 0.8595 - val_loss: 0.3632 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2640 - accuracy: 0.8430 - val_loss: 0.3631 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2671 - accuracy: 0.8306 - val_loss: 0.3634 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2819 - accuracy: 0.8306 - val_loss: 0.3626 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 142us/step - loss: 0.2645 - accuracy: 0.8430 - val_loss: 0.3618 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2781 - accuracy: 0.8471 - val_loss: 0.3623 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2615 - accuracy: 0.8554 - val_loss: 0.3627 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.3111 - accuracy: 0.8264 - val_loss: 0.3628 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.2621 - accuracy: 0.8678 - val_loss: 0.3628 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: 0.2891 - accuracy: 0.8182 - val_loss: 0.3625 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2727 - accuracy: 0.8512 - val_loss: 0.3626 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:50<00:35,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7039 - accuracy: 0.5331 - val_loss: 0.6608 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.6430 - accuracy: 0.5744 - val_loss: 0.6177 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 146us/step - loss: 0.5973 - accuracy: 0.6446 - val_loss: 0.5842 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.5477 - accuracy: 0.7107 - val_loss: 0.5505 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.4932 - accuracy: 0.7397 - val_loss: 0.5186 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.4997 - accuracy: 0.7851 - val_loss: 0.4907 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.4341 - accuracy: 0.8017 - val_loss: 0.4652 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.4460 - accuracy: 0.7686 - val_loss: 0.4418 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.4110 - accuracy: 0.8017 - val_loss: 0.4223 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.3681 - accuracy: 0.7975 - val_loss: 0.4046 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3361 - accuracy: 0.8471 - val_loss: 0.3865 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3441 - accuracy: 0.8058 - val_loss: 0.3719 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.3471 - accuracy: 0.8099 - val_loss: 0.3604 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.3259 - accuracy: 0.8099 - val_loss: 0.3564 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3179 - accuracy: 0.8140 - val_loss: 0.3524 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2993 - accuracy: 0.8347 - val_loss: 0.3497 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2900 - accuracy: 0.8430 - val_loss: 0.3483 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.2769 - accuracy: 0.8388 - val_loss: 0.3456 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.2671 - accuracy: 0.8719 - val_loss: 0.3407 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 137us/step - loss: 0.2970 - accuracy: 0.8471 - val_loss: 0.3388 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2792 - accuracy: 0.8388 - val_loss: 0.3362 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2802 - accuracy: 0.8430 - val_loss: 0.3314 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3281 - accuracy: 0.8140 - val_loss: 0.3309 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2558 - accuracy: 0.8512 - val_loss: 0.3318 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2745 - accuracy: 0.8471 - val_loss: 0.3303 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2691 - accuracy: 0.8760 - val_loss: 0.3292 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2674 - accuracy: 0.8636 - val_loss: 0.3300 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2806 - accuracy: 0.8388 - val_loss: 0.3296 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2295 - accuracy: 0.8760 - val_loss: 0.3279 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2428 - accuracy: 0.8843 - val_loss: 0.3284 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2596 - accuracy: 0.8430 - val_loss: 0.3258 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2440 - accuracy: 0.8636 - val_loss: 0.3277 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2368 - accuracy: 0.8636 - val_loss: 0.3285 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2209 - accuracy: 0.8719 - val_loss: 0.3281 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2666 - accuracy: 0.8678 - val_loss: 0.3230 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2873 - accuracy: 0.8760 - val_loss: 0.3257 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2527 - accuracy: 0.8678 - val_loss: 0.3300 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.2455 - accuracy: 0.8636 - val_loss: 0.3311 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2258 - accuracy: 0.8512 - val_loss: 0.3333 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2352 - accuracy: 0.8678 - val_loss: 0.3346 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2381 - accuracy: 0.8678 - val_loss: 0.3350 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2273 - accuracy: 0.8554 - val_loss: 0.3349 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.2335 - accuracy: 0.8636 - val_loss: 0.3345 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 156us/step - loss: 0.2304 - accuracy: 0.8967 - val_loss: 0.3350 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2282 - accuracy: 0.8802 - val_loss: 0.3362 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 164us/step - loss: 0.2442 - accuracy: 0.8554 - val_loss: 0.3369 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.2382 - accuracy: 0.8760 - val_loss: 0.3377 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2311 - accuracy: 0.8595 - val_loss: 0.3373 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2302 - accuracy: 0.8430 - val_loss: 0.3370 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2245 - accuracy: 0.8760 - val_loss: 0.3363 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 112us/step - loss: 0.2238 - accuracy: 0.8719 - val_loss: 0.3364 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 106us/step - loss: 0.2267 - accuracy: 0.8595 - val_loss: 0.3362 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 108us/step - loss: 0.2265 - accuracy: 0.8471 - val_loss: 0.3360 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2333 - accuracy: 0.8760 - val_loss: 0.3362 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2317 - accuracy: 0.8554 - val_loss: 0.3365 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2248 - accuracy: 0.8512 - val_loss: 0.3366 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2122 - accuracy: 0.8678 - val_loss: 0.3368 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2192 - accuracy: 0.8802 - val_loss: 0.3368 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2542 - accuracy: 0.8843 - val_loss: 0.3370 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2308 - accuracy: 0.8595 - val_loss: 0.3370 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:59<00:26,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.7651 - accuracy: 0.5083 - val_loss: 0.6391 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.6477 - accuracy: 0.6074 - val_loss: 0.5958 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.6521 - accuracy: 0.6446 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.5302 - accuracy: 0.7438 - val_loss: 0.5325 - val_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.5424 - accuracy: 0.7810 - val_loss: 0.5097 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.4897 - accuracy: 0.8017 - val_loss: 0.4884 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.5031 - accuracy: 0.7851 - val_loss: 0.4725 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.4744 - accuracy: 0.7810 - val_loss: 0.4545 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.4385 - accuracy: 0.8182 - val_loss: 0.4379 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3984 - accuracy: 0.8099 - val_loss: 0.4205 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.4031 - accuracy: 0.7934 - val_loss: 0.4067 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.3614 - accuracy: 0.8223 - val_loss: 0.3984 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.3649 - accuracy: 0.7893 - val_loss: 0.3915 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.3463 - accuracy: 0.8306 - val_loss: 0.3859 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.3207 - accuracy: 0.8223 - val_loss: 0.3833 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2931 - accuracy: 0.8306 - val_loss: 0.3807 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.3096 - accuracy: 0.8264 - val_loss: 0.3754 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 143us/step - loss: 0.3273 - accuracy: 0.8388 - val_loss: 0.3754 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 157us/step - loss: 0.3142 - accuracy: 0.8595 - val_loss: 0.3735 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 159us/step - loss: 0.2813 - accuracy: 0.8512 - val_loss: 0.3702 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 149us/step - loss: 0.3074 - accuracy: 0.8430 - val_loss: 0.3719 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.3194 - accuracy: 0.8430 - val_loss: 0.3713 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2860 - accuracy: 0.8471 - val_loss: 0.3715 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.2919 - accuracy: 0.8264 - val_loss: 0.3755 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 153us/step - loss: 0.3230 - accuracy: 0.8595 - val_loss: 0.3748 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.2825 - accuracy: 0.8512 - val_loss: 0.3730 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.2621 - accuracy: 0.8760 - val_loss: 0.3717 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.2770 - accuracy: 0.8512 - val_loss: 0.3714 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2776 - accuracy: 0.8636 - val_loss: 0.3733 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2845 - accuracy: 0.8388 - val_loss: 0.3723 - val_accuracy: 0.9000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2384 - accuracy: 0.8595 - val_loss: 0.3719 - val_accuracy: 0.9000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2574 - accuracy: 0.8595 - val_loss: 0.3722 - val_accuracy: 0.9000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2673 - accuracy: 0.8595 - val_loss: 0.3722 - val_accuracy: 0.9000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 114us/step - loss: 0.2448 - accuracy: 0.8636 - val_loss: 0.3725 - val_accuracy: 0.9000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2505 - accuracy: 0.8760 - val_loss: 0.3730 - val_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.3055 - accuracy: 0.8636 - val_loss: 0.3727 - val_accuracy: 0.9000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.2607 - accuracy: 0.8678 - val_loss: 0.3725 - val_accuracy: 0.9000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2501 - accuracy: 0.8802 - val_loss: 0.3724 - val_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2893 - accuracy: 0.8388 - val_loss: 0.3723 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2785 - accuracy: 0.8512 - val_loss: 0.3722 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2784 - accuracy: 0.8430 - val_loss: 0.3720 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2772 - accuracy: 0.8636 - val_loss: 0.3718 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2653 - accuracy: 0.8719 - val_loss: 0.3718 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2815 - accuracy: 0.8388 - val_loss: 0.3718 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2527 - accuracy: 0.8636 - val_loss: 0.3720 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:09<00:18,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6912 - accuracy: 0.5537 - val_loss: 0.6813 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.5961 - accuracy: 0.5826 - val_loss: 0.6514 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.5658 - accuracy: 0.6653 - val_loss: 0.6224 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.5785 - accuracy: 0.6570 - val_loss: 0.5967 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: 0.5148 - accuracy: 0.7149 - val_loss: 0.5668 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.5132 - accuracy: 0.6860 - val_loss: 0.5459 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.4639 - accuracy: 0.7645 - val_loss: 0.5230 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.4534 - accuracy: 0.7314 - val_loss: 0.5025 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.4055 - accuracy: 0.7438 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.4316 - accuracy: 0.7851 - val_loss: 0.4636 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.4012 - accuracy: 0.7603 - val_loss: 0.4478 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.3372 - accuracy: 0.8017 - val_loss: 0.4355 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3634 - accuracy: 0.7934 - val_loss: 0.4247 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3369 - accuracy: 0.8140 - val_loss: 0.4142 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3252 - accuracy: 0.8471 - val_loss: 0.4072 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3468 - accuracy: 0.8182 - val_loss: 0.4039 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.3185 - accuracy: 0.8099 - val_loss: 0.4034 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3069 - accuracy: 0.8347 - val_loss: 0.4038 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.3117 - accuracy: 0.8099 - val_loss: 0.4012 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2839 - accuracy: 0.8347 - val_loss: 0.3988 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2887 - accuracy: 0.8471 - val_loss: 0.3956 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2847 - accuracy: 0.8388 - val_loss: 0.3865 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2783 - accuracy: 0.8223 - val_loss: 0.3852 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 116us/step - loss: 0.2710 - accuracy: 0.8430 - val_loss: 0.3828 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2518 - accuracy: 0.8388 - val_loss: 0.3840 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: 0.2869 - accuracy: 0.8471 - val_loss: 0.3871 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2745 - accuracy: 0.8554 - val_loss: 0.3831 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.2553 - accuracy: 0.8223 - val_loss: 0.3834 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2535 - accuracy: 0.8760 - val_loss: 0.3832 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2572 - accuracy: 0.8471 - val_loss: 0.3793 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 133us/step - loss: 0.2457 - accuracy: 0.8595 - val_loss: 0.3780 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2746 - accuracy: 0.8595 - val_loss: 0.3753 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2569 - accuracy: 0.8471 - val_loss: 0.3738 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 141us/step - loss: 0.2946 - accuracy: 0.8264 - val_loss: 0.3752 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2425 - accuracy: 0.8512 - val_loss: 0.3748 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.2638 - accuracy: 0.8471 - val_loss: 0.3729 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2432 - accuracy: 0.8306 - val_loss: 0.3713 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.2435 - accuracy: 0.8802 - val_loss: 0.3710 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 139us/step - loss: 0.2415 - accuracy: 0.8471 - val_loss: 0.3717 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 123us/step - loss: 0.2350 - accuracy: 0.8843 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2784 - accuracy: 0.8471 - val_loss: 0.3728 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2441 - accuracy: 0.8471 - val_loss: 0.3723 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2537 - accuracy: 0.8636 - val_loss: 0.3756 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: 0.2180 - accuracy: 0.8802 - val_loss: 0.3751 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2621 - accuracy: 0.8347 - val_loss: 0.3740 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2643 - accuracy: 0.8595 - val_loss: 0.3735 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 160us/step - loss: 0.2528 - accuracy: 0.8306 - val_loss: 0.3737 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: 0.2704 - accuracy: 0.8430 - val_loss: 0.3749 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2304 - accuracy: 0.8471 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.2436 - accuracy: 0.8430 - val_loss: 0.3756 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.2370 - accuracy: 0.8636 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.2563 - accuracy: 0.8554 - val_loss: 0.3752 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2558 - accuracy: 0.8595 - val_loss: 0.3743 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2265 - accuracy: 0.8678 - val_loss: 0.3741 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2560 - accuracy: 0.8347 - val_loss: 0.3742 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2559 - accuracy: 0.8595 - val_loss: 0.3747 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 118us/step - loss: 0.2524 - accuracy: 0.8595 - val_loss: 0.3748 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2374 - accuracy: 0.8678 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 158us/step - loss: 0.2717 - accuracy: 0.8264 - val_loss: 0.3749 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: 0.2392 - accuracy: 0.8471 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 134us/step - loss: 0.2457 - accuracy: 0.8636 - val_loss: 0.3750 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 135us/step - loss: 0.2659 - accuracy: 0.8512 - val_loss: 0.3749 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 113us/step - loss: 0.2566 - accuracy: 0.8388 - val_loss: 0.3749 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:19<00:09,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6074 - accuracy: 0.6074 - val_loss: 0.6006 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 151us/step - loss: 0.5516 - accuracy: 0.6901 - val_loss: 0.5455 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.5108 - accuracy: 0.7355 - val_loss: 0.5049 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 162us/step - loss: 0.4574 - accuracy: 0.7603 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.4127 - accuracy: 0.8058 - val_loss: 0.4603 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.4511 - accuracy: 0.7893 - val_loss: 0.4417 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.3797 - accuracy: 0.7893 - val_loss: 0.4290 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.3467 - accuracy: 0.8388 - val_loss: 0.4176 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 117us/step - loss: 0.3344 - accuracy: 0.8140 - val_loss: 0.4080 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.3159 - accuracy: 0.8264 - val_loss: 0.4028 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 163us/step - loss: 0.3279 - accuracy: 0.8099 - val_loss: 0.4003 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 155us/step - loss: 0.3066 - accuracy: 0.8306 - val_loss: 0.3978 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 150us/step - loss: 0.3100 - accuracy: 0.8223 - val_loss: 0.3957 - val_accuracy: 0.7667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: 0.2760 - accuracy: 0.8471 - val_loss: 0.3932 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 121us/step - loss: 0.2936 - accuracy: 0.8264 - val_loss: 0.3905 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.2978 - accuracy: 0.8388 - val_loss: 0.3903 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 131us/step - loss: 0.2788 - accuracy: 0.8430 - val_loss: 0.3933 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2801 - accuracy: 0.8099 - val_loss: 0.3954 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 154us/step - loss: 0.2996 - accuracy: 0.8347 - val_loss: 0.3943 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 138us/step - loss: 0.2755 - accuracy: 0.8264 - val_loss: 0.3953 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2669 - accuracy: 0.8512 - val_loss: 0.3966 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2543 - accuracy: 0.8512 - val_loss: 0.3977 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 147us/step - loss: 0.2679 - accuracy: 0.8595 - val_loss: 0.3991 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 145us/step - loss: 0.2694 - accuracy: 0.8306 - val_loss: 0.3987 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2816 - accuracy: 0.8636 - val_loss: 0.3991 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2539 - accuracy: 0.8264 - val_loss: 0.4002 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.2581 - accuracy: 0.8554 - val_loss: 0.3996 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2527 - accuracy: 0.8512 - val_loss: 0.3990 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2503 - accuracy: 0.8760 - val_loss: 0.3997 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2528 - accuracy: 0.8306 - val_loss: 0.3998 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2534 - accuracy: 0.8430 - val_loss: 0.4007 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2768 - accuracy: 0.8306 - val_loss: 0.4006 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 130us/step - loss: 0.2763 - accuracy: 0.8347 - val_loss: 0.4008 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 129us/step - loss: 0.2587 - accuracy: 0.8430 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 125us/step - loss: 0.2486 - accuracy: 0.8512 - val_loss: 0.4000 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 127us/step - loss: 0.2313 - accuracy: 0.8636 - val_loss: 0.3997 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2596 - accuracy: 0.8388 - val_loss: 0.3998 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2343 - accuracy: 0.8471 - val_loss: 0.3997 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 126us/step - loss: 0.2719 - accuracy: 0.8512 - val_loss: 0.3998 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: 0.2657 - accuracy: 0.8471 - val_loss: 0.3997 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 122us/step - loss: 0.2428 - accuracy: 0.8760 - val_loss: 0.3998 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:28<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced ROC_value:  0.9342672413793104\n"
     ]
    }
   ],
   "source": [
    "nn_balanced = Ensemble(10)\n",
    "nn_balanced.print_summary()\n",
    "\n",
    "nn_balanced.fit(args_dict, wts_tr)\n",
    "roc_value = nn_balanced.validate_roc(X_oos, y_oos)\n",
    "print(\"Balanced ROC_value: \", roc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluating *both* neural nets on ages below 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced ROC_value:  0.9375\n",
      "Balanced ROC_value:  0.9299242424242424\n"
     ]
    }
   ],
   "source": [
    "## X_below & y_below defined at start of notebook\n",
    "\n",
    "roc_value_unbal = nn_unbalanced.validate_roc(X_below, y_below)\n",
    "print(\"Unbalanced ROC_value: \", roc_value_unbal)\n",
    "\n",
    "roc_value_bal = nn_balanced.validate_roc(X_below, y_below)\n",
    "print(\"Balanced ROC_value: \", roc_value_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unbalanced model's performance *decreases* for ages < 60, but the balanced model's performance **improves** for that age group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway from part 1\n",
    "\n",
    "Continuous weight-balancing improves performance for underrepresented groups across _all_ 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part - 2: Is CWB improve performance over *discretely* binned weights? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete weight generation\n",
    "\n",
    "**Goal**: generate sample weights; finite set of weights over training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights by decade:\n",
      "{'20s': 40.333333333333336,\n",
      " '30s': 3.361111111111111,\n",
      " '40s': 0.6402116402116402,\n",
      " '50s': 0.4432234432234432,\n",
      " '60s': 0.6019900497512438,\n",
      " '70s': 5.041666666666667}\n"
     ]
    }
   ],
   "source": [
    "## Bin ages in 10-yr-wide bins ##\n",
    "\n",
    "decades = (traits_train / 10).astype(int) #decade of each age sample\n",
    "unique_decades = np.unique(decades, return_counts=False)\n",
    "\n",
    "# traits are age corresponding to each training sample\n",
    "bin_wts = compute_class_weight('balanced', classes=unique_decades, y=decades)\n",
    "\n",
    "## Weights by decade\n",
    "print('Weights by decade:')\n",
    "pprint(dict(zip(['20s', '30s', '40s', '50s', '60s', '70s'], bin_wts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts_disc = np.take(bin_wts, decades - decades.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(traits_train[:10], wts_disc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: duplicate weights assigned to the multiple samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44322344 0.44322344 0.44322344 0.44322344 5.04166667 0.44322344\n",
      " 0.64021164 0.44322344 0.44322344 0.44322344] [0.52287923 0.52906655 0.52287923 0.53618597 2.29499022 0.52287923\n",
      " 0.78142046 0.53618597 0.58936399 0.58936399]\n"
     ]
    }
   ],
   "source": [
    "## Compare this to continuous weights\n",
    "print(wts_disc[:10], wts_tr[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete weight balancing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value on unbalanced data:  0.931573275862069\n"
     ]
    }
   ],
   "source": [
    "clf_disc = RandomForestClassifier(n_estimators=100, random_state=SEED).fit(X_train, y_train, sample_weight=wts_disc)\n",
    "roc_disc = roc_sklearn_model(clf_disc, X_oos, y_oos)\n",
    "print(\"ROC value on unbalanced data: \", roc_disc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous weight balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value on balanced data:  0.9401939655172414\n"
     ]
    }
   ],
   "source": [
    "clf_cont = RandomForestClassifier(n_estimators=100, random_state=SEED).fit(X_train, y_train, sample_weight=wts_tr)\n",
    "roc_cont = roc_sklearn_model(clf_cont, X_oos, y_oos)\n",
    "print(\"ROC value on balanced data: \", roc_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on ages below 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete ROC_value:  0.9592803030303031\n",
      "Continuous ROC_value:  0.9602272727272727\n"
     ]
    }
   ],
   "source": [
    "## X_below & y_below defined at start of notebook\n",
    "\n",
    "rf_probs = clf_disc.predict_proba(X_below)[:, 1]\n",
    "roc_value = roc_auc_score(y_below, rf_probs)\n",
    "print(\"Discrete ROC_value: \", roc_value)\n",
    "\n",
    "rf_probs_bal = clf_cont.predict_proba(X_below)[:, 1]\n",
    "roc_value_bal = roc_auc_score(y_below, rf_probs_bal)\n",
    "print(\"Continuous ROC_value: \", roc_value_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Both models perform aboutthe same on the OOS set, but the model trained on balanced data outperforms on a dataset limiited to subjects < 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "#### Discrete Weight Balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value discrete wts:  0.9267241379310345\n"
     ]
    }
   ],
   "source": [
    "clf_disc = LogisticRegression(random_state=SEED).fit(X_train, y_train, sample_weight=wts_disc)\n",
    "roc_disc = roc_sklearn_model(clf_disc, X_oos, y_oos)\n",
    "print(\"ROC value discrete wts: \", roc_disc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC value for cont wts:  0.9267241379310345\n"
     ]
    }
   ],
   "source": [
    "clf_cont = LogisticRegression(random_state=SEED).fit(X_train, y_train, sample_weight=wts_tr)\n",
    "roc_cont = roc_sklearn_model(clf_cont, X_oos, y_oos)\n",
    "print(\"ROC value for cont wts: \", roc_cont) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on ages below 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disc ROC value:  0.9223484848484849\n",
      "Cont ROC value:  0.9242424242424243\n"
     ]
    }
   ],
   "source": [
    "## X_below & y_below defined at start of notebook\n",
    "\n",
    "rf_probs = clf_disc.predict_proba(X_below)[:, 1]\n",
    "roc_value = roc_auc_score(y_below, rf_probs)\n",
    "print(\"Disc ROC value: \", roc_value)\n",
    "\n",
    "rf_probs_bal = clf_cont.predict_proba(X_below)[:, 1]\n",
    "roc_value_bal = roc_auc_score(y_below, rf_probs_bal)\n",
    "print(\"Cont ROC value: \", roc_value_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balanced model does slightly worse, but the difference is *within* 0.2 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First training with discrete weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_341 (Dense)            (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,953\n",
      "Trainable params: 1,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.7817 - accuracy: 0.5785 - val_loss: 0.5640 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 255us/step - loss: 0.5700 - accuracy: 0.7107 - val_loss: 0.5202 - val_accuracy: 0.8667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.5013 - accuracy: 0.7149 - val_loss: 0.4884 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.5202 - accuracy: 0.6983 - val_loss: 0.4604 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.3887 - accuracy: 0.7934 - val_loss: 0.4362 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.3973 - accuracy: 0.8099 - val_loss: 0.4166 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.4717 - accuracy: 0.7893 - val_loss: 0.4037 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.3935 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.3335 - accuracy: 0.7851 - val_loss: 0.3840 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 248us/step - loss: 0.3338 - accuracy: 0.7769 - val_loss: 0.3801 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2900 - accuracy: 0.7893 - val_loss: 0.3712 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.3269 - accuracy: 0.8347 - val_loss: 0.3629 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2796 - accuracy: 0.8140 - val_loss: 0.3597 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2725 - accuracy: 0.8182 - val_loss: 0.3587 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2412 - accuracy: 0.8471 - val_loss: 0.3526 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 259us/step - loss: 0.2550 - accuracy: 0.8182 - val_loss: 0.3507 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2683 - accuracy: 0.8264 - val_loss: 0.3494 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2614 - accuracy: 0.8140 - val_loss: 0.3471 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.2287 - accuracy: 0.8430 - val_loss: 0.3455 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2487 - accuracy: 0.8264 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2204 - accuracy: 0.8430 - val_loss: 0.3433 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2525 - accuracy: 0.8182 - val_loss: 0.3451 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2511 - accuracy: 0.8512 - val_loss: 0.3465 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.2081 - accuracy: 0.8306 - val_loss: 0.3483 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2376 - accuracy: 0.8347 - val_loss: 0.3492 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2456 - accuracy: 0.8430 - val_loss: 0.3440 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2279 - accuracy: 0.8471 - val_loss: 0.3443 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2388 - accuracy: 0.8223 - val_loss: 0.3458 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2461 - accuracy: 0.8512 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2607 - accuracy: 0.8182 - val_loss: 0.3415 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2329 - accuracy: 0.8347 - val_loss: 0.3409 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2151 - accuracy: 0.8678 - val_loss: 0.3390 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2255 - accuracy: 0.8347 - val_loss: 0.3403 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2338 - accuracy: 0.8471 - val_loss: 0.3403 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2342 - accuracy: 0.8636 - val_loss: 0.3393 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2202 - accuracy: 0.8636 - val_loss: 0.3385 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.2208 - accuracy: 0.8554 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.2081 - accuracy: 0.8802 - val_loss: 0.3410 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.1970 - accuracy: 0.8802 - val_loss: 0.3404 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2149 - accuracy: 0.8595 - val_loss: 0.3406 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2277 - accuracy: 0.8678 - val_loss: 0.3403 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2158 - accuracy: 0.8595 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2293 - accuracy: 0.8554 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2353 - accuracy: 0.8678 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2137 - accuracy: 0.8636 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2061 - accuracy: 0.8760 - val_loss: 0.3414 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2150 - accuracy: 0.8554 - val_loss: 0.3415 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2209 - accuracy: 0.8636 - val_loss: 0.3417 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.2128 - accuracy: 0.8554 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2288 - accuracy: 0.8595 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2193 - accuracy: 0.8595 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2466 - accuracy: 0.8388 - val_loss: 0.3422 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2045 - accuracy: 0.8636 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.1998 - accuracy: 0.8678 - val_loss: 0.3422 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2159 - accuracy: 0.8430 - val_loss: 0.3422 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2241 - accuracy: 0.8347 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2132 - accuracy: 0.8636 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.2280 - accuracy: 0.8636 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.2181 - accuracy: 0.8512 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 258us/step - loss: 0.2058 - accuracy: 0.8678 - val_loss: 0.3424 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.1976 - accuracy: 0.8636 - val_loss: 0.3425 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:38<05:50, 38.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.7248 - accuracy: 0.5537 - val_loss: 0.6922 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 258us/step - loss: 0.6372 - accuracy: 0.6570 - val_loss: 0.6250 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 255us/step - loss: 0.5131 - accuracy: 0.7149 - val_loss: 0.5706 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.5410 - accuracy: 0.7769 - val_loss: 0.5327 - val_accuracy: 0.7333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.4218 - accuracy: 0.7727 - val_loss: 0.4968 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.4087 - accuracy: 0.7851 - val_loss: 0.4739 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.3917 - accuracy: 0.7810 - val_loss: 0.4547 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.3701 - accuracy: 0.8388 - val_loss: 0.4365 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.3290 - accuracy: 0.8017 - val_loss: 0.4294 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3067 - accuracy: 0.8388 - val_loss: 0.4211 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.3130 - accuracy: 0.7893 - val_loss: 0.4156 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2927 - accuracy: 0.8512 - val_loss: 0.4068 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2707 - accuracy: 0.8099 - val_loss: 0.3997 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2877 - accuracy: 0.8099 - val_loss: 0.3955 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2408 - accuracy: 0.8430 - val_loss: 0.3944 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 191us/step - loss: 0.2926 - accuracy: 0.8223 - val_loss: 0.3982 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 196us/step - loss: 0.2820 - accuracy: 0.8306 - val_loss: 0.3976 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2660 - accuracy: 0.8058 - val_loss: 0.3988 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2528 - accuracy: 0.8347 - val_loss: 0.4000 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2692 - accuracy: 0.8306 - val_loss: 0.4026 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2640 - accuracy: 0.8264 - val_loss: 0.4051 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2365 - accuracy: 0.8512 - val_loss: 0.4049 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2381 - accuracy: 0.8223 - val_loss: 0.4057 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2437 - accuracy: 0.8306 - val_loss: 0.4070 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2126 - accuracy: 0.8388 - val_loss: 0.4090 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.1990 - accuracy: 0.8388 - val_loss: 0.4098 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2369 - accuracy: 0.8554 - val_loss: 0.4099 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2444 - accuracy: 0.8388 - val_loss: 0.4094 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2449 - accuracy: 0.8223 - val_loss: 0.4088 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 237us/step - loss: 0.2410 - accuracy: 0.8595 - val_loss: 0.4080 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 191us/step - loss: 0.2196 - accuracy: 0.8636 - val_loss: 0.4074 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2193 - accuracy: 0.8595 - val_loss: 0.4077 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2152 - accuracy: 0.8430 - val_loss: 0.4078 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2436 - accuracy: 0.8347 - val_loss: 0.4072 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2215 - accuracy: 0.8678 - val_loss: 0.4075 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2043 - accuracy: 0.8347 - val_loss: 0.4077 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2142 - accuracy: 0.8595 - val_loss: 0.4077 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2375 - accuracy: 0.8595 - val_loss: 0.4078 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.2164 - accuracy: 0.8471 - val_loss: 0.4078 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2355 - accuracy: 0.8347 - val_loss: 0.4083 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:15<04:58, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.8261 - accuracy: 0.5083 - val_loss: 0.6837 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.5989 - accuracy: 0.6446 - val_loss: 0.6215 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.4924 - accuracy: 0.6653 - val_loss: 0.5803 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.5225 - accuracy: 0.7066 - val_loss: 0.5470 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.4264 - accuracy: 0.7603 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.3734 - accuracy: 0.7645 - val_loss: 0.4909 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.3713 - accuracy: 0.7603 - val_loss: 0.4672 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3953 - accuracy: 0.8182 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.3483 - accuracy: 0.8306 - val_loss: 0.4399 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.3313 - accuracy: 0.8140 - val_loss: 0.4261 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2854 - accuracy: 0.8223 - val_loss: 0.4185 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 240us/step - loss: 0.2880 - accuracy: 0.8140 - val_loss: 0.4135 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2801 - accuracy: 0.8099 - val_loss: 0.4093 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.3101 - accuracy: 0.8182 - val_loss: 0.4067 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2501 - accuracy: 0.8223 - val_loss: 0.4036 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.2428 - accuracy: 0.8140 - val_loss: 0.4017 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2970 - accuracy: 0.8223 - val_loss: 0.4012 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2549 - accuracy: 0.8099 - val_loss: 0.3981 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2720 - accuracy: 0.8140 - val_loss: 0.3987 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2642 - accuracy: 0.8471 - val_loss: 0.4032 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2417 - accuracy: 0.8264 - val_loss: 0.4075 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2456 - accuracy: 0.8347 - val_loss: 0.4109 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 167us/step - loss: 0.2324 - accuracy: 0.8388 - val_loss: 0.4148 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 281us/step - loss: 0.2455 - accuracy: 0.8388 - val_loss: 0.4176 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2409 - accuracy: 0.8182 - val_loss: 0.4190 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2531 - accuracy: 0.8347 - val_loss: 0.4177 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2274 - accuracy: 0.8430 - val_loss: 0.4185 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2336 - accuracy: 0.8306 - val_loss: 0.4182 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.2490 - accuracy: 0.8306 - val_loss: 0.4178 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.2172 - accuracy: 0.8512 - val_loss: 0.4191 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2346 - accuracy: 0.8306 - val_loss: 0.4193 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2295 - accuracy: 0.8595 - val_loss: 0.4190 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2457 - accuracy: 0.8471 - val_loss: 0.4190 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2184 - accuracy: 0.8719 - val_loss: 0.4197 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2377 - accuracy: 0.8388 - val_loss: 0.4195 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2342 - accuracy: 0.8306 - val_loss: 0.4194 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2423 - accuracy: 0.8223 - val_loss: 0.4192 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2460 - accuracy: 0.8347 - val_loss: 0.4193 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2245 - accuracy: 0.8471 - val_loss: 0.4191 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2321 - accuracy: 0.8471 - val_loss: 0.4188 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2339 - accuracy: 0.8264 - val_loss: 0.4188 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2409 - accuracy: 0.8430 - val_loss: 0.4188 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2405 - accuracy: 0.8388 - val_loss: 0.4188 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:52<04:21, 37.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.7011 - accuracy: 0.5372 - val_loss: 0.6258 - val_accuracy: 0.7333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.6120 - accuracy: 0.6653 - val_loss: 0.5667 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.4741 - accuracy: 0.7355 - val_loss: 0.5156 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.4370 - accuracy: 0.7479 - val_loss: 0.4787 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.4891 - accuracy: 0.7355 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.3998 - accuracy: 0.7521 - val_loss: 0.4473 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.3618 - accuracy: 0.7810 - val_loss: 0.4302 - val_accuracy: 0.7333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3504 - accuracy: 0.7810 - val_loss: 0.4227 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.3232 - accuracy: 0.7893 - val_loss: 0.4134 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.3164 - accuracy: 0.7769 - val_loss: 0.4080 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2949 - accuracy: 0.8140 - val_loss: 0.4086 - val_accuracy: 0.7667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.3037 - accuracy: 0.8058 - val_loss: 0.4054 - val_accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2936 - accuracy: 0.8223 - val_loss: 0.4030 - val_accuracy: 0.7667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.2856 - accuracy: 0.8099 - val_loss: 0.4044 - val_accuracy: 0.7667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2907 - accuracy: 0.8058 - val_loss: 0.4039 - val_accuracy: 0.7667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2695 - accuracy: 0.8223 - val_loss: 0.4071 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2792 - accuracy: 0.7934 - val_loss: 0.4048 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 196us/step - loss: 0.2731 - accuracy: 0.8017 - val_loss: 0.4052 - val_accuracy: 0.7667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2644 - accuracy: 0.8058 - val_loss: 0.4072 - val_accuracy: 0.7333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2475 - accuracy: 0.8140 - val_loss: 0.4091 - val_accuracy: 0.7333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 248us/step - loss: 0.2554 - accuracy: 0.8099 - val_loss: 0.4119 - val_accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2462 - accuracy: 0.8099 - val_loss: 0.4127 - val_accuracy: 0.7333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2862 - accuracy: 0.7975 - val_loss: 0.4140 - val_accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2378 - accuracy: 0.8636 - val_loss: 0.4135 - val_accuracy: 0.7333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2512 - accuracy: 0.8017 - val_loss: 0.4147 - val_accuracy: 0.7333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2719 - accuracy: 0.8512 - val_loss: 0.4147 - val_accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2743 - accuracy: 0.8182 - val_loss: 0.4136 - val_accuracy: 0.7333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2433 - accuracy: 0.8058 - val_loss: 0.4134 - val_accuracy: 0.7333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2665 - accuracy: 0.8264 - val_loss: 0.4133 - val_accuracy: 0.7333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2579 - accuracy: 0.8595 - val_loss: 0.4148 - val_accuracy: 0.7667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2390 - accuracy: 0.8182 - val_loss: 0.4153 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2271 - accuracy: 0.8306 - val_loss: 0.4153 - val_accuracy: 0.7667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2539 - accuracy: 0.8595 - val_loss: 0.4150 - val_accuracy: 0.7667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2267 - accuracy: 0.8554 - val_loss: 0.4147 - val_accuracy: 0.7667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2529 - accuracy: 0.8347 - val_loss: 0.4147 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2379 - accuracy: 0.8306 - val_loss: 0.4148 - val_accuracy: 0.7667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2191 - accuracy: 0.8264 - val_loss: 0.4147 - val_accuracy: 0.7667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2519 - accuracy: 0.8264 - val_loss: 0.4144 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:29<03:44, 37.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.6858 - accuracy: 0.6281 - val_loss: 0.6278 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.5872 - accuracy: 0.6942 - val_loss: 0.5955 - val_accuracy: 0.6333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.4896 - accuracy: 0.7397 - val_loss: 0.5636 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.4952 - accuracy: 0.7562 - val_loss: 0.5350 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.4273 - accuracy: 0.7355 - val_loss: 0.5091 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.4032 - accuracy: 0.8058 - val_loss: 0.4875 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.3816 - accuracy: 0.7934 - val_loss: 0.4661 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3921 - accuracy: 0.7975 - val_loss: 0.4500 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.3473 - accuracy: 0.7810 - val_loss: 0.4331 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2952 - accuracy: 0.8140 - val_loss: 0.4212 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2818 - accuracy: 0.8347 - val_loss: 0.4163 - val_accuracy: 0.7667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2962 - accuracy: 0.8347 - val_loss: 0.4088 - val_accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2674 - accuracy: 0.8347 - val_loss: 0.4066 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.2775 - accuracy: 0.8264 - val_loss: 0.4030 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.2679 - accuracy: 0.8388 - val_loss: 0.4040 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2874 - accuracy: 0.8223 - val_loss: 0.4015 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2595 - accuracy: 0.8182 - val_loss: 0.3995 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2707 - accuracy: 0.8182 - val_loss: 0.4021 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2397 - accuracy: 0.8347 - val_loss: 0.4072 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2471 - accuracy: 0.8388 - val_loss: 0.4048 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2370 - accuracy: 0.8430 - val_loss: 0.4080 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2242 - accuracy: 0.8140 - val_loss: 0.4061 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2274 - accuracy: 0.8554 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.2122 - accuracy: 0.8595 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.2475 - accuracy: 0.8430 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2361 - accuracy: 0.8140 - val_loss: 0.4027 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2276 - accuracy: 0.8512 - val_loss: 0.3981 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2264 - accuracy: 0.8512 - val_loss: 0.3990 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2346 - accuracy: 0.8512 - val_loss: 0.3977 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2474 - accuracy: 0.8388 - val_loss: 0.3957 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2226 - accuracy: 0.8512 - val_loss: 0.3939 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2197 - accuracy: 0.8719 - val_loss: 0.3928 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2429 - accuracy: 0.8512 - val_loss: 0.3920 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.2313 - accuracy: 0.8471 - val_loss: 0.3925 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2212 - accuracy: 0.8512 - val_loss: 0.3930 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.2107 - accuracy: 0.8595 - val_loss: 0.3913 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2057 - accuracy: 0.8223 - val_loss: 0.3926 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.1931 - accuracy: 0.8471 - val_loss: 0.3930 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.1969 - accuracy: 0.8595 - val_loss: 0.3926 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2140 - accuracy: 0.8595 - val_loss: 0.3921 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2272 - accuracy: 0.8554 - val_loss: 0.3927 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2185 - accuracy: 0.8471 - val_loss: 0.3933 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2232 - accuracy: 0.8471 - val_loss: 0.3923 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.2101 - accuracy: 0.8636 - val_loss: 0.3910 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2105 - accuracy: 0.8636 - val_loss: 0.3910 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2044 - accuracy: 0.8430 - val_loss: 0.3915 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.2257 - accuracy: 0.8471 - val_loss: 0.3919 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.2199 - accuracy: 0.8719 - val_loss: 0.3909 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2256 - accuracy: 0.8512 - val_loss: 0.3919 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2154 - accuracy: 0.8512 - val_loss: 0.3927 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2084 - accuracy: 0.8430 - val_loss: 0.3924 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2484 - accuracy: 0.8471 - val_loss: 0.3912 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2074 - accuracy: 0.8554 - val_loss: 0.3887 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2108 - accuracy: 0.8636 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2130 - accuracy: 0.8512 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2034 - accuracy: 0.8512 - val_loss: 0.3877 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.2355 - accuracy: 0.8719 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.2003 - accuracy: 0.8512 - val_loss: 0.3862 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.1966 - accuracy: 0.8512 - val_loss: 0.3863 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.1989 - accuracy: 0.8554 - val_loss: 0.3863 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2076 - accuracy: 0.8430 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2223 - accuracy: 0.8512 - val_loss: 0.3862 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.1924 - accuracy: 0.8843 - val_loss: 0.3856 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.1984 - accuracy: 0.8554 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2049 - accuracy: 0.8430 - val_loss: 0.3853 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.1939 - accuracy: 0.8678 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2254 - accuracy: 0.8430 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2349 - accuracy: 0.8636 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.1961 - accuracy: 0.8512 - val_loss: 0.3851 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2073 - accuracy: 0.8554 - val_loss: 0.3853 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2071 - accuracy: 0.8512 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2267 - accuracy: 0.8554 - val_loss: 0.3855 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.1878 - accuracy: 0.8719 - val_loss: 0.3866 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2034 - accuracy: 0.8554 - val_loss: 0.3879 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2050 - accuracy: 0.8678 - val_loss: 0.3879 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.2089 - accuracy: 0.8843 - val_loss: 0.3876 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.1865 - accuracy: 0.8595 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2044 - accuracy: 0.8760 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2004 - accuracy: 0.8719 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.1989 - accuracy: 0.8678 - val_loss: 0.3881 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2126 - accuracy: 0.8430 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.1941 - accuracy: 0.8843 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2034 - accuracy: 0.8554 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2163 - accuracy: 0.8760 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.1998 - accuracy: 0.8512 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2232 - accuracy: 0.8347 - val_loss: 0.3883 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.2199 - accuracy: 0.8554 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.2430 - accuracy: 0.8430 - val_loss: 0.3882 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2430 - accuracy: 0.8512 - val_loss: 0.3881 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2122 - accuracy: 0.8719 - val_loss: 0.3881 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.1947 - accuracy: 0.8430 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.1929 - accuracy: 0.8430 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2292 - accuracy: 0.8595 - val_loss: 0.3880 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2135 - accuracy: 0.8595 - val_loss: 0.3880 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [03:10<03:12, 38.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.7521 - accuracy: 0.5537 - val_loss: 0.7338 - val_accuracy: 0.4333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 277us/step - loss: 0.5848 - accuracy: 0.6116 - val_loss: 0.6711 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.4987 - accuracy: 0.6860 - val_loss: 0.6127 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.5362 - accuracy: 0.7066 - val_loss: 0.5627 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.4630 - accuracy: 0.7107 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.4235 - accuracy: 0.7273 - val_loss: 0.4986 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3796 - accuracy: 0.7355 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 191us/step - loss: 0.3886 - accuracy: 0.7810 - val_loss: 0.4536 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3559 - accuracy: 0.7562 - val_loss: 0.4353 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.3470 - accuracy: 0.7686 - val_loss: 0.4195 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.3357 - accuracy: 0.7975 - val_loss: 0.4021 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.3162 - accuracy: 0.7851 - val_loss: 0.3899 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.3075 - accuracy: 0.8058 - val_loss: 0.3832 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2820 - accuracy: 0.8223 - val_loss: 0.3746 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2715 - accuracy: 0.8223 - val_loss: 0.3701 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2826 - accuracy: 0.8140 - val_loss: 0.3681 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3068 - accuracy: 0.8223 - val_loss: 0.3660 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.3016 - accuracy: 0.7975 - val_loss: 0.3644 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2670 - accuracy: 0.8058 - val_loss: 0.3610 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2637 - accuracy: 0.8512 - val_loss: 0.3577 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2668 - accuracy: 0.8058 - val_loss: 0.3569 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2809 - accuracy: 0.8306 - val_loss: 0.3544 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2612 - accuracy: 0.8264 - val_loss: 0.3518 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.2388 - accuracy: 0.8430 - val_loss: 0.3499 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 247us/step - loss: 0.2395 - accuracy: 0.8430 - val_loss: 0.3486 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2519 - accuracy: 0.8430 - val_loss: 0.3486 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 242us/step - loss: 0.2490 - accuracy: 0.8264 - val_loss: 0.3487 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2078 - accuracy: 0.8636 - val_loss: 0.3492 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2394 - accuracy: 0.8223 - val_loss: 0.3509 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2494 - accuracy: 0.8388 - val_loss: 0.3484 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.2237 - accuracy: 0.8264 - val_loss: 0.3494 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2330 - accuracy: 0.8471 - val_loss: 0.3524 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2226 - accuracy: 0.8430 - val_loss: 0.3522 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.2466 - accuracy: 0.8347 - val_loss: 0.3529 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2064 - accuracy: 0.8388 - val_loss: 0.3541 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 191us/step - loss: 0.2540 - accuracy: 0.8223 - val_loss: 0.3571 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2022 - accuracy: 0.8678 - val_loss: 0.3570 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2121 - accuracy: 0.8430 - val_loss: 0.3565 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2453 - accuracy: 0.8347 - val_loss: 0.3573 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2256 - accuracy: 0.8554 - val_loss: 0.3582 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2326 - accuracy: 0.8512 - val_loss: 0.3586 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2302 - accuracy: 0.8430 - val_loss: 0.3576 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2132 - accuracy: 0.8430 - val_loss: 0.3570 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.2484 - accuracy: 0.8554 - val_loss: 0.3582 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.2121 - accuracy: 0.8388 - val_loss: 0.3584 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2186 - accuracy: 0.8347 - val_loss: 0.3586 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2092 - accuracy: 0.8512 - val_loss: 0.3587 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2338 - accuracy: 0.8430 - val_loss: 0.3587 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.2336 - accuracy: 0.8471 - val_loss: 0.3577 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.2055 - accuracy: 0.8595 - val_loss: 0.3573 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.1904 - accuracy: 0.8595 - val_loss: 0.3575 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2118 - accuracy: 0.8554 - val_loss: 0.3575 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2376 - accuracy: 0.8471 - val_loss: 0.3575 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2125 - accuracy: 0.8471 - val_loss: 0.3576 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2120 - accuracy: 0.8388 - val_loss: 0.3573 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:49<02:34, 38.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.7197 - accuracy: 0.4711 - val_loss: 0.6284 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.6853 - accuracy: 0.5785 - val_loss: 0.5859 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.5467 - accuracy: 0.6488 - val_loss: 0.5583 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.5679 - accuracy: 0.6446 - val_loss: 0.5336 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 180us/step - loss: 0.5062 - accuracy: 0.7107 - val_loss: 0.5099 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.4147 - accuracy: 0.7727 - val_loss: 0.4902 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.4040 - accuracy: 0.7645 - val_loss: 0.4740 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.4078 - accuracy: 0.7603 - val_loss: 0.4584 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 264us/step - loss: 0.4114 - accuracy: 0.8099 - val_loss: 0.4426 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3805 - accuracy: 0.8099 - val_loss: 0.4308 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3357 - accuracy: 0.8058 - val_loss: 0.4230 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.3341 - accuracy: 0.8017 - val_loss: 0.4143 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.3070 - accuracy: 0.8058 - val_loss: 0.4083 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2761 - accuracy: 0.8388 - val_loss: 0.4053 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2964 - accuracy: 0.8140 - val_loss: 0.4026 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2955 - accuracy: 0.8140 - val_loss: 0.4025 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2899 - accuracy: 0.8058 - val_loss: 0.4037 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2765 - accuracy: 0.8223 - val_loss: 0.4017 - val_accuracy: 0.7667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2544 - accuracy: 0.8512 - val_loss: 0.3958 - val_accuracy: 0.7667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2369 - accuracy: 0.8430 - val_loss: 0.3948 - val_accuracy: 0.7667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2312 - accuracy: 0.8388 - val_loss: 0.3957 - val_accuracy: 0.7667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2572 - accuracy: 0.8306 - val_loss: 0.3921 - val_accuracy: 0.7667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.2511 - accuracy: 0.8140 - val_loss: 0.3922 - val_accuracy: 0.7667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.2822 - accuracy: 0.8058 - val_loss: 0.3931 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2399 - accuracy: 0.8347 - val_loss: 0.3923 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2335 - accuracy: 0.8554 - val_loss: 0.3929 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 237us/step - loss: 0.2390 - accuracy: 0.8223 - val_loss: 0.3977 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2496 - accuracy: 0.8636 - val_loss: 0.3992 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2321 - accuracy: 0.8430 - val_loss: 0.3989 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.2240 - accuracy: 0.8595 - val_loss: 0.3983 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.2548 - accuracy: 0.8223 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2295 - accuracy: 0.8347 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 191us/step - loss: 0.2431 - accuracy: 0.8223 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.2548 - accuracy: 0.8347 - val_loss: 0.4001 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2125 - accuracy: 0.8554 - val_loss: 0.4002 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2329 - accuracy: 0.8512 - val_loss: 0.3996 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2364 - accuracy: 0.8636 - val_loss: 0.3995 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2396 - accuracy: 0.8430 - val_loss: 0.3999 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2414 - accuracy: 0.8388 - val_loss: 0.4000 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2306 - accuracy: 0.8512 - val_loss: 0.4000 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2483 - accuracy: 0.8388 - val_loss: 0.4003 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2351 - accuracy: 0.8430 - val_loss: 0.4005 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2269 - accuracy: 0.8306 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.2305 - accuracy: 0.8430 - val_loss: 0.4002 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2182 - accuracy: 0.8306 - val_loss: 0.4001 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2334 - accuracy: 0.8388 - val_loss: 0.4003 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2154 - accuracy: 0.8595 - val_loss: 0.4003 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [04:29<01:57, 39.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 14ms/step - loss: 0.6627 - accuracy: 0.5620 - val_loss: 0.6752 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 196us/step - loss: 0.6536 - accuracy: 0.6281 - val_loss: 0.6196 - val_accuracy: 0.6333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 178us/step - loss: 0.5782 - accuracy: 0.6116 - val_loss: 0.5791 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.5024 - accuracy: 0.6860 - val_loss: 0.5428 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.4536 - accuracy: 0.7025 - val_loss: 0.5136 - val_accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.3988 - accuracy: 0.7314 - val_loss: 0.4916 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.3993 - accuracy: 0.7479 - val_loss: 0.4743 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.3814 - accuracy: 0.7727 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.3493 - accuracy: 0.7975 - val_loss: 0.4328 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.3323 - accuracy: 0.8058 - val_loss: 0.4212 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.3232 - accuracy: 0.7934 - val_loss: 0.4118 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2963 - accuracy: 0.8306 - val_loss: 0.3985 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.3109 - accuracy: 0.7893 - val_loss: 0.3896 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2693 - accuracy: 0.8347 - val_loss: 0.3817 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2754 - accuracy: 0.8140 - val_loss: 0.3759 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2613 - accuracy: 0.8017 - val_loss: 0.3687 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2906 - accuracy: 0.8099 - val_loss: 0.3657 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2662 - accuracy: 0.8140 - val_loss: 0.3627 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 242us/step - loss: 0.2332 - accuracy: 0.8512 - val_loss: 0.3615 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2255 - accuracy: 0.8512 - val_loss: 0.3597 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2495 - accuracy: 0.8264 - val_loss: 0.3624 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2418 - accuracy: 0.8636 - val_loss: 0.3630 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2218 - accuracy: 0.8388 - val_loss: 0.3634 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2330 - accuracy: 0.8264 - val_loss: 0.3687 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2346 - accuracy: 0.8347 - val_loss: 0.3709 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.2231 - accuracy: 0.8471 - val_loss: 0.3716 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2182 - accuracy: 0.8430 - val_loss: 0.3726 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.1967 - accuracy: 0.8719 - val_loss: 0.3764 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2202 - accuracy: 0.8306 - val_loss: 0.3743 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 179us/step - loss: 0.2256 - accuracy: 0.8264 - val_loss: 0.3729 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2120 - accuracy: 0.8595 - val_loss: 0.3732 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2321 - accuracy: 0.8223 - val_loss: 0.3730 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2162 - accuracy: 0.8802 - val_loss: 0.3726 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2238 - accuracy: 0.8512 - val_loss: 0.3724 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2303 - accuracy: 0.8388 - val_loss: 0.3720 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2211 - accuracy: 0.8512 - val_loss: 0.3727 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2357 - accuracy: 0.8264 - val_loss: 0.3729 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 171us/step - loss: 0.2130 - accuracy: 0.8388 - val_loss: 0.3725 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2591 - accuracy: 0.8430 - val_loss: 0.3728 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 166us/step - loss: 0.2073 - accuracy: 0.8347 - val_loss: 0.3724 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2193 - accuracy: 0.8471 - val_loss: 0.3722 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2136 - accuracy: 0.8512 - val_loss: 0.3720 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2111 - accuracy: 0.8264 - val_loss: 0.3719 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.2252 - accuracy: 0.8471 - val_loss: 0.3719 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2227 - accuracy: 0.8388 - val_loss: 0.3717 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [05:09<01:18, 39.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 14ms/step - loss: 0.5720 - accuracy: 0.6405 - val_loss: 0.6029 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.4947 - accuracy: 0.6901 - val_loss: 0.5633 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 182us/step - loss: 0.4700 - accuracy: 0.7521 - val_loss: 0.5350 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 250us/step - loss: 0.4714 - accuracy: 0.7355 - val_loss: 0.5144 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.4035 - accuracy: 0.7521 - val_loss: 0.4864 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.3663 - accuracy: 0.7562 - val_loss: 0.4679 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.3427 - accuracy: 0.8058 - val_loss: 0.4521 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.3760 - accuracy: 0.7851 - val_loss: 0.4405 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.3122 - accuracy: 0.8347 - val_loss: 0.4335 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.3023 - accuracy: 0.8017 - val_loss: 0.4270 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3038 - accuracy: 0.8099 - val_loss: 0.4242 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.3197 - accuracy: 0.8306 - val_loss: 0.4211 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.2680 - accuracy: 0.7934 - val_loss: 0.4195 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2697 - accuracy: 0.8306 - val_loss: 0.4201 - val_accuracy: 0.7667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.3062 - accuracy: 0.7975 - val_loss: 0.4176 - val_accuracy: 0.7667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2371 - accuracy: 0.8512 - val_loss: 0.4196 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2666 - accuracy: 0.8058 - val_loss: 0.4213 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2470 - accuracy: 0.8388 - val_loss: 0.4241 - val_accuracy: 0.7667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2673 - accuracy: 0.8306 - val_loss: 0.4265 - val_accuracy: 0.7667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 169us/step - loss: 0.2397 - accuracy: 0.8347 - val_loss: 0.4258 - val_accuracy: 0.7667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2272 - accuracy: 0.8223 - val_loss: 0.4255 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 265us/step - loss: 0.2327 - accuracy: 0.8306 - val_loss: 0.4249 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 283us/step - loss: 0.2582 - accuracy: 0.8430 - val_loss: 0.4193 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.2447 - accuracy: 0.8471 - val_loss: 0.4190 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.2417 - accuracy: 0.8223 - val_loss: 0.4167 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2352 - accuracy: 0.8595 - val_loss: 0.4195 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2138 - accuracy: 0.8347 - val_loss: 0.4216 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2335 - accuracy: 0.8264 - val_loss: 0.4230 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2343 - accuracy: 0.8306 - val_loss: 0.4244 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2711 - accuracy: 0.8719 - val_loss: 0.4236 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2097 - accuracy: 0.8595 - val_loss: 0.4235 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2415 - accuracy: 0.8471 - val_loss: 0.4242 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2296 - accuracy: 0.8554 - val_loss: 0.4245 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2195 - accuracy: 0.8430 - val_loss: 0.4251 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2419 - accuracy: 0.8512 - val_loss: 0.4261 - val_accuracy: 0.7667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2409 - accuracy: 0.8264 - val_loss: 0.4262 - val_accuracy: 0.7667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2259 - accuracy: 0.8306 - val_loss: 0.4269 - val_accuracy: 0.7667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2296 - accuracy: 0.8512 - val_loss: 0.4269 - val_accuracy: 0.7667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2137 - accuracy: 0.8512 - val_loss: 0.4264 - val_accuracy: 0.7667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 170us/step - loss: 0.2282 - accuracy: 0.8388 - val_loss: 0.4259 - val_accuracy: 0.7667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.2084 - accuracy: 0.8595 - val_loss: 0.4258 - val_accuracy: 0.7667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 172us/step - loss: 0.1874 - accuracy: 0.8471 - val_loss: 0.4257 - val_accuracy: 0.7667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 168us/step - loss: 0.2333 - accuracy: 0.8512 - val_loss: 0.4260 - val_accuracy: 0.7667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2382 - accuracy: 0.8554 - val_loss: 0.4264 - val_accuracy: 0.7667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2168 - accuracy: 0.8430 - val_loss: 0.4268 - val_accuracy: 0.7667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2080 - accuracy: 0.8554 - val_loss: 0.4268 - val_accuracy: 0.7667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2270 - accuracy: 0.8388 - val_loss: 0.4268 - val_accuracy: 0.7667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2157 - accuracy: 0.8471 - val_loss: 0.4269 - val_accuracy: 0.7667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2156 - accuracy: 0.8554 - val_loss: 0.4269 - val_accuracy: 0.7667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.2169 - accuracy: 0.8471 - val_loss: 0.4269 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [05:50<00:39, 39.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.7478 - accuracy: 0.4876 - val_loss: 0.6700 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 258us/step - loss: 0.7015 - accuracy: 0.5826 - val_loss: 0.6027 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.5603 - accuracy: 0.6860 - val_loss: 0.5459 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 240us/step - loss: 0.5768 - accuracy: 0.6983 - val_loss: 0.5015 - val_accuracy: 0.8667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.4814 - accuracy: 0.7438 - val_loss: 0.4631 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 266us/step - loss: 0.4248 - accuracy: 0.8099 - val_loss: 0.4344 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 237us/step - loss: 0.4036 - accuracy: 0.8058 - val_loss: 0.4137 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.3584 - accuracy: 0.8058 - val_loss: 0.3962 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.3488 - accuracy: 0.7851 - val_loss: 0.3795 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.3474 - accuracy: 0.8099 - val_loss: 0.3698 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.3121 - accuracy: 0.8264 - val_loss: 0.3606 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2804 - accuracy: 0.8306 - val_loss: 0.3572 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2796 - accuracy: 0.8388 - val_loss: 0.3598 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2690 - accuracy: 0.8017 - val_loss: 0.3603 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2919 - accuracy: 0.8264 - val_loss: 0.3632 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2707 - accuracy: 0.8347 - val_loss: 0.3714 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2636 - accuracy: 0.8430 - val_loss: 0.3727 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.2468 - accuracy: 0.8306 - val_loss: 0.3732 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2539 - accuracy: 0.8595 - val_loss: 0.3705 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 176us/step - loss: 0.2457 - accuracy: 0.8512 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2789 - accuracy: 0.8347 - val_loss: 0.3758 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 174us/step - loss: 0.2397 - accuracy: 0.8554 - val_loss: 0.3805 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2383 - accuracy: 0.8512 - val_loss: 0.3800 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2335 - accuracy: 0.8388 - val_loss: 0.3803 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2373 - accuracy: 0.8678 - val_loss: 0.3806 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2317 - accuracy: 0.8554 - val_loss: 0.3806 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 240us/step - loss: 0.2149 - accuracy: 0.8554 - val_loss: 0.3805 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2177 - accuracy: 0.8471 - val_loss: 0.3807 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 255us/step - loss: 0.2375 - accuracy: 0.8264 - val_loss: 0.3801 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.2553 - accuracy: 0.8264 - val_loss: 0.3796 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 191us/step - loss: 0.2574 - accuracy: 0.8347 - val_loss: 0.3805 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: 0.2326 - accuracy: 0.8471 - val_loss: 0.3823 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.2458 - accuracy: 0.8636 - val_loss: 0.3827 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: 0.2593 - accuracy: 0.8512 - val_loss: 0.3828 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 175us/step - loss: 0.2314 - accuracy: 0.8471 - val_loss: 0.3832 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2039 - accuracy: 0.8347 - val_loss: 0.3831 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2371 - accuracy: 0.8264 - val_loss: 0.3828 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:30<00:00, 39.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disc wts ROC:  0.926616379310345\n"
     ]
    }
   ],
   "source": [
    "nn_disc = Ensemble(10)\n",
    "nn_disc.print_summary()\n",
    "\n",
    "nn_disc.fit(args_dict, sample_weight=wts_disc)\n",
    "roc_value = nn_disc.validate_roc(X_oos, y_oos)\n",
    "print(\"Disc wts ROC: \", roc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, training with continuous weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_401 (Dense)            (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,953\n",
      "Trainable params: 1,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 5s 22ms/step - loss: 0.7661 - accuracy: 0.5537 - val_loss: 0.6646 - val_accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.6094 - accuracy: 0.6488 - val_loss: 0.6106 - val_accuracy: 0.7333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.6418 - accuracy: 0.6860 - val_loss: 0.5743 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.5625 - accuracy: 0.7314 - val_loss: 0.5404 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 262us/step - loss: 0.4796 - accuracy: 0.7851 - val_loss: 0.5204 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 350us/step - loss: 0.4944 - accuracy: 0.7397 - val_loss: 0.4957 - val_accuracy: 0.7667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.3969 - accuracy: 0.7727 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.4046 - accuracy: 0.7893 - val_loss: 0.4504 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.3855 - accuracy: 0.8140 - val_loss: 0.4357 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.3860 - accuracy: 0.7893 - val_loss: 0.4220 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.3992 - accuracy: 0.8058 - val_loss: 0.4117 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.3518 - accuracy: 0.8223 - val_loss: 0.4055 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.3448 - accuracy: 0.7934 - val_loss: 0.4028 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.3432 - accuracy: 0.8306 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.3319 - accuracy: 0.8306 - val_loss: 0.3971 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2971 - accuracy: 0.8595 - val_loss: 0.3940 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 267us/step - loss: 0.2950 - accuracy: 0.8347 - val_loss: 0.3900 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 292us/step - loss: 0.3193 - accuracy: 0.8471 - val_loss: 0.3917 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 275us/step - loss: 0.2791 - accuracy: 0.8347 - val_loss: 0.3908 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 250us/step - loss: 0.2832 - accuracy: 0.8595 - val_loss: 0.3952 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.3151 - accuracy: 0.8347 - val_loss: 0.3962 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.2737 - accuracy: 0.8554 - val_loss: 0.3983 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 307us/step - loss: 0.2693 - accuracy: 0.8554 - val_loss: 0.3996 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 260us/step - loss: 0.2946 - accuracy: 0.8471 - val_loss: 0.4001 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 234us/step - loss: 0.2983 - accuracy: 0.8554 - val_loss: 0.3998 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2443 - accuracy: 0.8678 - val_loss: 0.4005 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.2665 - accuracy: 0.8223 - val_loss: 0.3978 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2667 - accuracy: 0.8471 - val_loss: 0.3964 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 260us/step - loss: 0.2755 - accuracy: 0.8388 - val_loss: 0.3954 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 265us/step - loss: 0.2702 - accuracy: 0.8347 - val_loss: 0.3935 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.2814 - accuracy: 0.8223 - val_loss: 0.3930 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.3116 - accuracy: 0.8471 - val_loss: 0.3930 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2824 - accuracy: 0.8512 - val_loss: 0.3930 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3107 - accuracy: 0.8595 - val_loss: 0.3931 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.3007 - accuracy: 0.8388 - val_loss: 0.3934 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.2874 - accuracy: 0.8182 - val_loss: 0.3929 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2591 - accuracy: 0.8554 - val_loss: 0.3924 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2793 - accuracy: 0.8554 - val_loss: 0.3926 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.3038 - accuracy: 0.8306 - val_loss: 0.3925 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 181us/step - loss: 0.2722 - accuracy: 0.8678 - val_loss: 0.3927 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2624 - accuracy: 0.8678 - val_loss: 0.3928 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 255us/step - loss: 0.2690 - accuracy: 0.8347 - val_loss: 0.3927 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:54<08:14, 54.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.8101 - accuracy: 0.4835 - val_loss: 0.6326 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.7504 - accuracy: 0.5455 - val_loss: 0.5796 - val_accuracy: 0.9000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 234us/step - loss: 0.6669 - accuracy: 0.5992 - val_loss: 0.5460 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.5931 - accuracy: 0.7190 - val_loss: 0.5127 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 275us/step - loss: 0.5337 - accuracy: 0.7769 - val_loss: 0.4775 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.4978 - accuracy: 0.7438 - val_loss: 0.4497 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.4248 - accuracy: 0.7645 - val_loss: 0.4272 - val_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.4777 - accuracy: 0.7562 - val_loss: 0.4053 - val_accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.3882 - accuracy: 0.7934 - val_loss: 0.3846 - val_accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.4318 - accuracy: 0.8058 - val_loss: 0.3727 - val_accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.4034 - accuracy: 0.8017 - val_loss: 0.3631 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3348 - accuracy: 0.8223 - val_loss: 0.3510 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.3630 - accuracy: 0.8223 - val_loss: 0.3434 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.3280 - accuracy: 0.8223 - val_loss: 0.3391 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.3302 - accuracy: 0.8140 - val_loss: 0.3355 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.3038 - accuracy: 0.8347 - val_loss: 0.3361 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.3860 - accuracy: 0.8140 - val_loss: 0.3386 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.3033 - accuracy: 0.8099 - val_loss: 0.3394 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2943 - accuracy: 0.8347 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 258us/step - loss: 0.2923 - accuracy: 0.8636 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.3185 - accuracy: 0.8058 - val_loss: 0.3404 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 267us/step - loss: 0.2995 - accuracy: 0.8306 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 269us/step - loss: 0.2647 - accuracy: 0.8678 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.2934 - accuracy: 0.8471 - val_loss: 0.3411 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2867 - accuracy: 0.8306 - val_loss: 0.3414 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.3238 - accuracy: 0.8306 - val_loss: 0.3417 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.2595 - accuracy: 0.8554 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.3046 - accuracy: 0.8347 - val_loss: 0.3424 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 277us/step - loss: 0.3175 - accuracy: 0.8182 - val_loss: 0.3422 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 260us/step - loss: 0.2657 - accuracy: 0.8512 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2868 - accuracy: 0.8306 - val_loss: 0.3417 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2868 - accuracy: 0.8182 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2668 - accuracy: 0.8678 - val_loss: 0.3420 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2956 - accuracy: 0.8306 - val_loss: 0.3416 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2809 - accuracy: 0.8430 - val_loss: 0.3414 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2593 - accuracy: 0.8636 - val_loss: 0.3413 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2734 - accuracy: 0.8388 - val_loss: 0.3411 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 283us/step - loss: 0.3089 - accuracy: 0.8264 - val_loss: 0.3411 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.2826 - accuracy: 0.8388 - val_loss: 0.3410 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2971 - accuracy: 0.8430 - val_loss: 0.3412 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:41<06:38, 49.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.6895 - accuracy: 0.6074 - val_loss: 0.5244 - val_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 310us/step - loss: 0.5931 - accuracy: 0.7397 - val_loss: 0.4771 - val_accuracy: 0.8667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 299us/step - loss: 0.5156 - accuracy: 0.7190 - val_loss: 0.4312 - val_accuracy: 0.9000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 250us/step - loss: 0.4952 - accuracy: 0.7355 - val_loss: 0.4019 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.4611 - accuracy: 0.7769 - val_loss: 0.3746 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.4302 - accuracy: 0.8017 - val_loss: 0.3507 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.4387 - accuracy: 0.8017 - val_loss: 0.3367 - val_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.3896 - accuracy: 0.7934 - val_loss: 0.3245 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 237us/step - loss: 0.3909 - accuracy: 0.8099 - val_loss: 0.3117 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.3629 - accuracy: 0.8264 - val_loss: 0.3044 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.3015 - accuracy: 0.8388 - val_loss: 0.2957 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.3368 - accuracy: 0.8099 - val_loss: 0.2919 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.3171 - accuracy: 0.8223 - val_loss: 0.2882 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 287us/step - loss: 0.2994 - accuracy: 0.8223 - val_loss: 0.2857 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 290us/step - loss: 0.3250 - accuracy: 0.8430 - val_loss: 0.2867 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 302us/step - loss: 0.2889 - accuracy: 0.8223 - val_loss: 0.2877 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 248us/step - loss: 0.3027 - accuracy: 0.8430 - val_loss: 0.2882 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.2866 - accuracy: 0.8554 - val_loss: 0.2899 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2984 - accuracy: 0.8430 - val_loss: 0.2911 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2886 - accuracy: 0.8347 - val_loss: 0.2932 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 266us/step - loss: 0.2621 - accuracy: 0.8306 - val_loss: 0.2951 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 289us/step - loss: 0.2724 - accuracy: 0.8471 - val_loss: 0.2975 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 281us/step - loss: 0.2734 - accuracy: 0.8306 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.2975 - accuracy: 0.8306 - val_loss: 0.2987 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.2837 - accuracy: 0.8264 - val_loss: 0.2986 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 289us/step - loss: 0.2761 - accuracy: 0.8471 - val_loss: 0.2983 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 267us/step - loss: 0.2650 - accuracy: 0.8471 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 266us/step - loss: 0.2639 - accuracy: 0.8595 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 234us/step - loss: 0.2712 - accuracy: 0.8388 - val_loss: 0.2978 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2623 - accuracy: 0.8471 - val_loss: 0.2977 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2852 - accuracy: 0.8347 - val_loss: 0.2977 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2613 - accuracy: 0.8512 - val_loss: 0.2978 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2807 - accuracy: 0.8347 - val_loss: 0.2978 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.2570 - accuracy: 0.8719 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 294us/step - loss: 0.2701 - accuracy: 0.8760 - val_loss: 0.2981 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 271us/step - loss: 0.2580 - accuracy: 0.8512 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2371 - accuracy: 0.8636 - val_loss: 0.2980 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2648 - accuracy: 0.8595 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 265us/step - loss: 0.2728 - accuracy: 0.8306 - val_loss: 0.2983 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [02:28<05:40, 48.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.7538 - accuracy: 0.4504 - val_loss: 0.6837 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 298us/step - loss: 0.6396 - accuracy: 0.5909 - val_loss: 0.6273 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.5923 - accuracy: 0.6529 - val_loss: 0.5788 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.5046 - accuracy: 0.6983 - val_loss: 0.5336 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 242us/step - loss: 0.5370 - accuracy: 0.7686 - val_loss: 0.4998 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.4823 - accuracy: 0.8017 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.4128 - accuracy: 0.7810 - val_loss: 0.4395 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.3669 - accuracy: 0.8306 - val_loss: 0.4206 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.4080 - accuracy: 0.8017 - val_loss: 0.4067 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.3840 - accuracy: 0.8017 - val_loss: 0.3935 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.3338 - accuracy: 0.8099 - val_loss: 0.3819 - val_accuracy: 0.7667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 266us/step - loss: 0.3441 - accuracy: 0.8058 - val_loss: 0.3760 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 250us/step - loss: 0.3237 - accuracy: 0.8223 - val_loss: 0.3738 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.3250 - accuracy: 0.8140 - val_loss: 0.3726 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.3091 - accuracy: 0.8347 - val_loss: 0.3697 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.3021 - accuracy: 0.8223 - val_loss: 0.3713 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2939 - accuracy: 0.8430 - val_loss: 0.3704 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.3096 - accuracy: 0.8223 - val_loss: 0.3666 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 262us/step - loss: 0.3097 - accuracy: 0.8471 - val_loss: 0.3629 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 297us/step - loss: 0.2576 - accuracy: 0.8471 - val_loss: 0.3639 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 259us/step - loss: 0.3128 - accuracy: 0.8512 - val_loss: 0.3602 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2757 - accuracy: 0.8636 - val_loss: 0.3600 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2616 - accuracy: 0.8678 - val_loss: 0.3626 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.3139 - accuracy: 0.8182 - val_loss: 0.3606 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2531 - accuracy: 0.8678 - val_loss: 0.3633 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2615 - accuracy: 0.8595 - val_loss: 0.3645 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2607 - accuracy: 0.8554 - val_loss: 0.3612 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 287us/step - loss: 0.2733 - accuracy: 0.8595 - val_loss: 0.3612 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 264us/step - loss: 0.2717 - accuracy: 0.8636 - val_loss: 0.3623 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.2716 - accuracy: 0.8595 - val_loss: 0.3625 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 248us/step - loss: 0.2481 - accuracy: 0.8802 - val_loss: 0.3620 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 275us/step - loss: 0.2606 - accuracy: 0.8347 - val_loss: 0.3612 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2693 - accuracy: 0.8388 - val_loss: 0.3612 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2661 - accuracy: 0.8306 - val_loss: 0.3614 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2949 - accuracy: 0.8512 - val_loss: 0.3617 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2477 - accuracy: 0.8678 - val_loss: 0.3613 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2604 - accuracy: 0.8430 - val_loss: 0.3607 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 274us/step - loss: 0.2775 - accuracy: 0.8471 - val_loss: 0.3602 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2481 - accuracy: 0.8678 - val_loss: 0.3604 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.2411 - accuracy: 0.8636 - val_loss: 0.3610 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.2413 - accuracy: 0.8678 - val_loss: 0.3601 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2321 - accuracy: 0.8678 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2613 - accuracy: 0.8512 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2217 - accuracy: 0.8595 - val_loss: 0.3591 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2593 - accuracy: 0.8512 - val_loss: 0.3590 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2629 - accuracy: 0.8554 - val_loss: 0.3592 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 183us/step - loss: 0.2480 - accuracy: 0.8471 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2690 - accuracy: 0.8512 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.2454 - accuracy: 0.8595 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2343 - accuracy: 0.8636 - val_loss: 0.3589 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 272us/step - loss: 0.2445 - accuracy: 0.8636 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 262us/step - loss: 0.2556 - accuracy: 0.8388 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2461 - accuracy: 0.8471 - val_loss: 0.3581 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 259us/step - loss: 0.2421 - accuracy: 0.8760 - val_loss: 0.3580 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2589 - accuracy: 0.8595 - val_loss: 0.3582 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.2359 - accuracy: 0.8554 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 247us/step - loss: 0.2541 - accuracy: 0.8388 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2382 - accuracy: 0.8595 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2258 - accuracy: 0.8719 - val_loss: 0.3588 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2508 - accuracy: 0.8595 - val_loss: 0.3588 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2662 - accuracy: 0.8512 - val_loss: 0.3587 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2138 - accuracy: 0.8512 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2628 - accuracy: 0.8636 - val_loss: 0.3586 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2539 - accuracy: 0.8636 - val_loss: 0.3585 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 248us/step - loss: 0.2450 - accuracy: 0.8636 - val_loss: 0.3585 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2396 - accuracy: 0.8347 - val_loss: 0.3585 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 259us/step - loss: 0.2516 - accuracy: 0.8430 - val_loss: 0.3585 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.2324 - accuracy: 0.8678 - val_loss: 0.3585 - val_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 242us/step - loss: 0.2472 - accuracy: 0.8512 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 270us/step - loss: 0.2585 - accuracy: 0.8636 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 280us/step - loss: 0.2624 - accuracy: 0.8388 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2471 - accuracy: 0.8554 - val_loss: 0.3584 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2768 - accuracy: 0.8554 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2679 - accuracy: 0.8347 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2645 - accuracy: 0.8471 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 263us/step - loss: 0.2497 - accuracy: 0.8636 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2395 - accuracy: 0.8678 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.2442 - accuracy: 0.8678 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2425 - accuracy: 0.8760 - val_loss: 0.3583 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [03:18<04:55, 49.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.7189 - accuracy: 0.5413 - val_loss: 0.5980 - val_accuracy: 0.7000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.5858 - accuracy: 0.6529 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.5573 - accuracy: 0.7149 - val_loss: 0.5342 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.5135 - accuracy: 0.7438 - val_loss: 0.5181 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.4739 - accuracy: 0.7438 - val_loss: 0.5028 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.4411 - accuracy: 0.7603 - val_loss: 0.4888 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.4237 - accuracy: 0.7686 - val_loss: 0.4772 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.4079 - accuracy: 0.7975 - val_loss: 0.4657 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.3898 - accuracy: 0.7934 - val_loss: 0.4550 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.3586 - accuracy: 0.7975 - val_loss: 0.4457 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3461 - accuracy: 0.7975 - val_loss: 0.4353 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.3592 - accuracy: 0.8017 - val_loss: 0.4311 - val_accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.3693 - accuracy: 0.8099 - val_loss: 0.4256 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2997 - accuracy: 0.8512 - val_loss: 0.4213 - val_accuracy: 0.7667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.3214 - accuracy: 0.8017 - val_loss: 0.4199 - val_accuracy: 0.7667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.3208 - accuracy: 0.8223 - val_loss: 0.4145 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.3094 - accuracy: 0.8430 - val_loss: 0.4092 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.3243 - accuracy: 0.8182 - val_loss: 0.4081 - val_accuracy: 0.7667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 188us/step - loss: 0.3135 - accuracy: 0.8182 - val_loss: 0.4060 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: 0.2956 - accuracy: 0.8264 - val_loss: 0.4008 - val_accuracy: 0.7667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.2691 - accuracy: 0.8554 - val_loss: 0.4000 - val_accuracy: 0.7667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 184us/step - loss: 0.3049 - accuracy: 0.8306 - val_loss: 0.3975 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.3045 - accuracy: 0.8554 - val_loss: 0.3943 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 192us/step - loss: 0.2847 - accuracy: 0.8471 - val_loss: 0.3943 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.2622 - accuracy: 0.8306 - val_loss: 0.3938 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 186us/step - loss: 0.2879 - accuracy: 0.8471 - val_loss: 0.3910 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2798 - accuracy: 0.8512 - val_loss: 0.3891 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.2442 - accuracy: 0.8678 - val_loss: 0.3879 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2767 - accuracy: 0.8388 - val_loss: 0.3840 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2723 - accuracy: 0.8512 - val_loss: 0.3814 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 241us/step - loss: 0.2529 - accuracy: 0.8471 - val_loss: 0.3794 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2483 - accuracy: 0.8636 - val_loss: 0.3774 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2661 - accuracy: 0.8388 - val_loss: 0.3757 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 210us/step - loss: 0.2477 - accuracy: 0.8430 - val_loss: 0.3709 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.2398 - accuracy: 0.8636 - val_loss: 0.3692 - val_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2701 - accuracy: 0.8430 - val_loss: 0.3646 - val_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 187us/step - loss: 0.2381 - accuracy: 0.8760 - val_loss: 0.3643 - val_accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 258us/step - loss: 0.2464 - accuracy: 0.8719 - val_loss: 0.3632 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 255us/step - loss: 0.2718 - accuracy: 0.8471 - val_loss: 0.3638 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 248us/step - loss: 0.2558 - accuracy: 0.8636 - val_loss: 0.3645 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2314 - accuracy: 0.8678 - val_loss: 0.3631 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2661 - accuracy: 0.8430 - val_loss: 0.3612 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2302 - accuracy: 0.8471 - val_loss: 0.3648 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.2465 - accuracy: 0.8678 - val_loss: 0.3663 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2400 - accuracy: 0.8678 - val_loss: 0.3651 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.2425 - accuracy: 0.8636 - val_loss: 0.3652 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2562 - accuracy: 0.8554 - val_loss: 0.3645 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2098 - accuracy: 0.8926 - val_loss: 0.3632 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 196us/step - loss: 0.2545 - accuracy: 0.8430 - val_loss: 0.3616 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 189us/step - loss: 0.2417 - accuracy: 0.8636 - val_loss: 0.3604 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2315 - accuracy: 0.8678 - val_loss: 0.3569 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2352 - accuracy: 0.8636 - val_loss: 0.3563 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2474 - accuracy: 0.8471 - val_loss: 0.3556 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2394 - accuracy: 0.8719 - val_loss: 0.3543 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 265us/step - loss: 0.2357 - accuracy: 0.8554 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 265us/step - loss: 0.2374 - accuracy: 0.8719 - val_loss: 0.3508 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.2248 - accuracy: 0.8471 - val_loss: 0.3515 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2419 - accuracy: 0.8760 - val_loss: 0.3520 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2447 - accuracy: 0.8595 - val_loss: 0.3514 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.2725 - accuracy: 0.8471 - val_loss: 0.3507 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.2239 - accuracy: 0.8760 - val_loss: 0.3500 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2282 - accuracy: 0.8719 - val_loss: 0.3467 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2572 - accuracy: 0.8471 - val_loss: 0.3456 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2311 - accuracy: 0.8471 - val_loss: 0.3445 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2468 - accuracy: 0.8719 - val_loss: 0.3445 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2280 - accuracy: 0.8595 - val_loss: 0.3428 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2359 - accuracy: 0.8760 - val_loss: 0.3412 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2344 - accuracy: 0.8678 - val_loss: 0.3401 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 278us/step - loss: 0.2340 - accuracy: 0.8678 - val_loss: 0.3392 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2418 - accuracy: 0.8595 - val_loss: 0.3377 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.1995 - accuracy: 0.8760 - val_loss: 0.3379 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2162 - accuracy: 0.8719 - val_loss: 0.3373 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2320 - accuracy: 0.8678 - val_loss: 0.3377 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.2097 - accuracy: 0.8636 - val_loss: 0.3378 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2080 - accuracy: 0.8926 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.1943 - accuracy: 0.8760 - val_loss: 0.3423 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2048 - accuracy: 0.8719 - val_loss: 0.3413 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2319 - accuracy: 0.8678 - val_loss: 0.3416 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2332 - accuracy: 0.8554 - val_loss: 0.3415 - val_accuracy: 0.8667\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 241us/step - loss: 0.2270 - accuracy: 0.8884 - val_loss: 0.3415 - val_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 274us/step - loss: 0.2307 - accuracy: 0.8471 - val_loss: 0.3413 - val_accuracy: 0.8667\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 284us/step - loss: 0.1955 - accuracy: 0.8760 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.2409 - accuracy: 0.8471 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 264us/step - loss: 0.2402 - accuracy: 0.8802 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 218us/step - loss: 0.1953 - accuracy: 0.8884 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 239us/step - loss: 0.2159 - accuracy: 0.8719 - val_loss: 0.3406 - val_accuracy: 0.8667\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 263us/step - loss: 0.2275 - accuracy: 0.8678 - val_loss: 0.3404 - val_accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 252us/step - loss: 0.2271 - accuracy: 0.8802 - val_loss: 0.3403 - val_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 283us/step - loss: 0.2360 - accuracy: 0.8636 - val_loss: 0.3398 - val_accuracy: 0.8667\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.2066 - accuracy: 0.8884 - val_loss: 0.3395 - val_accuracy: 0.8667\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2401 - accuracy: 0.8595 - val_loss: 0.3394 - val_accuracy: 0.8667\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.2205 - accuracy: 0.8554 - val_loss: 0.3392 - val_accuracy: 0.8667\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.2229 - accuracy: 0.8719 - val_loss: 0.3392 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 263us/step - loss: 0.2161 - accuracy: 0.8719 - val_loss: 0.3392 - val_accuracy: 0.8667\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2303 - accuracy: 0.8719 - val_loss: 0.3391 - val_accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.2389 - accuracy: 0.8802 - val_loss: 0.3391 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2458 - accuracy: 0.8430 - val_loss: 0.3390 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [04:09<04:09, 49.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.6220 - accuracy: 0.5992 - val_loss: 0.6214 - val_accuracy: 0.6333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 277us/step - loss: 0.6028 - accuracy: 0.6736 - val_loss: 0.5792 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.5373 - accuracy: 0.7190 - val_loss: 0.5420 - val_accuracy: 0.7667\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.4834 - accuracy: 0.7603 - val_loss: 0.5079 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.4530 - accuracy: 0.7645 - val_loss: 0.4747 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.4706 - accuracy: 0.7893 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.4252 - accuracy: 0.7934 - val_loss: 0.4350 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.3722 - accuracy: 0.8099 - val_loss: 0.4194 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.3858 - accuracy: 0.7893 - val_loss: 0.4053 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.3574 - accuracy: 0.7934 - val_loss: 0.3955 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3436 - accuracy: 0.8099 - val_loss: 0.3908 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.3570 - accuracy: 0.8140 - val_loss: 0.3859 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.3299 - accuracy: 0.8140 - val_loss: 0.3793 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.3028 - accuracy: 0.8347 - val_loss: 0.3742 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.3177 - accuracy: 0.8264 - val_loss: 0.3700 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.3096 - accuracy: 0.8388 - val_loss: 0.3640 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2816 - accuracy: 0.8471 - val_loss: 0.3655 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.3069 - accuracy: 0.8347 - val_loss: 0.3683 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 196us/step - loss: 0.2915 - accuracy: 0.8471 - val_loss: 0.3667 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2775 - accuracy: 0.8388 - val_loss: 0.3692 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 190us/step - loss: 0.3060 - accuracy: 0.8347 - val_loss: 0.3776 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2827 - accuracy: 0.8347 - val_loss: 0.3743 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2792 - accuracy: 0.8554 - val_loss: 0.3727 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2666 - accuracy: 0.8306 - val_loss: 0.3725 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2693 - accuracy: 0.8347 - val_loss: 0.3731 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.2605 - accuracy: 0.8512 - val_loss: 0.3740 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2957 - accuracy: 0.8388 - val_loss: 0.3749 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.2367 - accuracy: 0.8512 - val_loss: 0.3756 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.2819 - accuracy: 0.8388 - val_loss: 0.3759 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 196us/step - loss: 0.2807 - accuracy: 0.8678 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.2715 - accuracy: 0.8388 - val_loss: 0.3763 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.2686 - accuracy: 0.8347 - val_loss: 0.3766 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.2588 - accuracy: 0.8430 - val_loss: 0.3769 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2323 - accuracy: 0.8678 - val_loss: 0.3770 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2511 - accuracy: 0.8719 - val_loss: 0.3767 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 285us/step - loss: 0.2456 - accuracy: 0.8430 - val_loss: 0.3768 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 247us/step - loss: 0.2284 - accuracy: 0.8678 - val_loss: 0.3768 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2532 - accuracy: 0.8347 - val_loss: 0.3769 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2464 - accuracy: 0.8595 - val_loss: 0.3771 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2685 - accuracy: 0.8554 - val_loss: 0.3770 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2570 - accuracy: 0.8595 - val_loss: 0.3774 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [04:57<03:16, 49.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.6823 - accuracy: 0.5289 - val_loss: 0.7216 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.6344 - accuracy: 0.5826 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.5867 - accuracy: 0.7025 - val_loss: 0.5827 - val_accuracy: 0.7333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.5114 - accuracy: 0.7273 - val_loss: 0.5334 - val_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 307us/step - loss: 0.4531 - accuracy: 0.7562 - val_loss: 0.4876 - val_accuracy: 0.9333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.4607 - accuracy: 0.7810 - val_loss: 0.4522 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 310us/step - loss: 0.4116 - accuracy: 0.8099 - val_loss: 0.4202 - val_accuracy: 0.9333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.3999 - val_accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.3761 - accuracy: 0.7934 - val_loss: 0.3880 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.3623 - accuracy: 0.7975 - val_loss: 0.3805 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.3353 - accuracy: 0.7934 - val_loss: 0.3714 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.3178 - accuracy: 0.8347 - val_loss: 0.3643 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.3062 - accuracy: 0.8264 - val_loss: 0.3591 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 200us/step - loss: 0.2986 - accuracy: 0.8140 - val_loss: 0.3527 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.3110 - accuracy: 0.8430 - val_loss: 0.3498 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.3357 - accuracy: 0.8306 - val_loss: 0.3446 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2986 - accuracy: 0.8058 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2801 - accuracy: 0.8347 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.2669 - accuracy: 0.8554 - val_loss: 0.3373 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.3040 - accuracy: 0.8347 - val_loss: 0.3360 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2912 - accuracy: 0.8471 - val_loss: 0.3372 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2933 - accuracy: 0.8388 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.2942 - accuracy: 0.7934 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.2631 - accuracy: 0.8554 - val_loss: 0.3337 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2705 - accuracy: 0.8099 - val_loss: 0.3322 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2743 - accuracy: 0.8388 - val_loss: 0.3289 - val_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.2611 - accuracy: 0.8554 - val_loss: 0.3290 - val_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.2788 - accuracy: 0.8430 - val_loss: 0.3289 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 212us/step - loss: 0.2944 - accuracy: 0.8347 - val_loss: 0.3287 - val_accuracy: 0.9000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2653 - accuracy: 0.8471 - val_loss: 0.3333 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2662 - accuracy: 0.8430 - val_loss: 0.3432 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2645 - accuracy: 0.8471 - val_loss: 0.3445 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2872 - accuracy: 0.8388 - val_loss: 0.3451 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 208us/step - loss: 0.2529 - accuracy: 0.8512 - val_loss: 0.3443 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.2760 - accuracy: 0.8306 - val_loss: 0.3430 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2646 - accuracy: 0.8595 - val_loss: 0.3435 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2670 - accuracy: 0.8512 - val_loss: 0.3433 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 214us/step - loss: 0.2282 - accuracy: 0.8512 - val_loss: 0.3435 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.2466 - accuracy: 0.8554 - val_loss: 0.3438 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2806 - accuracy: 0.8636 - val_loss: 0.3434 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2651 - accuracy: 0.8347 - val_loss: 0.3427 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2612 - accuracy: 0.8678 - val_loss: 0.3413 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.2679 - accuracy: 0.8471 - val_loss: 0.3410 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2591 - accuracy: 0.8554 - val_loss: 0.3410 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2444 - accuracy: 0.8554 - val_loss: 0.3410 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2430 - accuracy: 0.8595 - val_loss: 0.3411 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2707 - accuracy: 0.8595 - val_loss: 0.3409 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2509 - accuracy: 0.8306 - val_loss: 0.3411 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2408 - accuracy: 0.8512 - val_loss: 0.3415 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 202us/step - loss: 0.2628 - accuracy: 0.8182 - val_loss: 0.3416 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2319 - accuracy: 0.8802 - val_loss: 0.3418 - val_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2433 - accuracy: 0.8512 - val_loss: 0.3419 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 287us/step - loss: 0.2590 - accuracy: 0.8595 - val_loss: 0.3418 - val_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 235us/step - loss: 0.2326 - accuracy: 0.8802 - val_loss: 0.3418 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [05:46<02:27, 49.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 17ms/step - loss: 0.5869 - accuracy: 0.5826 - val_loss: 0.6084 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.5551 - accuracy: 0.6240 - val_loss: 0.5695 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.5224 - accuracy: 0.6901 - val_loss: 0.5387 - val_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 205us/step - loss: 0.4720 - accuracy: 0.6818 - val_loss: 0.5071 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.4620 - accuracy: 0.7355 - val_loss: 0.4787 - val_accuracy: 0.7667\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.4384 - accuracy: 0.7686 - val_loss: 0.4593 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.3900 - accuracy: 0.7769 - val_loss: 0.4409 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3859 - accuracy: 0.7934 - val_loss: 0.4269 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 204us/step - loss: 0.3464 - accuracy: 0.8140 - val_loss: 0.4135 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.3409 - accuracy: 0.8223 - val_loss: 0.4028 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.3429 - accuracy: 0.8099 - val_loss: 0.3950 - val_accuracy: 0.7667\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.3271 - accuracy: 0.8306 - val_loss: 0.3908 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.3208 - accuracy: 0.8306 - val_loss: 0.3862 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 199us/step - loss: 0.2896 - accuracy: 0.7934 - val_loss: 0.3812 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 267us/step - loss: 0.2541 - accuracy: 0.8554 - val_loss: 0.3812 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 293us/step - loss: 0.3195 - accuracy: 0.8099 - val_loss: 0.3823 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 244us/step - loss: 0.2867 - accuracy: 0.8430 - val_loss: 0.3856 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2970 - accuracy: 0.8388 - val_loss: 0.3855 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.2504 - accuracy: 0.8595 - val_loss: 0.3840 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.3025 - accuracy: 0.8430 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.2697 - accuracy: 0.8636 - val_loss: 0.3814 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 286us/step - loss: 0.2951 - accuracy: 0.8347 - val_loss: 0.3824 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.2800 - accuracy: 0.8554 - val_loss: 0.3839 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 222us/step - loss: 0.2842 - accuracy: 0.8430 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 271us/step - loss: 0.2675 - accuracy: 0.8471 - val_loss: 0.3854 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 276us/step - loss: 0.2498 - accuracy: 0.8636 - val_loss: 0.3863 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2357 - accuracy: 0.8554 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 254us/step - loss: 0.2547 - accuracy: 0.8430 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 237us/step - loss: 0.2667 - accuracy: 0.8471 - val_loss: 0.3850 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 221us/step - loss: 0.2638 - accuracy: 0.8595 - val_loss: 0.3842 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 290us/step - loss: 0.2559 - accuracy: 0.8512 - val_loss: 0.3846 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 268us/step - loss: 0.2372 - accuracy: 0.8802 - val_loss: 0.3844 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 247us/step - loss: 0.2186 - accuracy: 0.8760 - val_loss: 0.3843 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 219us/step - loss: 0.2635 - accuracy: 0.8471 - val_loss: 0.3847 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2836 - accuracy: 0.8388 - val_loss: 0.3846 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.2550 - accuracy: 0.8471 - val_loss: 0.3852 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 216us/step - loss: 0.2460 - accuracy: 0.8636 - val_loss: 0.3851 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 260us/step - loss: 0.2666 - accuracy: 0.8636 - val_loss: 0.3850 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.2387 - accuracy: 0.8802 - val_loss: 0.3848 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [06:35<01:37, 48.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.8300 - accuracy: 0.5083 - val_loss: 0.6725 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 213us/step - loss: 0.6508 - accuracy: 0.6364 - val_loss: 0.6163 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.6014 - accuracy: 0.6860 - val_loss: 0.5702 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 195us/step - loss: 0.5849 - accuracy: 0.7231 - val_loss: 0.5333 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.5248 - accuracy: 0.7479 - val_loss: 0.5030 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.4689 - accuracy: 0.7686 - val_loss: 0.4749 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 305us/step - loss: 0.4268 - accuracy: 0.7975 - val_loss: 0.4541 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 255us/step - loss: 0.4475 - accuracy: 0.8099 - val_loss: 0.4427 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 206us/step - loss: 0.4050 - accuracy: 0.8347 - val_loss: 0.4317 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 201us/step - loss: 0.3391 - accuracy: 0.8471 - val_loss: 0.4171 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 269us/step - loss: 0.3535 - accuracy: 0.8058 - val_loss: 0.4058 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 264us/step - loss: 0.3566 - accuracy: 0.8058 - val_loss: 0.4019 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 215us/step - loss: 0.3332 - accuracy: 0.8388 - val_loss: 0.3989 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 227us/step - loss: 0.2965 - accuracy: 0.8388 - val_loss: 0.3961 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 269us/step - loss: 0.3454 - accuracy: 0.8306 - val_loss: 0.3918 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 209us/step - loss: 0.3064 - accuracy: 0.8471 - val_loss: 0.3889 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 294us/step - loss: 0.3114 - accuracy: 0.8471 - val_loss: 0.3910 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2889 - accuracy: 0.8430 - val_loss: 0.3933 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.3206 - accuracy: 0.8512 - val_loss: 0.3918 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 217us/step - loss: 0.2978 - accuracy: 0.8306 - val_loss: 0.3899 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 273us/step - loss: 0.2930 - accuracy: 0.8223 - val_loss: 0.3936 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 278us/step - loss: 0.2867 - accuracy: 0.8306 - val_loss: 0.3937 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 264us/step - loss: 0.2947 - accuracy: 0.8347 - val_loss: 0.3947 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.2634 - accuracy: 0.8595 - val_loss: 0.3963 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 233us/step - loss: 0.2936 - accuracy: 0.8388 - val_loss: 0.3977 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 223us/step - loss: 0.2570 - accuracy: 0.8512 - val_loss: 0.3960 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 225us/step - loss: 0.2901 - accuracy: 0.8430 - val_loss: 0.3954 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.2826 - accuracy: 0.8512 - val_loss: 0.3958 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.2746 - accuracy: 0.8471 - val_loss: 0.3956 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 249us/step - loss: 0.2795 - accuracy: 0.8430 - val_loss: 0.3956 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 207us/step - loss: 0.2779 - accuracy: 0.8430 - val_loss: 0.3971 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2852 - accuracy: 0.8471 - val_loss: 0.3967 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 194us/step - loss: 0.2586 - accuracy: 0.8554 - val_loss: 0.3963 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 193us/step - loss: 0.2675 - accuracy: 0.8264 - val_loss: 0.3965 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 267us/step - loss: 0.2686 - accuracy: 0.8512 - val_loss: 0.3966 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 273us/step - loss: 0.2607 - accuracy: 0.8636 - val_loss: 0.3976 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 287us/step - loss: 0.2746 - accuracy: 0.8512 - val_loss: 0.3981 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 236us/step - loss: 0.2702 - accuracy: 0.8388 - val_loss: 0.3984 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 245us/step - loss: 0.2694 - accuracy: 0.8595 - val_loss: 0.3984 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 305us/step - loss: 0.2501 - accuracy: 0.8636 - val_loss: 0.3983 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 259us/step - loss: 0.2762 - accuracy: 0.8388 - val_loss: 0.3979 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [07:25<00:49, 49.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 4s 18ms/step - loss: 0.6750 - accuracy: 0.5702 - val_loss: 0.6498 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 298us/step - loss: 0.6066 - accuracy: 0.6612 - val_loss: 0.6086 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 281us/step - loss: 0.5540 - accuracy: 0.7066 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 300us/step - loss: 0.5169 - accuracy: 0.7521 - val_loss: 0.5391 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 293us/step - loss: 0.4993 - accuracy: 0.7893 - val_loss: 0.5129 - val_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 261us/step - loss: 0.4594 - accuracy: 0.7686 - val_loss: 0.4868 - val_accuracy: 0.8667\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 288us/step - loss: 0.4302 - accuracy: 0.7851 - val_loss: 0.4679 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 283us/step - loss: 0.4186 - accuracy: 0.8017 - val_loss: 0.4479 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 240us/step - loss: 0.4155 - accuracy: 0.8058 - val_loss: 0.4358 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 228us/step - loss: 0.3682 - accuracy: 0.8182 - val_loss: 0.4217 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 224us/step - loss: 0.3681 - accuracy: 0.8223 - val_loss: 0.4093 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 291us/step - loss: 0.3540 - accuracy: 0.8264 - val_loss: 0.4012 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 263us/step - loss: 0.3342 - accuracy: 0.8388 - val_loss: 0.3900 - val_accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 231us/step - loss: 0.3525 - accuracy: 0.8182 - val_loss: 0.3839 - val_accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 229us/step - loss: 0.3140 - accuracy: 0.8471 - val_loss: 0.3786 - val_accuracy: 0.8667\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 238us/step - loss: 0.3818 - accuracy: 0.8099 - val_loss: 0.3753 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.3214 - accuracy: 0.8264 - val_loss: 0.3718 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 274us/step - loss: 0.3281 - accuracy: 0.8306 - val_loss: 0.3688 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 246us/step - loss: 0.3069 - accuracy: 0.8512 - val_loss: 0.3673 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.3037 - accuracy: 0.8306 - val_loss: 0.3699 - val_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 308us/step - loss: 0.3032 - accuracy: 0.8223 - val_loss: 0.3696 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 334us/step - loss: 0.2841 - accuracy: 0.8595 - val_loss: 0.3633 - val_accuracy: 0.8667\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 313us/step - loss: 0.2895 - accuracy: 0.8430 - val_loss: 0.3613 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 294us/step - loss: 0.3055 - accuracy: 0.8430 - val_loss: 0.3604 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 253us/step - loss: 0.2918 - accuracy: 0.8471 - val_loss: 0.3580 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 263us/step - loss: 0.2495 - accuracy: 0.8719 - val_loss: 0.3573 - val_accuracy: 0.8667\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 259us/step - loss: 0.3152 - accuracy: 0.8347 - val_loss: 0.3568 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 251us/step - loss: 0.2663 - accuracy: 0.8595 - val_loss: 0.3523 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 250us/step - loss: 0.2699 - accuracy: 0.8595 - val_loss: 0.3496 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 237us/step - loss: 0.2930 - accuracy: 0.8306 - val_loss: 0.3508 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 226us/step - loss: 0.2728 - accuracy: 0.8760 - val_loss: 0.3522 - val_accuracy: 0.8667\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 232us/step - loss: 0.2433 - accuracy: 0.8512 - val_loss: 0.3517 - val_accuracy: 0.8667\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 283us/step - loss: 0.2735 - accuracy: 0.8388 - val_loss: 0.3562 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 243us/step - loss: 0.2438 - accuracy: 0.8636 - val_loss: 0.3632 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 211us/step - loss: 0.2541 - accuracy: 0.8595 - val_loss: 0.3636 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 203us/step - loss: 0.2899 - accuracy: 0.8306 - val_loss: 0.3640 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 281us/step - loss: 0.2456 - accuracy: 0.8554 - val_loss: 0.3621 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 256us/step - loss: 0.2445 - accuracy: 0.8347 - val_loss: 0.3611 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 301us/step - loss: 0.2393 - accuracy: 0.8512 - val_loss: 0.3572 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 281us/step - loss: 0.2671 - accuracy: 0.8554 - val_loss: 0.3564 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 294us/step - loss: 0.2480 - accuracy: 0.8430 - val_loss: 0.3557 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 264us/step - loss: 0.2307 - accuracy: 0.8760 - val_loss: 0.3553 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.2881 - accuracy: 0.8430 - val_loss: 0.3546 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.2600 - accuracy: 0.8471 - val_loss: 0.3540 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2304 - accuracy: 0.8719 - val_loss: 0.3540 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 198us/step - loss: 0.2469 - accuracy: 0.8471 - val_loss: 0.3542 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 197us/step - loss: 0.2681 - accuracy: 0.8595 - val_loss: 0.3537 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 220us/step - loss: 0.2823 - accuracy: 0.8264 - val_loss: 0.3536 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 251us/step - loss: 0.2782 - accuracy: 0.8471 - val_loss: 0.3537 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 230us/step - loss: 0.2330 - accuracy: 0.8554 - val_loss: 0.3537 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 310us/step - loss: 0.2357 - accuracy: 0.8554 - val_loss: 0.3537 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 267us/step - loss: 0.2610 - accuracy: 0.8306 - val_loss: 0.3536 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 292us/step - loss: 0.2242 - accuracy: 0.8760 - val_loss: 0.3535 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 288us/step - loss: 0.2573 - accuracy: 0.8636 - val_loss: 0.3534 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:17<00:00, 49.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cont wts ROC:  0.9321120689655171\n"
     ]
    }
   ],
   "source": [
    "nn_cont = Ensemble(10)\n",
    "nn_cont.print_summary()\n",
    "\n",
    "nn_cont.fit(args_dict, wts_tr)\n",
    "roc_value = nn_cont.validate_roc(X_oos, y_oos)\n",
    "print(\"Cont wts ROC: \", roc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now evaluating *both* neural nets on ages below 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disc ROC value:  0.9267045454545455\n",
      "Cont ROC value:  0.9323863636363635\n"
     ]
    }
   ],
   "source": [
    "## X_below & y_below defined at start of notebook\n",
    "\n",
    "disc_roc = nn_disc.validate_roc(X_below, y_below)\n",
    "print(\"Disc ROC value: \", disc_roc)\n",
    "\n",
    "cont_roc = nn_cont.validate_roc(X_below, y_below)\n",
    "print(\"Cont ROC value: \", cont_roc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unbalanced model's performance *decreases* for ages < 60, but the balanced model's performance **improves** for that age group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways from part 2\n",
    "\n",
    "Continuous weight-balancing provides greater gains in performance compared to discrete weights, across 3 different ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
